{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow_probability==0.8.0rc0 --user --upgrade\n",
    "#pip install tf-hub-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from re import match\n",
    "from itertools import product, count, chain\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import layers # replced keras with tensorflow.keras due to this issue \n",
    "#\"AttributeError: module 'tensorflow' has no attribute 'get_default_graph\"\n",
    "# This occured on layers.Input()\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import callbacks\n",
    "import os\n",
    "import cv2\n",
    "import string\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Image dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(filter(lambda image: match('^[a-z0-9]+\\..+$', image), images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1070"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [image[0:5] for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['226md',\n",
       " '22d5n',\n",
       " '2356g',\n",
       " '23mdg',\n",
       " '23n88',\n",
       " '243mm',\n",
       " '244e2',\n",
       " '245y5',\n",
       " '24f6w',\n",
       " '24pew',\n",
       " '25257',\n",
       " '253dc',\n",
       " '25egp',\n",
       " '25m6p',\n",
       " '25p2m',\n",
       " '25w53',\n",
       " '264m5',\n",
       " '268g2',\n",
       " '28348',\n",
       " '28x47',\n",
       " '2b827',\n",
       " '2bg48',\n",
       " '2cegf',\n",
       " '2cg58',\n",
       " '2cgyx',\n",
       " '2en7g',\n",
       " '2enf4',\n",
       " '2fxgd',\n",
       " '2g783',\n",
       " '2g7nm',\n",
       " '2gyb6',\n",
       " '2mg87',\n",
       " '2mpnn',\n",
       " '2n73f',\n",
       " '2nbc5',\n",
       " '2nbcx',\n",
       " '2nf26',\n",
       " '2npg6',\n",
       " '2nx38',\n",
       " '2p2y8',\n",
       " '2pfpn',\n",
       " '2w4y7',\n",
       " '2wc38',\n",
       " '2wx73',\n",
       " '2x7bm',\n",
       " '2xc2n',\n",
       " '2ycn8',\n",
       " '2yggg',\n",
       " '325fb',\n",
       " '32cnn',\n",
       " '32dnn',\n",
       " '33b22',\n",
       " '33f7m',\n",
       " '33n73',\n",
       " '33ng4',\n",
       " '33p4e',\n",
       " '34b84',\n",
       " '34fxm',\n",
       " '34pcn',\n",
       " '368y5',\n",
       " '36bc2',\n",
       " '36nx4',\n",
       " '36w25',\n",
       " '373gb',\n",
       " '377xx',\n",
       " '378e5',\n",
       " '37d52',\n",
       " '37ep6',\n",
       " '387g2',\n",
       " '38n57',\n",
       " '3b4we',\n",
       " '3bd8f',\n",
       " '3bfnd',\n",
       " '3bnyf',\n",
       " '3bx86',\n",
       " '3c7de',\n",
       " '3cpwb',\n",
       " '3d7bd',\n",
       " '3den6',\n",
       " '3dgmf',\n",
       " '3ebnn',\n",
       " '3ebpw',\n",
       " '3eny7',\n",
       " '3fbxd',\n",
       " '3g2w6',\n",
       " '3mxdn',\n",
       " '3n2b4',\n",
       " '3n3cf',\n",
       " '3n7mx',\n",
       " '3ndxd',\n",
       " '3nfdn',\n",
       " '3nnpw',\n",
       " '3nw7w',\n",
       " '3ny45',\n",
       " '3p4nn',\n",
       " '3p67n',\n",
       " '3pe4g',\n",
       " '3w2bw',\n",
       " '3wnd3',\n",
       " '3x325',\n",
       " '3x5fm',\n",
       " '3xcgg',\n",
       " '3xng6',\n",
       " '3ye2e',\n",
       " '3ygde',\n",
       " '3ym7f',\n",
       " '428b6',\n",
       " '42dw4',\n",
       " '42nxy',\n",
       " '42xpy',\n",
       " '43gey',\n",
       " '43mn5',\n",
       " '43p5d',\n",
       " '43xfe',\n",
       " '4433m',\n",
       " '445cc',\n",
       " '44c22',\n",
       " '44fyb',\n",
       " '44xe8',\n",
       " '44ype',\n",
       " '467d5',\n",
       " '46mbm',\n",
       " '4743p',\n",
       " '474ff',\n",
       " '478nx',\n",
       " '47e4p',\n",
       " '47m2b',\n",
       " '488de',\n",
       " '4b2pw',\n",
       " '4c8n8',\n",
       " '4cfw8',\n",
       " '4cn7b',\n",
       " '4d22m',\n",
       " '4dgf7',\n",
       " '4dw3w',\n",
       " '4egem',\n",
       " '4exnn',\n",
       " '4f8yp',\n",
       " '4fc36',\n",
       " '4fp5g',\n",
       " '4gb3f',\n",
       " '4gycb',\n",
       " '4m2w5',\n",
       " '4n2yg',\n",
       " '4n3mn',\n",
       " '4nc37',\n",
       " '4nnf3',\n",
       " '4w6mw',\n",
       " '4w76g',\n",
       " '4yc85',\n",
       " '4ycex',\n",
       " '4ynf3',\n",
       " '52447',\n",
       " '5325m',\n",
       " '537nf',\n",
       " '53mn8',\n",
       " '53wb8',\n",
       " '53wp3',\n",
       " '556wd',\n",
       " '55w5c',\n",
       " '55y2m',\n",
       " '56c34',\n",
       " '56m6y',\n",
       " '56ncx',\n",
       " '573bn',\n",
       " '573d8',\n",
       " '574d7',\n",
       " '57b27',\n",
       " '57gnx',\n",
       " '57wdp',\n",
       " '58b5m',\n",
       " '58pnp',\n",
       " '5bb66',\n",
       " '5bg8f',\n",
       " '5bgp2',\n",
       " '5bnd7',\n",
       " '5dxnm',\n",
       " '5ep3n',\n",
       " '5expp',\n",
       " '5f3gf',\n",
       " '5fyem',\n",
       " '5g5e5',\n",
       " '5gcd3',\n",
       " '5mcy7',\n",
       " '5mf7c',\n",
       " '5mfff',\n",
       " '5mgn4',\n",
       " '5mnpd',\n",
       " '5n245',\n",
       " '5n3w4',\n",
       " '5n728',\n",
       " '5n732',\n",
       " '5ng6e',\n",
       " '5nggg',\n",
       " '5nm6d',\n",
       " '5nnff',\n",
       " '5np4m',\n",
       " '5npdn',\n",
       " '5nxnn',\n",
       " '5p3mm',\n",
       " '5p8fm',\n",
       " '5pm6b',\n",
       " '5wddw',\n",
       " '5x5nx',\n",
       " '5x7x5',\n",
       " '5xd2e',\n",
       " '5xwcg',\n",
       " '5ywwf',\n",
       " '5yxgp',\n",
       " '62fgn',\n",
       " '62nb3',\n",
       " '63824',\n",
       " '63pxe',\n",
       " '646x8',\n",
       " '64b3p',\n",
       " '64m82',\n",
       " '658xe',\n",
       " '65ebm',\n",
       " '65m85',\n",
       " '65nmw',\n",
       " '662bw',\n",
       " '664dn',\n",
       " '664nf',\n",
       " '66wp5',\n",
       " '675p3',\n",
       " '677g3',\n",
       " '678w3',\n",
       " '67dey',\n",
       " '6825y',\n",
       " '68wfd',\n",
       " '68x48',\n",
       " '6b46g',\n",
       " '6b4w6',\n",
       " '6bdn5',\n",
       " '6bnnm',\n",
       " '6bxwg',\n",
       " '6c3n6',\n",
       " '6c3p5',\n",
       " '6cm6m',\n",
       " '6cwxe',\n",
       " '6dd2y',\n",
       " '6dmx7',\n",
       " '6e2dg',\n",
       " '6e554',\n",
       " '6e6pn',\n",
       " '6ecbn',\n",
       " '6end3',\n",
       " '6f2yc',\n",
       " '6f857',\n",
       " '6fg8c',\n",
       " '6fgdw',\n",
       " '6fn84',\n",
       " '6g45w',\n",
       " '6ge3p',\n",
       " '6gnm3',\n",
       " '6m5eg',\n",
       " '6mege',\n",
       " '6mn8n',\n",
       " '6mygb',\n",
       " '6n443',\n",
       " '6n5fd',\n",
       " '6n6gg',\n",
       " '6ng6n',\n",
       " '6ng6w',\n",
       " '6p2ge',\n",
       " '6p7gx',\n",
       " '6pfy4',\n",
       " '6pwcn',\n",
       " '6wb76',\n",
       " '6wg4n',\n",
       " '6wnyc',\n",
       " '6xen4',\n",
       " '6xpme',\n",
       " '6xxdx',\n",
       " '6ydyp',\n",
       " '728n8',\n",
       " '72m6f',\n",
       " '73mnx',\n",
       " '74853',\n",
       " '74eyg',\n",
       " '75pfw',\n",
       " '7634y',\n",
       " '76353',\n",
       " '76n7p',\n",
       " '76nxn',\n",
       " '76y6f',\n",
       " '77387',\n",
       " '77n6g',\n",
       " '77wp4',\n",
       " '785n4',\n",
       " '78dw6',\n",
       " '78eec',\n",
       " '7b4bm',\n",
       " '7bb7b',\n",
       " '7bwm2',\n",
       " '7cdge',\n",
       " '7cgym',\n",
       " '7d44m',\n",
       " '7dgc2',\n",
       " '7dwx4',\n",
       " '7dxbd',\n",
       " '7dyww',\n",
       " '7e2y7',\n",
       " '7f8b3',\n",
       " '7fde7',\n",
       " '7fmcy',\n",
       " '7g3nf',\n",
       " '7gce6',\n",
       " '7gmf3',\n",
       " '7gnge',\n",
       " '7gp47',\n",
       " '7m8px',\n",
       " '7mgmf',\n",
       " '7nnnx',\n",
       " '7p852',\n",
       " '7pcd7',\n",
       " '7pn5g',\n",
       " '7w67m',\n",
       " '7wn74',\n",
       " '7wnpm',\n",
       " '7wyp4',\n",
       " '7xcyd',\n",
       " '7xd5m',\n",
       " '7y2x4',\n",
       " '7yf62',\n",
       " '823p2',\n",
       " '82fx2',\n",
       " '832f3',\n",
       " '84py4',\n",
       " '84w7x',\n",
       " '85622',\n",
       " '85dxn',\n",
       " '85pew',\n",
       " '865wm',\n",
       " '8684m',\n",
       " '87d4c',\n",
       " '87nym',\n",
       " '88bgx',\n",
       " '88y52',\n",
       " '8b735',\n",
       " '8bbm4',\n",
       " '8bbw8',\n",
       " '8c23f',\n",
       " '8c2wy',\n",
       " '8cccc',\n",
       " '8cm46',\n",
       " '8d2nd',\n",
       " '8d4wm',\n",
       " '8d8ep',\n",
       " '8db67',\n",
       " '8e32m',\n",
       " '8eggg',\n",
       " '8fexn',\n",
       " '8g4yp',\n",
       " '8gecm',\n",
       " '8gf7n',\n",
       " '8gmc4',\n",
       " '8gmnx',\n",
       " '8n2pg',\n",
       " '8n34n',\n",
       " '8n4n8',\n",
       " '8n56m',\n",
       " '8n5p3',\n",
       " '8n5pn',\n",
       " '8n62n',\n",
       " '8n65n',\n",
       " '8nbew',\n",
       " '8ne4g',\n",
       " '8nn73',\n",
       " '8np22',\n",
       " '8npd5',\n",
       " '8npe3',\n",
       " '8pfxx',\n",
       " '8w754',\n",
       " '8w875',\n",
       " '8wy7d',\n",
       " '8xef7',\n",
       " '8y63f',\n",
       " '8y6b3',\n",
       " '8ypdn',\n",
       " 'b26nd',\n",
       " 'b28g8',\n",
       " 'b2g8e',\n",
       " 'b2nen',\n",
       " 'b35f6',\n",
       " 'b3xpn',\n",
       " 'b43nw',\n",
       " 'b4d7c',\n",
       " 'b4ncn',\n",
       " 'b4ndb',\n",
       " 'b4y5x',\n",
       " 'b55d6',\n",
       " 'b5dn4',\n",
       " 'b5fm7',\n",
       " 'b5nmm',\n",
       " 'b5pnn',\n",
       " 'b685n',\n",
       " 'b6f2p',\n",
       " 'b84xc',\n",
       " 'bbymy',\n",
       " 'bc8nf',\n",
       " 'bcwnn',\n",
       " 'bd3b7',\n",
       " 'bdbb3',\n",
       " 'bdg84',\n",
       " 'be3bp',\n",
       " 'be6np',\n",
       " 'befbd',\n",
       " 'bf52c',\n",
       " 'bgb48',\n",
       " 'bgd4m',\n",
       " 'bgem5',\n",
       " 'bgxcd',\n",
       " 'bm3p8',\n",
       " 'bmxpe',\n",
       " 'bn5mw',\n",
       " 'bnc2f',\n",
       " 'bnc5f',\n",
       " 'bny23',\n",
       " 'bny4w',\n",
       " 'bp2d4',\n",
       " 'bp6mw',\n",
       " 'bpwd7',\n",
       " 'bw44w',\n",
       " 'bw5nf',\n",
       " 'bw5ym',\n",
       " 'bw6n6',\n",
       " 'bwmee',\n",
       " 'bx5ed',\n",
       " 'bxxfc',\n",
       " 'by5y3',\n",
       " 'byc82',\n",
       " 'byfgn',\n",
       " 'c2fb7',\n",
       " 'c2g4d',\n",
       " 'c2pg6',\n",
       " 'c2yn8',\n",
       " 'c353e',\n",
       " 'c3572',\n",
       " 'c3n8x',\n",
       " 'c43b4',\n",
       " 'c4527',\n",
       " 'c482b',\n",
       " 'c4bgd',\n",
       " 'c4bny',\n",
       " 'c4mcm',\n",
       " 'c55c6',\n",
       " 'c5xne',\n",
       " 'c6745',\n",
       " 'c6f8g',\n",
       " 'c6we6',\n",
       " 'c753e',\n",
       " 'c7gb3',\n",
       " 'c7nn8',\n",
       " 'c86md',\n",
       " 'c8fxy',\n",
       " 'c8n8c',\n",
       " 'cb8cf',\n",
       " 'cc845',\n",
       " 'ccf2w',\n",
       " 'ccn2x',\n",
       " 'cd4eg',\n",
       " 'cd6p4',\n",
       " 'cdcb3',\n",
       " 'cdf77',\n",
       " 'cdfen',\n",
       " 'cdmn8',\n",
       " 'cen55',\n",
       " 'cewnm',\n",
       " 'cfc2y',\n",
       " 'cfc56',\n",
       " 'cffp4',\n",
       " 'cfn53',\n",
       " 'cfp86',\n",
       " 'cfw6e',\n",
       " 'cg5dd',\n",
       " 'cgcgb',\n",
       " 'cm6yb',\n",
       " 'cndmc',\n",
       " 'cnex4',\n",
       " 'cnmnn',\n",
       " 'cnwyc',\n",
       " 'cpc8c',\n",
       " 'cpe63',\n",
       " 'cwdnx',\n",
       " 'cwgyx',\n",
       " 'cwmny',\n",
       " 'cx3wg',\n",
       " 'cy3nw',\n",
       " 'd22bd',\n",
       " 'd22n7',\n",
       " 'd22y5',\n",
       " 'd236n',\n",
       " 'd2n8x',\n",
       " 'd2nbn',\n",
       " 'd2ycw',\n",
       " 'd378n',\n",
       " 'd3c7y',\n",
       " 'd3c8y',\n",
       " 'd3ycn',\n",
       " 'd4n82',\n",
       " 'd4ppy',\n",
       " 'd666m',\n",
       " 'd66cn',\n",
       " 'd6fcn',\n",
       " 'd75b5',\n",
       " 'd7c5x',\n",
       " 'd7en3',\n",
       " 'd7nn3',\n",
       " 'd8dce',\n",
       " 'd8xcn',\n",
       " 'dbex3',\n",
       " 'dbfen',\n",
       " 'dbny3',\n",
       " 'dbpcd',\n",
       " 'dc436',\n",
       " 'dce8y',\n",
       " 'dcnp8',\n",
       " 'dd5w5',\n",
       " 'dd764',\n",
       " 'ddcdd',\n",
       " 'ddcne',\n",
       " 'ddmyg',\n",
       " 'ddnpf',\n",
       " 'ddpyb',\n",
       " 'ddxpp',\n",
       " 'de45x',\n",
       " 'de7f8',\n",
       " 'deep5',\n",
       " 'defyx',\n",
       " 'deneb',\n",
       " 'dfnx4',\n",
       " 'dgcm4',\n",
       " 'dmw8n',\n",
       " 'dmx8p',\n",
       " 'dmxp8',\n",
       " 'dn26n',\n",
       " 'dn2ym',\n",
       " 'dn5df',\n",
       " 'dnmd8',\n",
       " 'dnne7',\n",
       " 'dnxdp',\n",
       " 'dpbyd',\n",
       " 'dw3nn',\n",
       " 'dw6mn',\n",
       " 'dw8d3',\n",
       " 'dxwcw',\n",
       " 'dy3cx',\n",
       " 'dyp7n',\n",
       " 'dyxnc',\n",
       " 'e25xg',\n",
       " 'e2d66',\n",
       " 'e2mg2',\n",
       " 'e3cfe',\n",
       " 'e3ndn',\n",
       " 'e43ym',\n",
       " 'e46pd',\n",
       " 'e46yw',\n",
       " 'e4gd7',\n",
       " 'e5n66',\n",
       " 'e667x',\n",
       " 'e6b7y',\n",
       " 'e6m6p',\n",
       " 'e72cd',\n",
       " 'e76n4',\n",
       " 'e7nx4',\n",
       " 'e7x45',\n",
       " 'e84n2',\n",
       " 'e8dxn',\n",
       " 'e8e5e',\n",
       " 'ebcbx',\n",
       " 'ec6pm',\n",
       " 'ecd4w',\n",
       " 'edg3p',\n",
       " 'edwny',\n",
       " 'ee8fg',\n",
       " 'een23',\n",
       " 'ef4mn',\n",
       " 'ef4np',\n",
       " 'efb3f',\n",
       " 'efe62',\n",
       " 'efg72',\n",
       " 'efgx5',\n",
       " 'efx34',\n",
       " 'egxmp',\n",
       " 'emwpn',\n",
       " 'en32e',\n",
       " 'en4n4',\n",
       " 'eng53',\n",
       " 'enn7n',\n",
       " 'ennmm',\n",
       " 'enpw2',\n",
       " 'ep85x',\n",
       " 'eppg3',\n",
       " 'ewcf5',\n",
       " 'ewnx8',\n",
       " 'ewyg7',\n",
       " 'excmn',\n",
       " 'exycn',\n",
       " 'f228n',\n",
       " 'f22bn',\n",
       " 'f2fge',\n",
       " 'f2m8n',\n",
       " 'f35xp',\n",
       " 'f364x',\n",
       " 'f4fn2',\n",
       " 'f4wfn',\n",
       " 'f5cm2',\n",
       " 'f5e5e',\n",
       " 'f6bpw',\n",
       " 'f6ne5',\n",
       " 'f6ww8',\n",
       " 'f74x3',\n",
       " 'f753f',\n",
       " 'f75cx',\n",
       " 'f7cey',\n",
       " 'f83pn',\n",
       " 'f858x',\n",
       " 'f85y3',\n",
       " 'f8f8g',\n",
       " 'fbp2c',\n",
       " 'fc2ff',\n",
       " 'fc6xb',\n",
       " 'fcey3',\n",
       " 'fcmem',\n",
       " 'fcne6',\n",
       " 'fdpgd',\n",
       " 'feyc8',\n",
       " 'ffd6p',\n",
       " 'ffnxn',\n",
       " 'ffpxf',\n",
       " 'fg38b',\n",
       " 'fg7mg',\n",
       " 'fg8n4',\n",
       " 'fgb36',\n",
       " 'fnbfw',\n",
       " 'fncnb',\n",
       " 'fp382',\n",
       " 'fp3wy',\n",
       " 'fp5wn',\n",
       " 'fp762',\n",
       " 'fpw76',\n",
       " 'fw3b2',\n",
       " 'fwxdp',\n",
       " 'fxpw3',\n",
       " 'fy2nd',\n",
       " 'fyfbn',\n",
       " 'fywb8',\n",
       " 'g247w',\n",
       " 'g2577',\n",
       " 'g2fnw',\n",
       " 'g3dy6',\n",
       " 'g3ex3',\n",
       " 'g55b4',\n",
       " 'g6n7x',\n",
       " 'g78gn',\n",
       " 'g7fmc',\n",
       " 'g7gnf',\n",
       " 'g7wxw',\n",
       " 'g842c',\n",
       " 'g888x',\n",
       " 'g8gnd',\n",
       " 'gbxyy',\n",
       " 'gc277',\n",
       " 'gc2wd',\n",
       " 'gc83b',\n",
       " 'gcfgp',\n",
       " 'gcx6f',\n",
       " 'gd4mf',\n",
       " 'gd8fb',\n",
       " 'gdng3',\n",
       " 'gecmf',\n",
       " 'gegw4',\n",
       " 'gewfy',\n",
       " 'geyn5',\n",
       " 'gf2g4',\n",
       " 'gfbx6',\n",
       " 'gfp54',\n",
       " 'gfxcc',\n",
       " 'ggd7m',\n",
       " 'gm2c2',\n",
       " 'gm6nn',\n",
       " 'gm7n8',\n",
       " 'gmmne',\n",
       " 'gn2d3',\n",
       " 'gn2xy',\n",
       " 'gnbde',\n",
       " 'gnbn4',\n",
       " 'gnc3n',\n",
       " 'gnf85',\n",
       " 'gng6e',\n",
       " 'gny6b',\n",
       " 'gp22x',\n",
       " 'gp7c5',\n",
       " 'gpnxn',\n",
       " 'gpxng',\n",
       " 'gw468',\n",
       " 'gw53m',\n",
       " 'gwn53',\n",
       " 'gwnm6',\n",
       " 'gxx2p',\n",
       " 'gxxpf',\n",
       " 'gy433',\n",
       " 'gy5bf',\n",
       " 'gy8xb',\n",
       " 'gymmn',\n",
       " 'm22e3',\n",
       " 'm23bp',\n",
       " 'm2576',\n",
       " 'm2nf4',\n",
       " 'm3588',\n",
       " 'm3b5p',\n",
       " 'm3wfw',\n",
       " 'm448b',\n",
       " 'm457d',\n",
       " 'm4fd8',\n",
       " 'm4g8g',\n",
       " 'm5meg',\n",
       " 'm5ym2',\n",
       " 'm67b3',\n",
       " 'm6n4x',\n",
       " 'm74dm',\n",
       " 'm75bf',\n",
       " 'm8gmx',\n",
       " 'm8m4x',\n",
       " 'mb4en',\n",
       " 'mbf58',\n",
       " 'mbp2y',\n",
       " 'mc35n',\n",
       " 'mc8w2',\n",
       " 'mcc2x',\n",
       " 'mcg43',\n",
       " 'mcyfx',\n",
       " 'md344',\n",
       " 'mddgb',\n",
       " 'mdxpn',\n",
       " 'mdyp7',\n",
       " 'men4f',\n",
       " 'mfb3x',\n",
       " 'mfc35',\n",
       " 'mg5nn',\n",
       " 'mgdwb',\n",
       " 'mggce',\n",
       " 'mgw3n',\n",
       " 'mm3nn',\n",
       " 'mmc5n',\n",
       " 'mmfm6',\n",
       " 'mmg2m',\n",
       " 'mmg38',\n",
       " 'mmy5n',\n",
       " 'mn5c4',\n",
       " 'mnef5',\n",
       " 'mp7wp',\n",
       " 'mpmy5',\n",
       " 'mpxfb',\n",
       " 'mw5p2',\n",
       " 'mwdf6',\n",
       " 'mwxwp',\n",
       " 'mx8bb',\n",
       " 'mxnw4',\n",
       " 'mxyxw',\n",
       " 'my84e',\n",
       " 'myc3c',\n",
       " 'mye68',\n",
       " 'myf82',\n",
       " 'n265y',\n",
       " 'n2by7',\n",
       " 'n2c85',\n",
       " 'n2gmg',\n",
       " 'n336e',\n",
       " 'n373n',\n",
       " 'n3bm6',\n",
       " 'n3ffn',\n",
       " 'n3m6x',\n",
       " 'n3x4c',\n",
       " 'n3xfg',\n",
       " 'n464c',\n",
       " 'n4b4m',\n",
       " 'n4cpy',\n",
       " 'n4wwn',\n",
       " 'n4xx5',\n",
       " 'n5cm7',\n",
       " 'n5n8b',\n",
       " 'n5w5g',\n",
       " 'n5wbg',\n",
       " 'n5x2n',\n",
       " 'n6f4b',\n",
       " 'n6nn2',\n",
       " 'n6xc5',\n",
       " 'n7dyb',\n",
       " 'n7ebx',\n",
       " 'n7enn',\n",
       " 'n7ff2',\n",
       " 'n7g4f',\n",
       " 'n7meb',\n",
       " 'n8fp6',\n",
       " 'n8pfe',\n",
       " 'n8wxm',\n",
       " 'n8ydd',\n",
       " 'nb267',\n",
       " 'nb45d',\n",
       " 'nbcgb',\n",
       " 'nbf8m',\n",
       " 'nbfx5',\n",
       " 'nbmx7',\n",
       " 'nbp3e',\n",
       " 'nbwnn',\n",
       " 'nbwpn',\n",
       " 'nc4yg',\n",
       " 'ncfgb',\n",
       " 'ncw4g',\n",
       " 'ncww7',\n",
       " 'ncyx8',\n",
       " 'nd5wg',\n",
       " 'ndecc',\n",
       " 'ndg2b',\n",
       " 'ndme7',\n",
       " 'ndyfe',\n",
       " 'ne325',\n",
       " 'neecd',\n",
       " 'neggn',\n",
       " 'nf2n8',\n",
       " 'nf7bn',\n",
       " 'nf8b8',\n",
       " 'nfbg8',\n",
       " 'nfcb5',\n",
       " 'nfcwy',\n",
       " 'nfd8g',\n",
       " 'nfg23',\n",
       " 'nfndw',\n",
       " 'ng2gw',\n",
       " 'ng46m',\n",
       " 'ng6yp',\n",
       " 'ng756',\n",
       " 'ngn26',\n",
       " 'nm248',\n",
       " 'nm46n',\n",
       " 'nmw46',\n",
       " 'nmy2x',\n",
       " 'nn4wx',\n",
       " 'nn6mg',\n",
       " 'nn6w6',\n",
       " 'nnf8b',\n",
       " 'nnfx3',\n",
       " 'nngxc',\n",
       " 'nnn57',\n",
       " 'nnn5p',\n",
       " 'nnp4e',\n",
       " 'nny5e',\n",
       " 'npxb7',\n",
       " 'nw5b2',\n",
       " 'nwfde',\n",
       " 'nwg2m',\n",
       " 'nwncn',\n",
       " 'nxc83',\n",
       " 'nxcmn',\n",
       " 'nxf2c',\n",
       " 'nxn4f',\n",
       " 'nxx25',\n",
       " 'nxxf8',\n",
       " 'ny3dw',\n",
       " 'ny3nn',\n",
       " 'ny5dp',\n",
       " 'ny8np',\n",
       " 'nybcx',\n",
       " 'p24gn',\n",
       " 'p2dw7',\n",
       " 'p2m6n',\n",
       " 'p2x7x',\n",
       " 'p2ym2',\n",
       " 'p4nm4',\n",
       " 'p4pde',\n",
       " 'p57fn',\n",
       " 'p5g5m',\n",
       " 'p5nce',\n",
       " 'p6mn8',\n",
       " 'p7fyp',\n",
       " 'p8c24',\n",
       " 'p8ngx',\n",
       " 'p8wwf',\n",
       " 'pbpgc',\n",
       " 'pcede',\n",
       " 'pcm7f',\n",
       " 'pcmcc',\n",
       " 'pcpg6',\n",
       " 'pdcp4',\n",
       " 'pdw38',\n",
       " 'pdyc8',\n",
       " 'pe4xn',\n",
       " 'pf4nb',\n",
       " 'pf5ng',\n",
       " 'pg2pm',\n",
       " 'pg2yx',\n",
       " 'pg4bf',\n",
       " 'pgg3n',\n",
       " 'pgm2e',\n",
       " 'pgmn2',\n",
       " 'pgwnp',\n",
       " 'pm363',\n",
       " 'pm47f',\n",
       " 'pmd3w',\n",
       " 'pme86',\n",
       " 'pmf5w',\n",
       " 'pmg55',\n",
       " 'pn7pn',\n",
       " 'pnmxf',\n",
       " 'pnnwy',\n",
       " 'pp546',\n",
       " 'pp87n',\n",
       " 'ppwyd',\n",
       " 'ppx77',\n",
       " 'pw5nc',\n",
       " 'pwebm',\n",
       " 'pwmbn',\n",
       " 'pwn5e',\n",
       " 'px2xp',\n",
       " 'px8n8',\n",
       " 'pxdwp',\n",
       " 'pxne8',\n",
       " 'pybee',\n",
       " 'pyefb',\n",
       " 'pyf65',\n",
       " 'pym7p',\n",
       " 'w2e87',\n",
       " 'w2n7e',\n",
       " 'w2yp7',\n",
       " 'w46ep',\n",
       " 'w48cw',\n",
       " 'w4cdc',\n",
       " 'w4cnn',\n",
       " 'w4nfx',\n",
       " 'w4x2m',\n",
       " 'w52fn',\n",
       " 'w6ny4',\n",
       " 'w6pxy',\n",
       " 'w6yne',\n",
       " 'w75w8',\n",
       " 'w7e6m',\n",
       " 'w8bnx',\n",
       " 'w8f36',\n",
       " 'wb3ed',\n",
       " 'wbncw',\n",
       " 'wc2bd',\n",
       " 'wce5n',\n",
       " 'wd2gb',\n",
       " 'wddcp',\n",
       " 'wdww8',\n",
       " 'wecfd',\n",
       " 'wf684',\n",
       " 'wfy5m',\n",
       " 'wg625',\n",
       " 'wgnwp',\n",
       " 'wm47f',\n",
       " 'wm746',\n",
       " 'wmpmp',\n",
       " 'wnmyn',\n",
       " 'wnpec',\n",
       " 'wwmn6',\n",
       " 'wxcn8',\n",
       " 'wxy4n',\n",
       " 'wyc25',\n",
       " 'wye85',\n",
       " 'x277e',\n",
       " 'x2cnn',\n",
       " 'x347n',\n",
       " 'x362g',\n",
       " 'x37bf',\n",
       " 'x38fn',\n",
       " 'x3deb',\n",
       " 'x3fwf',\n",
       " 'x44n4',\n",
       " 'x458w',\n",
       " 'x4f7g',\n",
       " 'x4gg5',\n",
       " 'x4pnp',\n",
       " 'x5f54',\n",
       " 'x5nyn',\n",
       " 'x6b5m',\n",
       " 'x6pdb',\n",
       " 'x7422',\n",
       " 'x74b2',\n",
       " 'x7547',\n",
       " 'x76mn',\n",
       " 'x7746',\n",
       " 'x775w',\n",
       " 'x8e8n',\n",
       " 'x8xnp',\n",
       " 'xbcbx',\n",
       " 'xbem6',\n",
       " 'xc68n',\n",
       " 'xce8d',\n",
       " 'xcf88',\n",
       " 'xcmbp',\n",
       " 'xdcn4',\n",
       " 'xdn65',\n",
       " 'xe6eb',\n",
       " 'xe8xm',\n",
       " 'xemyg',\n",
       " 'xf4p4',\n",
       " 'xf5g7',\n",
       " ...]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if all captcha has length of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(len(text)==5 for text in texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finsing the distinct characters from all the captch : Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2345678bcdefgmnpwxy'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = list(frozenset(chain.from_iterable(texts)))\n",
    "alphabet.sort()\n",
    "''.join(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finsing the distinct characters from all the captch: Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryset = ()\n",
    "tryset = set(tryset)\n",
    "for text in texts:\n",
    "    for i in text:\n",
    "        tryset.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryset = sorted(''.join(tryset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryset = ''.join(tryset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2345678bcdefgmnpwxy'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign a unique integer id label for each character in the alphabet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids =  dict([(ch, tryset.index(ch)) for ch in tryset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 0,\n",
       " '3': 1,\n",
       " '4': 2,\n",
       " '5': 3,\n",
       " '6': 4,\n",
       " '7': 5,\n",
       " '8': 6,\n",
       " 'b': 7,\n",
       " 'c': 8,\n",
       " 'd': 9,\n",
       " 'e': 10,\n",
       " 'f': 11,\n",
       " 'g': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'p': 15,\n",
       " 'w': 16,\n",
       " 'x': 17,\n",
       " 'y': 18}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we are going to to create a 2D array ('y_labels') of size num images (n) x captcha text size (m)\n",
    "\n",
    "Where the element ylji\n",
    "its the integer label for the jth character on the ith captcha image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = len(texts),5\n",
    "y_labels = np.zeros([n, m], dtype=np.uint8)\n",
    "images[9]\n",
    "y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels[156][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  1, 13, 13], dtype=uint8)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,j in product(range(0,n), range(0,m)):\n",
    "    y_labels[i][j] = ids[texts[i][j]]\n",
    "y_labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we turn y_labels to a 3D matrix ('y') of size num images x text size x alphabet size.\n",
    "yji\n",
    "\n",
    "(y[i, j, :]) is a sparse vector filled by zeros except the element at kth position where k is the integer label of the jth character on the ith captcha image\n",
    "\n",
    "yji=[ylj,0iylj,1iylj,2i...ylj,si]=[00...1...00]\n",
    "\n",
    "s\n",
    "is the alphabet size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros([n, m, len(alphabet)], dtype=np.uint8)\n",
    "for i, j in product(range(0,n),range(0,m)):\n",
    "    y[i,j,:] = to_categorical(y_labels[i,j], len(tryset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 5, 19)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to store all the images (grayscaled) in a 4D matrix of size: num images x image height x image width x 1 with float32 dtype with values in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((n,) + (50, 200, 1))\n",
    "for i, filename in zip(range(0, n), images):\n",
    "    img = cv2.imread(os.path.join('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/samples/' + filename), cv2.IMREAD_GRAYSCALE)\n",
    "    assert img.shape == (50, 200)\n",
    "    X[i, :, :, 0] = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[10, :, :, 0], cmap='gray'), plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[192, 192, 192, ..., 251, 251, 251],\n",
       "       [192, 192, 192, ..., 251, 251, 251],\n",
       "       [192, 192, 192, ..., 251, 251, 251],\n",
       "       ...,\n",
       "       [195, 195, 195, ..., 254, 254, 254],\n",
       "       [195, 195, 195, ..., 254, 254, 254],\n",
       "       [195, 195, 195, ..., 254, 254, 254]], dtype=uint8)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('preprocessed-data.npz', X=X, y=y, y_labels=y_labels, alphabet=alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data After Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('C:/Users/ankur/Downloads/Kaggle Notebooks/preprocessed-data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_labels, y = data['X'], data['y_labels'], data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  4, 13,  9],\n",
       "       [ 0,  0,  9,  3, 14],\n",
       "       [ 0,  1,  3,  4, 12],\n",
       "       ...,\n",
       "       [18, 18,  6,  0,  2],\n",
       "       [18, 18, 12,  3, 12],\n",
       "       [18, 18, 14,  3,  5]], dtype=uint8)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  4, 13,  9], dtype=uint8)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 9, 8], dtype=uint8)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A : CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 50, 200, 1)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 5)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1070, 19)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1070, 19)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.reshape(y,(5,1070,19))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:970], y[:, :970]\n",
    "X_test, y_test = X[970:], y[:,970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 50, 200, 1)\n",
      "(100, 50, 200, 1)\n",
      "(5, 970, 19)\n",
      "(5, 100, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/samples'))\n",
    "    print(n_samples)\n",
    "    X = np.zeros((n_samples, 50, 200, 1)) #1070*50*200\n",
    "    y = np.zeros((5, n_samples, num_symbols)) #5*1070*36\n",
    "\n",
    "    for i, pic in enumerate(os.listdir('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/samples')):\n",
    "        # Read image as grayscale\n",
    "        img = cv2.imread(os.path.join('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/samples', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        pic_target = pic[:-4]\n",
    "        if len(pic_target) < 6:\n",
    "            # Scale and reshape image\n",
    "            img = img / 255.0\n",
    "            img = np.reshape(img, (50, 200, 1))\n",
    "            # Define targets and code them using OneHotEncoding\n",
    "            targs = np.zeros((5, num_symbols))\n",
    "            for j, l in enumerate(pic_target):\n",
    "                ind = tryset.find(l)\n",
    "                targs[j, ind] = 1\n",
    "            X[i] = img\n",
    "            y[:, i] = targs\n",
    "    \n",
    "    # Return final data\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data()\n",
    "X_train, y_train = X[:970], y[:, :970]\n",
    "X_test, y_test = X[970:], y[:, 970:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 50, 200, 16)  160         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 50, 32)   128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 5600)         0           max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 64)           358464      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 64)           358464      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 64)           358464      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 64)           358464      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 64)           358464      flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 64)           0           dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 64)           0           dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 64)           0           dense_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 64)           0           dense_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 64)           0           dense_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 19)           1235        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 19)           1235        dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 19)           1235        dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 19)           1235        dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 19)           1235        dropout_69[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=create_model();\n",
    "model.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 14.9638 - dense_131_loss: 2.9125 - dense_133_loss: 3.0201 - dense_135_loss: 3.0073 - dense_137_loss: 3.0180 - dense_139_loss: 2.9953 - dense_131_accuracy: 0.0838 - dense_133_accuracy: 0.0683 - dense_135_accuracy: 0.0683 - dense_137_accuracy: 0.0747 - dense_139_accuracy: 0.0567 - val_loss: 14.8874 - val_dense_131_loss: 3.1158 - val_dense_133_loss: 2.9487 - val_dense_135_loss: 2.9392 - val_dense_137_loss: 2.9463 - val_dense_139_loss: 2.9527 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.0773 - val_dense_135_accuracy: 0.0670 - val_dense_137_accuracy: 0.0361 - val_dense_139_accuracy: 0.0567\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.3541 - dense_131_loss: 2.7178 - dense_133_loss: 2.8668 - dense_135_loss: 2.9158 - dense_137_loss: 2.9154 - dense_139_loss: 2.9257 - dense_131_accuracy: 0.0979 - dense_133_accuracy: 0.0966 - dense_135_accuracy: 0.0902 - dense_137_accuracy: 0.0941 - dense_139_accuracy: 0.0825 - val_loss: 14.8145 - val_dense_131_loss: 3.0640 - val_dense_133_loss: 2.9373 - val_dense_135_loss: 2.9409 - val_dense_137_loss: 2.9389 - val_dense_139_loss: 2.9487 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.1082 - val_dense_135_accuracy: 0.0567 - val_dense_137_accuracy: 0.0928 - val_dense_139_accuracy: 0.0567\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.7440 - dense_131_loss: 2.5095 - dense_133_loss: 2.7004 - dense_135_loss: 2.7863 - dense_137_loss: 2.8567 - dense_139_loss: 2.8797 - dense_131_accuracy: 0.1688 - dense_133_accuracy: 0.1379 - dense_135_accuracy: 0.1237 - dense_137_accuracy: 0.0979 - dense_139_accuracy: 0.1057 - val_loss: 14.7797 - val_dense_131_loss: 3.0883 - val_dense_133_loss: 2.9100 - val_dense_135_loss: 2.9270 - val_dense_137_loss: 2.9314 - val_dense_139_loss: 2.9358 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.1443 - val_dense_135_accuracy: 0.1082 - val_dense_137_accuracy: 0.0979 - val_dense_139_accuracy: 0.1443\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 13.2138 - dense_131_loss: 2.3657 - dense_133_loss: 2.5429 - dense_135_loss: 2.6668 - dense_137_loss: 2.8140 - dense_139_loss: 2.8205 - dense_131_accuracy: 0.1972 - dense_133_accuracy: 0.2023 - dense_135_accuracy: 0.1881 - dense_137_accuracy: 0.1160 - dense_139_accuracy: 0.1070 - val_loss: 14.7877 - val_dense_131_loss: 3.1527 - val_dense_133_loss: 2.8888 - val_dense_135_loss: 2.9016 - val_dense_137_loss: 2.9327 - val_dense_139_loss: 2.9319 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.1340 - val_dense_135_accuracy: 0.1753 - val_dense_137_accuracy: 0.0670 - val_dense_139_accuracy: 0.1134\n",
      "Epoch 5/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 12.6006 - dense_131_loss: 2.1918 - dense_133_loss: 2.4270 - dense_135_loss: 2.5178 - dense_137_loss: 2.7028 - dense_139_loss: 2.7392 - dense_131_accuracy: 0.2603 - dense_133_accuracy: 0.2320 - dense_135_accuracy: 0.1933 - dense_137_accuracy: 0.1302 - dense_139_accuracy: 0.1211 - val_loss: 14.6142 - val_dense_131_loss: 3.1523 - val_dense_133_loss: 2.8027 - val_dense_135_loss: 2.8596 - val_dense_137_loss: 2.8933 - val_dense_139_loss: 2.9149 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.2990 - val_dense_135_accuracy: 0.1907 - val_dense_137_accuracy: 0.1186 - val_dense_139_accuracy: 0.1186\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 11.9043 - dense_131_loss: 1.9671 - dense_133_loss: 2.2308 - dense_135_loss: 2.4335 - dense_137_loss: 2.6058 - dense_139_loss: 2.6472 - dense_131_accuracy: 0.3363 - dense_133_accuracy: 0.2255 - dense_135_accuracy: 0.2294 - dense_137_accuracy: 0.1482 - dense_139_accuracy: 0.1521 - val_loss: 14.4946 - val_dense_131_loss: 3.1566 - val_dense_133_loss: 2.7341 - val_dense_135_loss: 2.8391 - val_dense_137_loss: 2.8477 - val_dense_139_loss: 2.8771 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.2062 - val_dense_135_accuracy: 0.2474 - val_dense_137_accuracy: 0.1598 - val_dense_139_accuracy: 0.1546\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 11.1174 - dense_131_loss: 1.6710 - dense_133_loss: 2.1343 - dense_135_loss: 2.2776 - dense_137_loss: 2.4877 - dense_139_loss: 2.5057 - dense_131_accuracy: 0.4523 - dense_133_accuracy: 0.2693 - dense_135_accuracy: 0.2423 - dense_137_accuracy: 0.1765 - dense_139_accuracy: 0.1894 - val_loss: 14.2271 - val_dense_131_loss: 3.2072 - val_dense_133_loss: 2.6418 - val_dense_135_loss: 2.7696 - val_dense_137_loss: 2.8058 - val_dense_139_loss: 2.8460 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.3454 - val_dense_135_accuracy: 0.2680 - val_dense_137_accuracy: 0.2474 - val_dense_139_accuracy: 0.1856\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 10.1973 - dense_131_loss: 1.4026 - dense_133_loss: 1.9021 - dense_135_loss: 2.1481 - dense_137_loss: 2.3512 - dense_139_loss: 2.4080 - dense_131_accuracy: 0.5412 - dense_133_accuracy: 0.3479 - dense_135_accuracy: 0.2577 - dense_137_accuracy: 0.1830 - dense_139_accuracy: 0.2113 - val_loss: 14.1022 - val_dense_131_loss: 3.2106 - val_dense_133_loss: 2.5857 - val_dense_135_loss: 2.7224 - val_dense_137_loss: 2.7719 - val_dense_139_loss: 2.8123 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.4278 - val_dense_135_accuracy: 0.3918 - val_dense_137_accuracy: 0.1495 - val_dense_139_accuracy: 0.2938\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 9.3801 - dense_131_loss: 1.0738 - dense_133_loss: 1.8156 - dense_135_loss: 1.9416 - dense_137_loss: 2.2724 - dense_139_loss: 2.2884 - dense_131_accuracy: 0.6688 - dense_133_accuracy: 0.4175 - dense_135_accuracy: 0.3492 - dense_137_accuracy: 0.2229 - dense_139_accuracy: 0.2719 - val_loss: 13.8231 - val_dense_131_loss: 3.5047 - val_dense_133_loss: 2.3203 - val_dense_135_loss: 2.5025 - val_dense_137_loss: 2.6941 - val_dense_139_loss: 2.7149 - val_dense_131_accuracy: 0.0052 - val_dense_133_accuracy: 0.4433 - val_dense_135_accuracy: 0.3814 - val_dense_137_accuracy: 0.2680 - val_dense_139_accuracy: 0.3402\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 8.3888 - dense_131_loss: 0.7993 - dense_133_loss: 1.5911 - dense_135_loss: 1.7699 - dense_137_loss: 2.0859 - dense_139_loss: 2.1448 - dense_131_accuracy: 0.7487 - dense_133_accuracy: 0.4562 - dense_135_accuracy: 0.4021 - dense_137_accuracy: 0.2616 - dense_139_accuracy: 0.2668 - val_loss: 13.4208 - val_dense_131_loss: 3.4066 - val_dense_133_loss: 2.2984 - val_dense_135_loss: 2.4719 - val_dense_137_loss: 2.6297 - val_dense_139_loss: 2.6683 - val_dense_131_accuracy: 0.0000e+00 - val_dense_133_accuracy: 0.5052 - val_dense_135_accuracy: 0.4742 - val_dense_137_accuracy: 0.3299 - val_dense_139_accuracy: 0.3351\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 7.8043 - dense_131_loss: 0.6870 - dense_133_loss: 1.4246 - dense_135_loss: 1.6301 - dense_137_loss: 2.0101 - dense_139_loss: 2.0235 - dense_131_accuracy: 0.7874 - dense_133_accuracy: 0.5271 - dense_135_accuracy: 0.4575 - dense_137_accuracy: 0.2990 - dense_139_accuracy: 0.3157 - val_loss: 12.8862 - val_dense_131_loss: 3.6393 - val_dense_133_loss: 2.0508 - val_dense_135_loss: 2.2614 - val_dense_137_loss: 2.4647 - val_dense_139_loss: 2.5370 - val_dense_131_accuracy: 0.0567 - val_dense_133_accuracy: 0.7113 - val_dense_135_accuracy: 0.6134 - val_dense_137_accuracy: 0.3866 - val_dense_139_accuracy: 0.4072\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 6.9284 - dense_131_loss: 0.5953 - dense_133_loss: 1.2298 - dense_135_loss: 1.4726 - dense_137_loss: 1.7555 - dense_139_loss: 1.8480 - dense_131_accuracy: 0.7925 - dense_133_accuracy: 0.6031 - dense_135_accuracy: 0.5026 - dense_137_accuracy: 0.4201 - dense_139_accuracy: 0.3982 - val_loss: 12.4314 - val_dense_131_loss: 3.9501 - val_dense_133_loss: 1.9576 - val_dense_135_loss: 2.0658 - val_dense_137_loss: 2.2380 - val_dense_139_loss: 2.3659 - val_dense_131_accuracy: 0.0103 - val_dense_133_accuracy: 0.7010 - val_dense_135_accuracy: 0.5876 - val_dense_137_accuracy: 0.4588 - val_dense_139_accuracy: 0.5052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 6.0909 - dense_131_loss: 0.4762 - dense_133_loss: 1.0921 - dense_135_loss: 1.2718 - dense_137_loss: 1.6236 - dense_139_loss: 1.6343 - dense_131_accuracy: 0.8389 - dense_133_accuracy: 0.6469 - dense_135_accuracy: 0.5683 - dense_137_accuracy: 0.4665 - dense_139_accuracy: 0.4201 - val_loss: 12.0120 - val_dense_131_loss: 4.3907 - val_dense_133_loss: 1.6690 - val_dense_135_loss: 1.7638 - val_dense_137_loss: 2.0697 - val_dense_139_loss: 2.2013 - val_dense_131_accuracy: 0.0103 - val_dense_133_accuracy: 0.7680 - val_dense_135_accuracy: 0.6907 - val_dense_137_accuracy: 0.5361 - val_dense_139_accuracy: 0.5928\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 5.3653 - dense_131_loss: 0.4042 - dense_133_loss: 0.9061 - dense_135_loss: 1.1115 - dense_137_loss: 1.4492 - dense_139_loss: 1.4526 - dense_131_accuracy: 0.8621 - dense_133_accuracy: 0.7010 - dense_135_accuracy: 0.5941 - dense_137_accuracy: 0.5219 - dense_139_accuracy: 0.5013 - val_loss: 11.4573 - val_dense_131_loss: 5.0579 - val_dense_133_loss: 1.1991 - val_dense_135_loss: 1.5459 - val_dense_137_loss: 1.8496 - val_dense_139_loss: 1.8439 - val_dense_131_accuracy: 0.0155 - val_dense_133_accuracy: 0.8041 - val_dense_135_accuracy: 0.6649 - val_dense_137_accuracy: 0.6340 - val_dense_139_accuracy: 0.6289\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 4.8460 - dense_131_loss: 0.3475 - dense_133_loss: 0.8700 - dense_135_loss: 1.0410 - dense_137_loss: 1.2904 - dense_139_loss: 1.2850 - dense_131_accuracy: 0.8776 - dense_133_accuracy: 0.6946 - dense_135_accuracy: 0.6418 - dense_137_accuracy: 0.5528 - dense_139_accuracy: 0.5438 - val_loss: 10.9925 - val_dense_131_loss: 4.9976 - val_dense_133_loss: 1.0795 - val_dense_135_loss: 1.5295 - val_dense_137_loss: 1.7835 - val_dense_139_loss: 1.7183 - val_dense_131_accuracy: 0.0155 - val_dense_133_accuracy: 0.7887 - val_dense_135_accuracy: 0.7113 - val_dense_137_accuracy: 0.6856 - val_dense_139_accuracy: 0.6804\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 4.3368 - dense_131_loss: 0.3533 - dense_133_loss: 0.6506 - dense_135_loss: 0.9096 - dense_137_loss: 1.2068 - dense_139_loss: 1.2076 - dense_131_accuracy: 0.8776 - dense_133_accuracy: 0.7732 - dense_135_accuracy: 0.6521 - dense_137_accuracy: 0.5812 - dense_139_accuracy: 0.5503 - val_loss: 10.5649 - val_dense_131_loss: 5.2475 - val_dense_133_loss: 0.9234 - val_dense_135_loss: 1.3309 - val_dense_137_loss: 1.4806 - val_dense_139_loss: 1.6278 - val_dense_131_accuracy: 0.0052 - val_dense_133_accuracy: 0.8247 - val_dense_135_accuracy: 0.7268 - val_dense_137_accuracy: 0.6959 - val_dense_139_accuracy: 0.7165\n",
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.8624 - dense_131_loss: 0.2913 - dense_133_loss: 0.6578 - dense_135_loss: 0.8270 - dense_137_loss: 1.0478 - dense_139_loss: 1.0710 - dense_131_accuracy: 0.9098 - dense_133_accuracy: 0.7835 - dense_135_accuracy: 0.7088 - dense_137_accuracy: 0.6263 - dense_139_accuracy: 0.6211 - val_loss: 9.9702 - val_dense_131_loss: 5.4141 - val_dense_133_loss: 0.7779 - val_dense_135_loss: 1.0295 - val_dense_137_loss: 1.3439 - val_dense_139_loss: 1.2961 - val_dense_131_accuracy: 0.0464 - val_dense_133_accuracy: 0.8144 - val_dense_135_accuracy: 0.7371 - val_dense_137_accuracy: 0.6649 - val_dense_139_accuracy: 0.7320\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.5000 - dense_131_loss: 0.2778 - dense_133_loss: 0.5726 - dense_135_loss: 0.7577 - dense_137_loss: 0.9439 - dense_139_loss: 0.9550 - dense_131_accuracy: 0.9008 - dense_133_accuracy: 0.8003 - dense_135_accuracy: 0.7281 - dense_137_accuracy: 0.6778 - dense_139_accuracy: 0.6443 - val_loss: 9.9990 - val_dense_131_loss: 6.0435 - val_dense_133_loss: 0.6204 - val_dense_135_loss: 1.0442 - val_dense_137_loss: 1.2839 - val_dense_139_loss: 1.1081 - val_dense_131_accuracy: 0.0206 - val_dense_133_accuracy: 0.8454 - val_dense_135_accuracy: 0.7526 - val_dense_137_accuracy: 0.6856 - val_dense_139_accuracy: 0.7887\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.1464 - dense_131_loss: 0.2937 - dense_133_loss: 0.4814 - dense_135_loss: 0.7612 - dense_137_loss: 0.8191 - dense_139_loss: 0.7988 - dense_131_accuracy: 0.9021 - dense_133_accuracy: 0.8235 - dense_135_accuracy: 0.7448 - dense_137_accuracy: 0.7010 - dense_139_accuracy: 0.6920 - val_loss: 10.7600 - val_dense_131_loss: 7.3973 - val_dense_133_loss: 0.5856 - val_dense_135_loss: 0.8945 - val_dense_137_loss: 0.9008 - val_dense_139_loss: 0.9654 - val_dense_131_accuracy: 0.0052 - val_dense_133_accuracy: 0.8402 - val_dense_135_accuracy: 0.7577 - val_dense_137_accuracy: 0.8093 - val_dense_139_accuracy: 0.7784\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.0087 - dense_131_loss: 0.2043 - dense_133_loss: 0.4798 - dense_135_loss: 0.7078 - dense_137_loss: 0.8290 - dense_139_loss: 0.7757 - dense_131_accuracy: 0.9317 - dense_133_accuracy: 0.8428 - dense_135_accuracy: 0.7564 - dense_137_accuracy: 0.6959 - dense_139_accuracy: 0.7216 - val_loss: 10.3649 - val_dense_131_loss: 7.1545 - val_dense_133_loss: 0.5719 - val_dense_135_loss: 0.8050 - val_dense_137_loss: 0.8997 - val_dense_139_loss: 1.0334 - val_dense_131_accuracy: 0.0309 - val_dense_133_accuracy: 0.8505 - val_dense_135_accuracy: 0.7835 - val_dense_137_accuracy: 0.7577 - val_dense_139_accuracy: 0.7732\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.6521 - dense_131_loss: 0.2051 - dense_133_loss: 0.4233 - dense_135_loss: 0.6012 - dense_137_loss: 0.7179 - dense_139_loss: 0.7041 - dense_131_accuracy: 0.9343 - dense_133_accuracy: 0.8544 - dense_135_accuracy: 0.7887 - dense_137_accuracy: 0.7371 - dense_139_accuracy: 0.7423 - val_loss: 11.9218 - val_dense_131_loss: 8.7433 - val_dense_133_loss: 0.5930 - val_dense_135_loss: 0.8166 - val_dense_137_loss: 1.0150 - val_dense_139_loss: 0.6617 - val_dense_131_accuracy: 0.0258 - val_dense_133_accuracy: 0.8351 - val_dense_135_accuracy: 0.7165 - val_dense_137_accuracy: 0.7216 - val_dense_139_accuracy: 0.7990\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.5244 - dense_131_loss: 0.1853 - dense_133_loss: 0.3814 - dense_135_loss: 0.6032 - dense_137_loss: 0.6982 - dense_139_loss: 0.6587 - dense_131_accuracy: 0.9407 - dense_133_accuracy: 0.8621 - dense_135_accuracy: 0.7938 - dense_137_accuracy: 0.7358 - dense_139_accuracy: 0.7552 - val_loss: 11.5292 - val_dense_131_loss: 9.0416 - val_dense_133_loss: 0.5767 - val_dense_135_loss: 0.6189 - val_dense_137_loss: 0.7486 - val_dense_139_loss: 0.6140 - val_dense_131_accuracy: 0.0103 - val_dense_133_accuracy: 0.8299 - val_dense_135_accuracy: 0.8041 - val_dense_137_accuracy: 0.7835 - val_dense_139_accuracy: 0.8351nse_133_loss: 0.3503 - dense_135_loss: 0.6025 - dense_137_loss: 0.6909 - dense_139_loss: 0.6386 - dense_131_accuracy: 0.9410 - dense_133_accuracy: 0.8785 - dense_135_accuracy: 0.7847 - dense_137_accuracy: 0.7431 - dense_139_accuracy:\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 2.3098 - dense_131_loss: 0.1585 - dense_133_loss: 0.3925 - dense_135_loss: 0.5070 - dense_137_loss: 0.5829 - dense_139_loss: 0.6599 - dense_131_accuracy: 0.9446 - dense_133_accuracy: 0.8570 - dense_135_accuracy: 0.8338 - dense_137_accuracy: 0.7938 - dense_139_accuracy: 0.7358 - val_loss: 12.5461 - val_dense_131_loss: 10.1119 - val_dense_133_loss: 0.6351 - val_dense_135_loss: 0.6418 - val_dense_137_loss: 0.7485 - val_dense_139_loss: 0.6644 - val_dense_131_accuracy: 0.0309 - val_dense_133_accuracy: 0.8557 - val_dense_135_accuracy: 0.8351 - val_dense_137_accuracy: 0.7887 - val_dense_139_accuracy: 0.8093\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 2.1541 - dense_131_loss: 0.1580 - dense_133_loss: 0.3354 - dense_135_loss: 0.4372 - dense_137_loss: 0.6429 - dense_139_loss: 0.5870 - dense_131_accuracy: 0.9485 - dense_133_accuracy: 0.8737 - dense_135_accuracy: 0.8338 - dense_137_accuracy: 0.7655 - dense_139_accuracy: 0.7835 - val_loss: 13.1314 - val_dense_131_loss: 10.5157 - val_dense_133_loss: 0.6046 - val_dense_135_loss: 0.7021 - val_dense_137_loss: 0.8132 - val_dense_139_loss: 0.7263 - val_dense_131_accuracy: 0.0052 - val_dense_133_accuracy: 0.8351 - val_dense_135_accuracy: 0.7887 - val_dense_137_accuracy: 0.7680 - val_dense_139_accuracy: 0.8144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.0039 - dense_131_loss: 0.1276 - dense_133_loss: 0.3629 - dense_135_loss: 0.4342 - dense_137_loss: 0.5707 - dense_139_loss: 0.5205 - dense_131_accuracy: 0.9562 - dense_133_accuracy: 0.8711 - dense_135_accuracy: 0.8724 - dense_137_accuracy: 0.8170 - dense_139_accuracy: 0.8157 - val_loss: 13.0380 - val_dense_131_loss: 10.4719 - val_dense_133_loss: 0.6515 - val_dense_135_loss: 0.6713 - val_dense_137_loss: 0.7578 - val_dense_139_loss: 0.6590 - val_dense_131_accuracy: 0.0206 - val_dense_133_accuracy: 0.8608 - val_dense_135_accuracy: 0.7887 - val_dense_137_accuracy: 0.7990 - val_dense_139_accuracy: 0.8144\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 2.0120 - dense_131_loss: 0.1486 - dense_133_loss: 0.3166 - dense_135_loss: 0.4134 - dense_137_loss: 0.6022 - dense_139_loss: 0.5319 - dense_131_accuracy: 0.9433 - dense_133_accuracy: 0.8905 - dense_135_accuracy: 0.8492 - dense_137_accuracy: 0.7861 - dense_139_accuracy: 0.7925 - val_loss: 12.5623 - val_dense_131_loss: 10.2737 - val_dense_133_loss: 0.6731 - val_dense_135_loss: 0.6227 - val_dense_137_loss: 0.7601 - val_dense_139_loss: 0.4902 - val_dense_131_accuracy: 0.0464 - val_dense_133_accuracy: 0.8505 - val_dense_135_accuracy: 0.7887 - val_dense_137_accuracy: 0.8093 - val_dense_139_accuracy: 0.8351\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.8974 - dense_131_loss: 0.1252 - dense_133_loss: 0.2749 - dense_135_loss: 0.4197 - dense_137_loss: 0.5792 - dense_139_loss: 0.5059 - dense_131_accuracy: 0.9472 - dense_133_accuracy: 0.8943 - dense_135_accuracy: 0.8454 - dense_137_accuracy: 0.7848 - dense_139_accuracy: 0.8144 - val_loss: 13.9715 - val_dense_131_loss: 11.5963 - val_dense_133_loss: 0.6494 - val_dense_135_loss: 0.7506 - val_dense_137_loss: 0.8301 - val_dense_139_loss: 0.4908 - val_dense_131_accuracy: 0.0258 - val_dense_133_accuracy: 0.8660 - val_dense_135_accuracy: 0.7938 - val_dense_137_accuracy: 0.7990 - val_dense_139_accuracy: 0.8247\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.7376 - dense_131_loss: 0.1372 - dense_133_loss: 0.2526 - dense_135_loss: 0.3214 - dense_137_loss: 0.5416 - dense_139_loss: 0.4883 - dense_131_accuracy: 0.9420 - dense_133_accuracy: 0.8982 - dense_135_accuracy: 0.8724 - dense_137_accuracy: 0.7887 - dense_139_accuracy: 0.8325 - val_loss: 12.4226 - val_dense_131_loss: 10.4875 - val_dense_133_loss: 0.6436 - val_dense_135_loss: 0.6471 - val_dense_137_loss: 0.6580 - val_dense_139_loss: 0.5466 - val_dense_131_accuracy: 0.0567 - val_dense_133_accuracy: 0.8711 - val_dense_135_accuracy: 0.7887 - val_dense_137_accuracy: 0.8041 - val_dense_139_accuracy: 0.8402\n",
      "Epoch 29/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.7067 - dense_131_loss: 0.1538 - dense_133_loss: 0.2515 - dense_135_loss: 0.3391 - dense_137_loss: 0.5398 - dense_139_loss: 0.4495 - dense_131_accuracy: 0.9407 - dense_133_accuracy: 0.9034 - dense_135_accuracy: 0.8750 - dense_137_accuracy: 0.7925 - dense_139_accuracy: 0.8351 - val_loss: 14.4251 - val_dense_131_loss: 11.6669 - val_dense_133_loss: 0.6966 - val_dense_135_loss: 0.8677 - val_dense_137_loss: 0.9362 - val_dense_139_loss: 0.5179 - val_dense_131_accuracy: 0.0309 - val_dense_133_accuracy: 0.8557 - val_dense_135_accuracy: 0.7887 - val_dense_137_accuracy: 0.8041 - val_dense_139_accuracy: 0.8351\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.5520 - dense_131_loss: 0.1506 - dense_133_loss: 0.2624 - dense_135_loss: 0.3284 - dense_137_loss: 0.4268 - dense_139_loss: 0.3993 - dense_131_accuracy: 0.9536 - dense_133_accuracy: 0.9162 - dense_135_accuracy: 0.8802 - dense_137_accuracy: 0.8312 - dense_139_accuracy: 0.8454 - val_loss: 13.0386 - val_dense_131_loss: 10.8169 - val_dense_133_loss: 0.6443 - val_dense_135_loss: 0.6793 - val_dense_137_loss: 0.8016 - val_dense_139_loss: 0.5452 - val_dense_131_accuracy: 0.0722 - val_dense_133_accuracy: 0.8402 - val_dense_135_accuracy: 0.8144 - val_dense_137_accuracy: 0.8041 - val_dense_139_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to predict captcha\n",
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = img / 255.0\n",
    "    else:\n",
    "        print(\"Not detected\");\n",
    "    res = np.array(model.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 19))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        #probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += tryset[l]\n",
    "    return capt#, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 17.3807 - dense_131_loss: 15.9427 - dense_133_loss: 0.1229 - dense_135_loss: 0.4435 - dense_137_loss: 0.8603 - dense_139_loss: 0.3068 - dense_131_accuracy: 0.0000e+00 - dense_133_accuracy: 0.9700 - dense_135_accuracy: 0.8500 - dense_137_accuracy: 0.8300 - dense_139_accuracy: 0.8800\n",
      "Test Loss and accuracy: [17.906119079589843, 15.942744, 0.12290828, 0.4435117, 0.86025214, 0.3068247, 0.0, 0.97, 0.85, 0.83, 0.88]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(X_test,[y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]],verbose=1)\n",
    "print('Test Loss and accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 17.3807 - dense_131_loss: 15.9427 - dense_133_loss: 0.1229 - dense_135_loss: 0.4435 - dense_137_loss: 0.8603 - dense_139_loss: 0.3068 - dense_131_accuracy: 0.0000e+00 - dense_133_accuracy: 0.9700 - dense_135_accuracy: 0.8500 - dense_137_accuracy: 0.8300 - dense_139_accuracy: 0.8800\n",
      "8n5p3\n",
      "f2m8n\n",
      "dce8y\n",
      "3eny7\n",
      "mpxb7\n"
     ]
    }
   ],
   "source": [
    "# Check model on some samples\n",
    "model.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]])\n",
    "print(predict('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/8n5p3.png'))\n",
    "print(predict('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/f2m8n.png'))\n",
    "print(predict('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/dce8y.png'))\n",
    "print(predict('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/3eny7.png'))\n",
    "print(predict('C:/Users/ankur/Downloads/Kaggle Notebooks/captcha-version-2-images/samples/npxb7.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Relu and Softmax Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def act_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation=LeakyReLU(alpha=0.1))(img)\n",
    "    #model.add(LeakyReLU(alpha=0.05))\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation=LeakyReLU(alpha=0.1))(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation=LeakyReLU(alpha=0.1))(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation=LeakyReLU(alpha=0.1))(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 50, 200, 16)  160         input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 50, 32)   128         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 5600)         0           max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 64)           358464      flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 64)           358464      flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_164 (Dense)               (None, 64)           358464      flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_166 (Dense)               (None, 64)           358464      flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_168 (Dense)               (None, 64)           358464      flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 64)           0           dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 64)           0           dense_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 64)           0           dense_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 64)           0           dense_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 64)           0           dense_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 19)           1235        dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 19)           1235        dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_165 (Dense)               (None, 19)           1235        dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_167 (Dense)               (None, 19)           1235        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_169 (Dense)               (None, 19)           1235        dropout_84[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 8s 11ms/sample - loss: 15.2310 - dense_161_loss: 2.9221 - dense_163_loss: 3.0748 - dense_165_loss: 3.0150 - dense_167_loss: 3.1021 - dense_169_loss: 3.0870 - dense_161_accuracy: 0.0696 - dense_163_accuracy: 0.0683 - dense_165_accuracy: 0.0631 - dense_167_accuracy: 0.0619 - dense_169_accuracy: 0.0619 - val_loss: 14.8562 - val_dense_161_loss: 3.0964 - val_dense_163_loss: 2.9412 - val_dense_165_loss: 2.9414 - val_dense_167_loss: 2.9369 - val_dense_169_loss: 2.9552 - val_dense_161_accuracy: 0.0000e+00 - val_dense_163_accuracy: 0.0928 - val_dense_165_accuracy: 0.0825 - val_dense_167_accuracy: 0.0979 - val_dense_169_accuracy: 0.0464\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.0656 - dense_161_loss: 2.6046 - dense_163_loss: 2.8508 - dense_165_loss: 2.8583 - dense_167_loss: 2.8730 - dense_169_loss: 2.8643 - dense_161_accuracy: 0.1327 - dense_163_accuracy: 0.1018 - dense_165_accuracy: 0.1211 - dense_167_accuracy: 0.1082 - dense_169_accuracy: 0.0889 - val_loss: 14.6189 - val_dense_161_loss: 2.9048 - val_dense_163_loss: 2.9173 - val_dense_165_loss: 2.9359 - val_dense_167_loss: 2.9308 - val_dense_169_loss: 2.9272 - val_dense_161_accuracy: 0.2526 - val_dense_163_accuracy: 0.0773 - val_dense_165_accuracy: 0.0567 - val_dense_167_accuracy: 0.0515 - val_dense_169_accuracy: 0.0825\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.0151 - dense_161_loss: 2.2729 - dense_163_loss: 2.5805 - dense_165_loss: 2.6790 - dense_167_loss: 2.7303 - dense_169_loss: 2.7376 - dense_161_accuracy: 0.2680 - dense_163_accuracy: 0.2358 - dense_165_accuracy: 0.1624 - dense_167_accuracy: 0.1443 - dense_169_accuracy: 0.1314 - val_loss: 14.3026 - val_dense_161_loss: 2.7764 - val_dense_163_loss: 2.8573 - val_dense_165_loss: 2.8910 - val_dense_167_loss: 2.8887 - val_dense_169_loss: 2.8896 - val_dense_161_accuracy: 0.0412 - val_dense_163_accuracy: 0.1959 - val_dense_165_accuracy: 0.1392 - val_dense_167_accuracy: 0.0722 - val_dense_169_accuracy: 0.2216\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 11.1200 - dense_161_loss: 1.7655 - dense_163_loss: 2.1529 - dense_165_loss: 2.3022 - dense_167_loss: 2.4015 - dense_169_loss: 2.4577 - dense_161_accuracy: 0.5232 - dense_163_accuracy: 0.3621 - dense_165_accuracy: 0.2938 - dense_167_accuracy: 0.2706 - dense_169_accuracy: 0.2771 - val_loss: 14.0188 - val_dense_161_loss: 2.7622 - val_dense_163_loss: 2.7614 - val_dense_165_loss: 2.8256 - val_dense_167_loss: 2.8213 - val_dense_169_loss: 2.8474 - val_dense_161_accuracy: 0.2887 - val_dense_163_accuracy: 0.3144 - val_dense_165_accuracy: 0.1753 - val_dense_167_accuracy: 0.1907 - val_dense_169_accuracy: 0.3402\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 7ms/sample - loss: 9.0405 - dense_161_loss: 1.2387 - dense_163_loss: 1.7636 - dense_165_loss: 1.9369 - dense_167_loss: 1.9926 - dense_169_loss: 2.1011 - dense_161_accuracy: 0.6392 - dense_163_accuracy: 0.5142 - dense_165_accuracy: 0.4755 - dense_167_accuracy: 0.4253 - dense_169_accuracy: 0.4162 - val_loss: 13.5080 - val_dense_161_loss: 2.7367 - val_dense_163_loss: 2.6663 - val_dense_165_loss: 2.7024 - val_dense_167_loss: 2.7147 - val_dense_169_loss: 2.7048 - val_dense_161_accuracy: 0.4278 - val_dense_163_accuracy: 0.4485 - val_dense_165_accuracy: 0.4021 - val_dense_167_accuracy: 0.4175 - val_dense_169_accuracy: 0.2732\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 7.3511 - dense_161_loss: 0.8979 - dense_163_loss: 1.4053 - dense_165_loss: 1.5576 - dense_167_loss: 1.6893 - dense_169_loss: 1.8106 - dense_161_accuracy: 0.7539 - dense_163_accuracy: 0.6289 - dense_165_accuracy: 0.5722 - dense_167_accuracy: 0.4884 - dense_169_accuracy: 0.4549 - val_loss: 12.6994 - val_dense_161_loss: 2.6276 - val_dense_163_loss: 2.4852 - val_dense_165_loss: 2.5531 - val_dense_167_loss: 2.5707 - val_dense_169_loss: 2.5420 - val_dense_161_accuracy: 0.3557 - val_dense_163_accuracy: 0.6082 - val_dense_165_accuracy: 0.3866 - val_dense_167_accuracy: 0.4485 - val_dense_169_accuracy: 0.2784\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 5.9269 - dense_161_loss: 0.6105 - dense_163_loss: 1.1286 - dense_165_loss: 1.2290 - dense_167_loss: 1.4061 - dense_169_loss: 1.5125 - dense_161_accuracy: 0.8286 - dense_163_accuracy: 0.7049 - dense_165_accuracy: 0.6740 - dense_167_accuracy: 0.5825 - dense_169_accuracy: 0.5528 - val_loss: 12.0871 - val_dense_161_loss: 2.6459 - val_dense_163_loss: 2.2632 - val_dense_165_loss: 2.4173 - val_dense_167_loss: 2.4417 - val_dense_169_loss: 2.3875 - val_dense_161_accuracy: 0.4021 - val_dense_163_accuracy: 0.6753 - val_dense_165_accuracy: 0.5515 - val_dense_167_accuracy: 0.5979 - val_dense_169_accuracy: 0.4433\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 4.6327 - dense_161_loss: 0.4497 - dense_163_loss: 0.7926 - dense_165_loss: 0.9442 - dense_167_loss: 1.1066 - dense_169_loss: 1.2821 - dense_161_accuracy: 0.8969 - dense_163_accuracy: 0.7990 - dense_165_accuracy: 0.7332 - dense_167_accuracy: 0.6675 - dense_169_accuracy: 0.6456 - val_loss: 11.5422 - val_dense_161_loss: 2.5889 - val_dense_163_loss: 2.1701 - val_dense_165_loss: 2.3122 - val_dense_167_loss: 2.3538 - val_dense_169_loss: 2.2444 - val_dense_161_accuracy: 0.4381 - val_dense_163_accuracy: 0.7423 - val_dense_165_accuracy: 0.6701 - val_dense_167_accuracy: 0.6289 - val_dense_169_accuracy: 0.5258\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 3.7956 - dense_161_loss: 0.3412 - dense_163_loss: 0.6628 - dense_165_loss: 0.7865 - dense_167_loss: 0.9551 - dense_169_loss: 1.0471 - dense_161_accuracy: 0.9124 - dense_163_accuracy: 0.8196 - dense_165_accuracy: 0.7668 - dense_167_accuracy: 0.7320 - dense_169_accuracy: 0.7126 - val_loss: 11.0068 - val_dense_161_loss: 2.5260 - val_dense_163_loss: 2.0541 - val_dense_165_loss: 2.2634 - val_dense_167_loss: 2.2339 - val_dense_169_loss: 2.0900 - val_dense_161_accuracy: 0.4485 - val_dense_163_accuracy: 0.7680 - val_dense_165_accuracy: 0.6443 - val_dense_167_accuracy: 0.6443 - val_dense_169_accuracy: 0.6289\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.0317 - dense_161_loss: 0.3031 - dense_163_loss: 0.5533 - dense_165_loss: 0.6469 - dense_167_loss: 0.6905 - dense_169_loss: 0.8376 - dense_161_accuracy: 0.9059 - dense_163_accuracy: 0.8608 - dense_165_accuracy: 0.8196 - dense_167_accuracy: 0.7925 - dense_169_accuracy: 0.7616 - val_loss: 10.4218 - val_dense_161_loss: 2.4871 - val_dense_163_loss: 1.8866 - val_dense_165_loss: 2.1185 - val_dense_167_loss: 2.1355 - val_dense_169_loss: 1.9483 - val_dense_161_accuracy: 0.4330 - val_dense_163_accuracy: 0.8093 - val_dense_165_accuracy: 0.6959 - val_dense_167_accuracy: 0.6649 - val_dense_169_accuracy: 0.6598\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 2.6560 - dense_161_loss: 0.2648 - dense_163_loss: 0.4371 - dense_165_loss: 0.5690 - dense_167_loss: 0.6743 - dense_169_loss: 0.7134 - dense_161_accuracy: 0.9227 - dense_163_accuracy: 0.8956 - dense_165_accuracy: 0.8338 - dense_167_accuracy: 0.8157 - dense_169_accuracy: 0.7964 - val_loss: 9.3471 - val_dense_161_loss: 2.4743 - val_dense_163_loss: 1.4713 - val_dense_165_loss: 1.8998 - val_dense_167_loss: 1.9491 - val_dense_169_loss: 1.6521 - val_dense_161_accuracy: 0.4536 - val_dense_163_accuracy: 0.8299 - val_dense_165_accuracy: 0.7010 - val_dense_167_accuracy: 0.6649 - val_dense_169_accuracy: 0.6804\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 2.1626 - dense_161_loss: 0.2098 - dense_163_loss: 0.3336 - dense_165_loss: 0.4362 - dense_167_loss: 0.5832 - dense_169_loss: 0.6124 - dense_161_accuracy: 0.9433 - dense_163_accuracy: 0.9072 - dense_165_accuracy: 0.8776 - dense_167_accuracy: 0.8363 - dense_169_accuracy: 0.8454 - val_loss: 8.6449 - val_dense_161_loss: 2.5368 - val_dense_163_loss: 1.3520 - val_dense_165_loss: 1.6480 - val_dense_167_loss: 1.7062 - val_dense_169_loss: 1.5241 - val_dense_161_accuracy: 0.4278 - val_dense_163_accuracy: 0.8402 - val_dense_165_accuracy: 0.7526 - val_dense_167_accuracy: 0.7423 - val_dense_169_accuracy: 0.7423\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.8994 - dense_161_loss: 0.1614 - dense_163_loss: 0.3050 - dense_165_loss: 0.4265 - dense_167_loss: 0.4774 - dense_169_loss: 0.5183 - dense_161_accuracy: 0.9639 - dense_163_accuracy: 0.9175 - dense_165_accuracy: 0.8905 - dense_167_accuracy: 0.8608 - dense_169_accuracy: 0.8634 - val_loss: 8.3380 - val_dense_161_loss: 2.4746 - val_dense_163_loss: 1.2541 - val_dense_165_loss: 1.6085 - val_dense_167_loss: 1.6848 - val_dense_169_loss: 1.5006 - val_dense_161_accuracy: 0.4588 - val_dense_163_accuracy: 0.8557 - val_dense_165_accuracy: 0.7732 - val_dense_167_accuracy: 0.7320 - val_dense_169_accuracy: 0.7320\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.5192 - dense_161_loss: 0.1327 - dense_163_loss: 0.2304 - dense_165_loss: 0.3607 - dense_167_loss: 0.3752 - dense_169_loss: 0.4121 - dense_161_accuracy: 0.9665 - dense_163_accuracy: 0.9304 - dense_165_accuracy: 0.9021 - dense_167_accuracy: 0.9008 - dense_169_accuracy: 0.8853 - val_loss: 7.3657 - val_dense_161_loss: 2.4894 - val_dense_163_loss: 1.0773 - val_dense_165_loss: 1.3750 - val_dense_167_loss: 1.4045 - val_dense_169_loss: 1.1716 - val_dense_161_accuracy: 0.4330 - val_dense_163_accuracy: 0.8351 - val_dense_165_accuracy: 0.7887 - val_dense_167_accuracy: 0.7371 - val_dense_169_accuracy: 0.7887\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.3836 - dense_161_loss: 0.1112 - dense_163_loss: 0.2123 - dense_165_loss: 0.3088 - dense_167_loss: 0.3725 - dense_169_loss: 0.3621 - dense_161_accuracy: 0.9678 - dense_163_accuracy: 0.9420 - dense_165_accuracy: 0.9162 - dense_167_accuracy: 0.8789 - dense_169_accuracy: 0.8956 - val_loss: 6.9194 - val_dense_161_loss: 2.6781 - val_dense_163_loss: 0.9579 - val_dense_165_loss: 1.1738 - val_dense_167_loss: 1.2295 - val_dense_169_loss: 1.0405 - val_dense_161_accuracy: 0.3711 - val_dense_163_accuracy: 0.8711 - val_dense_165_accuracy: 0.7784 - val_dense_167_accuracy: 0.7423 - val_dense_169_accuracy: 0.7784\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: 1.2087 - dense_161_loss: 0.1338 - dense_163_loss: 0.2092 - dense_165_loss: 0.2639 - dense_167_loss: 0.3104 - dense_169_loss: 0.2914 - dense_161_accuracy: 0.9639 - dense_163_accuracy: 0.9433 - dense_165_accuracy: 0.9227 - dense_167_accuracy: 0.9059 - dense_169_accuracy: 0.9330 - val_loss: 6.4857 - val_dense_161_loss: 2.5509 - val_dense_163_loss: 0.8912 - val_dense_165_loss: 1.0566 - val_dense_167_loss: 1.1819 - val_dense_169_loss: 0.9233 - val_dense_161_accuracy: 0.4124 - val_dense_163_accuracy: 0.8660 - val_dense_165_accuracy: 0.7732 - val_dense_167_accuracy: 0.7423 - val_dense_169_accuracy: 0.8247\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 8s 11ms/sample - loss: 1.1470 - dense_161_loss: 0.0996 - dense_163_loss: 0.1842 - dense_165_loss: 0.2441 - dense_167_loss: 0.3117 - dense_169_loss: 0.2977 - dense_161_accuracy: 0.9729 - dense_163_accuracy: 0.9562 - dense_165_accuracy: 0.9317 - dense_167_accuracy: 0.9149 - dense_169_accuracy: 0.9149 - val_loss: 6.5459 - val_dense_161_loss: 3.2580 - val_dense_163_loss: 0.6724 - val_dense_165_loss: 0.8780 - val_dense_167_loss: 0.9512 - val_dense_169_loss: 0.8787 - val_dense_161_accuracy: 0.3608 - val_dense_163_accuracy: 0.8660 - val_dense_165_accuracy: 0.7784 - val_dense_167_accuracy: 0.7990 - val_dense_169_accuracy: 0.8144\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.9672 - dense_161_loss: 0.0830 - dense_163_loss: 0.1569 - dense_165_loss: 0.2154 - dense_167_loss: 0.2328 - dense_169_loss: 0.2736 - dense_161_accuracy: 0.9755 - dense_163_accuracy: 0.9613 - dense_165_accuracy: 0.9459 - dense_167_accuracy: 0.9381 - dense_169_accuracy: 0.9214 - val_loss: 6.5743 - val_dense_161_loss: 3.5075 - val_dense_163_loss: 0.8187 - val_dense_165_loss: 0.7481 - val_dense_167_loss: 0.8078 - val_dense_169_loss: 0.7572 - val_dense_161_accuracy: 0.2680 - val_dense_163_accuracy: 0.8299 - val_dense_165_accuracy: 0.8196 - val_dense_167_accuracy: 0.8247 - val_dense_169_accuracy: 0.7835\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.8706 - dense_161_loss: 0.0950 - dense_163_loss: 0.1337 - dense_165_loss: 0.1778 - dense_167_loss: 0.2369 - dense_169_loss: 0.2616 - dense_161_accuracy: 0.9781 - dense_163_accuracy: 0.9626 - dense_165_accuracy: 0.9665 - dense_167_accuracy: 0.9433 - dense_169_accuracy: 0.9253 - val_loss: 6.6016 - val_dense_161_loss: 3.8456 - val_dense_163_loss: 0.7395 - val_dense_165_loss: 0.6533 - val_dense_167_loss: 0.7011 - val_dense_169_loss: 0.5949 - val_dense_161_accuracy: 0.3299 - val_dense_163_accuracy: 0.8608 - val_dense_165_accuracy: 0.7938 - val_dense_167_accuracy: 0.8144 - val_dense_169_accuracy: 0.8505\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.8356 - dense_161_loss: 0.0778 - dense_163_loss: 0.1152 - dense_165_loss: 0.1869 - dense_167_loss: 0.2289 - dense_169_loss: 0.2160 - dense_161_accuracy: 0.9768 - dense_163_accuracy: 0.9652 - dense_165_accuracy: 0.9523 - dense_167_accuracy: 0.9291 - dense_169_accuracy: 0.9381 - val_loss: 6.7585 - val_dense_161_loss: 4.1711 - val_dense_163_loss: 0.8466 - val_dense_165_loss: 0.7057 - val_dense_167_loss: 0.6735 - val_dense_169_loss: 0.5109 - val_dense_161_accuracy: 0.2680 - val_dense_163_accuracy: 0.8763 - val_dense_165_accuracy: 0.8041 - val_dense_167_accuracy: 0.8144 - val_dense_169_accuracy: 0.8505\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.7283 - dense_161_loss: 0.0554 - dense_163_loss: 0.0892 - dense_165_loss: 0.1506 - dense_167_loss: 0.2156 - dense_169_loss: 0.1988 - dense_161_accuracy: 0.9858 - dense_163_accuracy: 0.9742 - dense_165_accuracy: 0.9459 - dense_167_accuracy: 0.9394 - dense_169_accuracy: 0.9304 - val_loss: 7.9110 - val_dense_161_loss: 5.4006 - val_dense_163_loss: 0.9159 - val_dense_165_loss: 0.6830 - val_dense_167_loss: 0.5788 - val_dense_169_loss: 0.6070 - val_dense_161_accuracy: 0.2938 - val_dense_163_accuracy: 0.8660 - val_dense_165_accuracy: 0.7835 - val_dense_167_accuracy: 0.8196 - val_dense_169_accuracy: 0.8144\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.7108 - dense_161_loss: 0.0674 - dense_163_loss: 0.1442 - dense_165_loss: 0.1641 - dense_167_loss: 0.1598 - dense_169_loss: 0.1821 - dense_161_accuracy: 0.9820 - dense_163_accuracy: 0.9639 - dense_165_accuracy: 0.9575 - dense_167_accuracy: 0.9601 - dense_169_accuracy: 0.9562 - val_loss: 7.1995 - val_dense_161_loss: 4.7189 - val_dense_163_loss: 0.7826 - val_dense_165_loss: 0.5971 - val_dense_167_loss: 0.6244 - val_dense_169_loss: 0.5884 - val_dense_161_accuracy: 0.2938 - val_dense_163_accuracy: 0.8660 - val_dense_165_accuracy: 0.8041 - val_dense_167_accuracy: 0.8093 - val_dense_169_accuracy: 0.8247\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.6788 - dense_161_loss: 0.0471 - dense_163_loss: 0.1479 - dense_165_loss: 0.1360 - dense_167_loss: 0.1589 - dense_169_loss: 0.1817 - dense_161_accuracy: 0.9884 - dense_163_accuracy: 0.9678 - dense_165_accuracy: 0.9639 - dense_167_accuracy: 0.9420 - dense_169_accuracy: 0.9510 - val_loss: 8.9801 - val_dense_161_loss: 6.4101 - val_dense_163_loss: 0.8792 - val_dense_165_loss: 0.6306 - val_dense_167_loss: 0.6198 - val_dense_169_loss: 0.5607 - val_dense_161_accuracy: 0.2165 - val_dense_163_accuracy: 0.8763 - val_dense_165_accuracy: 0.8041 - val_dense_167_accuracy: 0.8196 - val_dense_169_accuracy: 0.8299\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.5932 - dense_161_loss: 0.0457 - dense_163_loss: 0.1035 - dense_165_loss: 0.1445 - dense_167_loss: 0.1620 - dense_169_loss: 0.1414 - dense_161_accuracy: 0.9884 - dense_163_accuracy: 0.9704 - dense_165_accuracy: 0.9575 - dense_167_accuracy: 0.9497 - dense_169_accuracy: 0.9626 - val_loss: 8.7433 - val_dense_161_loss: 6.0997 - val_dense_163_loss: 0.8815 - val_dense_165_loss: 0.6371 - val_dense_167_loss: 0.6136 - val_dense_169_loss: 0.5635 - val_dense_161_accuracy: 0.2268 - val_dense_163_accuracy: 0.9021 - val_dense_165_accuracy: 0.8041 - val_dense_167_accuracy: 0.8144 - val_dense_169_accuracy: 0.8247\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.6192 - dense_161_loss: 0.0709 - dense_163_loss: 0.0922 - dense_165_loss: 0.1324 - dense_167_loss: 0.1537 - dense_169_loss: 0.1683 - dense_161_accuracy: 0.9794 - dense_163_accuracy: 0.9742 - dense_165_accuracy: 0.9536 - dense_167_accuracy: 0.9549 - dense_169_accuracy: 0.9497 - val_loss: 11.8068 - val_dense_161_loss: 8.8122 - val_dense_163_loss: 0.9307 - val_dense_165_loss: 0.7197 - val_dense_167_loss: 0.6975 - val_dense_169_loss: 0.5619 - val_dense_161_accuracy: 0.1701 - val_dense_163_accuracy: 0.8763 - val_dense_165_accuracy: 0.7938 - val_dense_167_accuracy: 0.8247 - val_dense_169_accuracy: 0.8454\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.5424 - dense_161_loss: 0.0486 - dense_163_loss: 0.0769 - dense_165_loss: 0.1150 - dense_167_loss: 0.1415 - dense_169_loss: 0.1492 - dense_161_accuracy: 0.9897 - dense_163_accuracy: 0.9858 - dense_165_accuracy: 0.9678 - dense_167_accuracy: 0.9601 - dense_169_accuracy: 0.9536 - val_loss: 11.3142 - val_dense_161_loss: 8.3155 - val_dense_163_loss: 1.2144 - val_dense_165_loss: 0.7454 - val_dense_167_loss: 0.5765 - val_dense_169_loss: 0.4662 - val_dense_161_accuracy: 0.1701 - val_dense_163_accuracy: 0.8763 - val_dense_165_accuracy: 0.7990 - val_dense_167_accuracy: 0.8299 - val_dense_169_accuracy: 0.8557\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.5085 - dense_161_loss: 0.0540 - dense_163_loss: 0.0802 - dense_165_loss: 0.1047 - dense_167_loss: 0.1644 - dense_169_loss: 0.1012 - dense_161_accuracy: 0.9845 - dense_163_accuracy: 0.9768 - dense_165_accuracy: 0.9729 - dense_167_accuracy: 0.9523 - dense_169_accuracy: 0.9742 - val_loss: 11.0959 - val_dense_161_loss: 8.3780 - val_dense_163_loss: 1.0678 - val_dense_165_loss: 0.6553 - val_dense_167_loss: 0.5122 - val_dense_169_loss: 0.4566 - val_dense_161_accuracy: 0.1495 - val_dense_163_accuracy: 0.8814 - val_dense_165_accuracy: 0.8196 - val_dense_167_accuracy: 0.8454 - val_dense_169_accuracy: 0.8660\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.4478 - dense_161_loss: 0.0456 - dense_163_loss: 0.0654 - dense_165_loss: 0.0852 - dense_167_loss: 0.1219 - dense_169_loss: 0.1197 - dense_161_accuracy: 0.9871 - dense_163_accuracy: 0.9832 - dense_165_accuracy: 0.9832 - dense_167_accuracy: 0.9626 - dense_169_accuracy: 0.9665 - val_loss: 10.1837 - val_dense_161_loss: 7.2962 - val_dense_163_loss: 1.0944 - val_dense_165_loss: 0.6802 - val_dense_167_loss: 0.6200 - val_dense_169_loss: 0.6033 - val_dense_161_accuracy: 0.3093 - val_dense_163_accuracy: 0.8866 - val_dense_165_accuracy: 0.8196 - val_dense_167_accuracy: 0.7990 - val_dense_169_accuracy: 0.8660\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.4207 - dense_161_loss: 0.0416 - dense_163_loss: 0.0608 - dense_165_loss: 0.0827 - dense_167_loss: 0.1308 - dense_169_loss: 0.0985 - dense_161_accuracy: 0.9897 - dense_163_accuracy: 0.9794 - dense_165_accuracy: 0.9742 - dense_167_accuracy: 0.9601 - dense_169_accuracy: 0.9652 - val_loss: 12.6938 - val_dense_161_loss: 9.8665 - val_dense_163_loss: 1.0866 - val_dense_165_loss: 0.8342 - val_dense_167_loss: 0.7212 - val_dense_169_loss: 0.6229 - val_dense_161_accuracy: 0.1340 - val_dense_163_accuracy: 0.8918 - val_dense_165_accuracy: 0.8144 - val_dense_167_accuracy: 0.8196 - val_dense_169_accuracy: 0.8660\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.3909 - dense_161_loss: 0.0306 - dense_163_loss: 0.0844 - dense_165_loss: 0.0797 - dense_167_loss: 0.0977 - dense_169_loss: 0.0946 - dense_161_accuracy: 0.9948 - dense_163_accuracy: 0.9755 - dense_165_accuracy: 0.9781 - dense_167_accuracy: 0.9768 - dense_169_accuracy: 0.9742 - val_loss: 14.0530 - val_dense_161_loss: 11.0686 - val_dense_163_loss: 1.2198 - val_dense_165_loss: 0.9632 - val_dense_167_loss: 0.9402 - val_dense_169_loss: 0.6722 - val_dense_161_accuracy: 0.0979 - val_dense_163_accuracy: 0.8814 - val_dense_165_accuracy: 0.8041 - val_dense_167_accuracy: 0.8144 - val_dense_169_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "model=act_create_model();\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 2ms/sample - loss: 10.9829 - dense_141_loss: 7.8568 - dense_143_loss: 0.5705 - dense_145_loss: 0.6102 - dense_147_loss: 0.8401 - dense_149_loss: 0.3195 - dense_141_accuracy: 0.0000e+00 - dense_143_accuracy: 0.9000 - dense_145_accuracy: 0.8200 - dense_147_accuracy: 0.8400 - dense_149_accuracy: 0.8800\n",
      "Test Loss and accuracy: [9.585947303771972, 7.856838, 0.57052374, 0.61021674, 0.84007394, 0.31946328, 0.0, 0.9, 0.82, 0.84, 0.88]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(X_test,[y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]],verbose=1)\n",
    "print('Test Loss and accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Tanh and Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def act_2_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='tanh')(img)\n",
    "    #model.add(LeakyReLU(alpha=0.05))\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='tanh')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='tanh')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='tanh')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 50, 200, 16)  160         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 50, 32)   128         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 5600)         0           max_pooling2d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 64)           358464      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 64)           358464      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 64)           358464      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 64)           358464      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 64)           358464      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 64)           0           dense_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 64)           0           dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 64)           0           dense_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 64)           0           dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 64)           0           dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 19)           1235        dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 19)           1235        dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 19)           1235        dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 19)           1235        dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 19)           1235        dropout_79[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 9s 11ms/sample - loss: 15.3203 - dense_151_loss: 2.8816 - dense_153_loss: 3.1523 - dense_155_loss: 3.0700 - dense_157_loss: 3.1797 - dense_159_loss: 3.0295 - dense_151_accuracy: 0.0657 - dense_153_accuracy: 0.0606 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0567 - dense_159_accuracy: 0.0954 - val_loss: 16.6803 - val_dense_151_loss: 4.7153 - val_dense_153_loss: 2.9583 - val_dense_155_loss: 3.0203 - val_dense_157_loss: 3.0984 - val_dense_159_loss: 2.9890 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0567 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0619 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.9788 - dense_151_loss: 2.7658 - dense_153_loss: 3.0575 - dense_155_loss: 3.0493 - dense_157_loss: 3.0638 - dense_159_loss: 3.0419 - dense_151_accuracy: 0.0683 - dense_153_accuracy: 0.0593 - dense_155_accuracy: 0.0722 - dense_157_accuracy: 0.0644 - dense_159_accuracy: 0.0992 - val_loss: 17.3490 - val_dense_151_loss: 5.4941 - val_dense_153_loss: 2.9383 - val_dense_155_loss: 2.9918 - val_dense_157_loss: 3.0316 - val_dense_159_loss: 2.9701 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0825 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.8046 - dense_151_loss: 2.7383 - dense_153_loss: 3.0329 - dense_155_loss: 2.9958 - dense_157_loss: 3.0267 - dense_159_loss: 2.9863 - dense_151_accuracy: 0.0786 - dense_153_accuracy: 0.0709 - dense_155_accuracy: 0.0941 - dense_157_accuracy: 0.0670 - dense_159_accuracy: 0.0979 - val_loss: 17.7782 - val_dense_151_loss: 5.9907 - val_dense_153_loss: 2.9260 - val_dense_155_loss: 2.9701 - val_dense_157_loss: 2.9932 - val_dense_159_loss: 2.9608 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 14.6554 - dense_151_loss: 2.7019 - dense_153_loss: 3.0346 - dense_155_loss: 2.9783 - dense_157_loss: 2.9898 - dense_159_loss: 2.9509 - dense_151_accuracy: 0.0567 - dense_153_accuracy: 0.0863 - dense_155_accuracy: 0.0915 - dense_157_accuracy: 0.0747 - dense_159_accuracy: 0.0992 - val_loss: 18.0364 - val_dense_151_loss: 6.3003 - val_dense_153_loss: 2.9248 - val_dense_155_loss: 2.9609 - val_dense_157_loss: 2.9862 - val_dense_159_loss: 2.9640 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 7s 8ms/sample - loss: 14.6842 - dense_151_loss: 2.7192 - dense_153_loss: 3.0212 - dense_155_loss: 2.9685 - dense_157_loss: 2.9864 - dense_159_loss: 2.9650 - dense_151_accuracy: 0.0902 - dense_153_accuracy: 0.0593 - dense_155_accuracy: 0.0876 - dense_157_accuracy: 0.0709 - dense_159_accuracy: 0.1018 - val_loss: 18.2396 - val_dense_151_loss: 6.5404 - val_dense_153_loss: 2.9259 - val_dense_155_loss: 2.9529 - val_dense_157_loss: 2.9813 - val_dense_159_loss: 2.9594 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 14.5635 - dense_151_loss: 2.7007 - dense_153_loss: 2.9762 - dense_155_loss: 2.9628 - dense_157_loss: 2.9702 - dense_159_loss: 2.9357 - dense_151_accuracy: 0.0799 - dense_153_accuracy: 0.0747 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0838 - dense_159_accuracy: 0.1057 - val_loss: 18.4066 - val_dense_151_loss: 6.7400 - val_dense_153_loss: 2.9222 - val_dense_155_loss: 2.9498 - val_dense_157_loss: 2.9695 - val_dense_159_loss: 2.9572 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.6175 - dense_151_loss: 2.6929 - dense_153_loss: 3.0069 - dense_155_loss: 2.9795 - dense_157_loss: 2.9877 - dense_159_loss: 2.9526 - dense_151_accuracy: 0.0657 - dense_153_accuracy: 0.0863 - dense_155_accuracy: 0.0979 - dense_157_accuracy: 0.0812 - dense_159_accuracy: 0.1018 - val_loss: 18.5465 - val_dense_151_loss: 6.9052 - val_dense_153_loss: 2.9125 - val_dense_155_loss: 2.9476 - val_dense_157_loss: 2.9685 - val_dense_159_loss: 2.9502 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.5404 - dense_151_loss: 2.7029 - dense_153_loss: 2.9646 - dense_155_loss: 2.9365 - dense_157_loss: 2.9585 - dense_159_loss: 2.9734 - dense_151_accuracy: 0.0786 - dense_153_accuracy: 0.0851 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0670 - dense_159_accuracy: 0.1082 - val_loss: 18.6861 - val_dense_151_loss: 7.0733 - val_dense_153_loss: 2.9120 - val_dense_155_loss: 2.9473 - val_dense_157_loss: 2.9719 - val_dense_159_loss: 2.9593 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4970 - dense_151_loss: 2.6908 - dense_153_loss: 2.9461 - dense_155_loss: 2.9336 - dense_157_loss: 2.9769 - dense_159_loss: 2.9554 - dense_151_accuracy: 0.0838 - dense_153_accuracy: 0.0876 - dense_155_accuracy: 0.0966 - dense_157_accuracy: 0.1031 - dense_159_accuracy: 0.0979 - val_loss: 18.8005 - val_dense_151_loss: 7.1883 - val_dense_153_loss: 2.9165 - val_dense_155_loss: 2.9442 - val_dense_157_loss: 2.9666 - val_dense_159_loss: 2.9528 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4858 - dense_151_loss: 2.6938 - dense_153_loss: 2.9546 - dense_155_loss: 2.9476 - dense_157_loss: 2.9458 - dense_159_loss: 2.9418 - dense_151_accuracy: 0.0786 - dense_153_accuracy: 0.0928 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0760 - dense_159_accuracy: 0.0928 - val_loss: 18.8106 - val_dense_151_loss: 7.2208 - val_dense_153_loss: 2.9157 - val_dense_155_loss: 2.9427 - val_dense_157_loss: 2.9599 - val_dense_159_loss: 2.9575 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.5035 - dense_151_loss: 2.6834 - dense_153_loss: 2.9808 - dense_155_loss: 2.9553 - dense_157_loss: 2.9563 - dense_159_loss: 2.9418 - dense_151_accuracy: 0.0851 - dense_153_accuracy: 0.0825 - dense_155_accuracy: 0.0992 - dense_157_accuracy: 0.0863 - dense_159_accuracy: 0.1044 - val_loss: 18.8985 - val_dense_151_loss: 7.3147 - val_dense_153_loss: 2.9211 - val_dense_155_loss: 2.9465 - val_dense_157_loss: 2.9584 - val_dense_159_loss: 2.9577 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4835 - dense_151_loss: 2.6833 - dense_153_loss: 2.9358 - dense_155_loss: 2.9486 - dense_157_loss: 2.9674 - dense_159_loss: 2.9428 - dense_151_accuracy: 0.0735 - dense_153_accuracy: 0.1108 - dense_155_accuracy: 0.0979 - dense_157_accuracy: 0.0722 - dense_159_accuracy: 0.1082 - val_loss: 19.0179 - val_dense_151_loss: 7.4355 - val_dense_153_loss: 2.9234 - val_dense_155_loss: 2.9459 - val_dense_157_loss: 2.9587 - val_dense_159_loss: 2.9480 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4750 - dense_151_loss: 2.6892 - dense_153_loss: 2.9355 - dense_155_loss: 2.9544 - dense_157_loss: 2.9571 - dense_159_loss: 2.9307 - dense_151_accuracy: 0.0876 - dense_153_accuracy: 0.0966 - dense_155_accuracy: 0.0979 - dense_157_accuracy: 0.0722 - dense_159_accuracy: 0.1070 - val_loss: 19.0308 - val_dense_151_loss: 7.4653 - val_dense_153_loss: 2.9252 - val_dense_155_loss: 2.9430 - val_dense_157_loss: 2.9584 - val_dense_159_loss: 2.9492 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4902 - dense_151_loss: 2.6888 - dense_153_loss: 2.9316 - dense_155_loss: 2.9582 - dense_157_loss: 2.9725 - dense_159_loss: 2.9399 - dense_151_accuracy: 0.0709 - dense_153_accuracy: 0.0915 - dense_155_accuracy: 0.1005 - dense_157_accuracy: 0.0838 - dense_159_accuracy: 0.1070 - val_loss: 19.0626 - val_dense_151_loss: 7.5101 - val_dense_153_loss: 2.9194 - val_dense_155_loss: 2.9400 - val_dense_157_loss: 2.9581 - val_dense_159_loss: 2.9531 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4743 - dense_151_loss: 2.6833 - dense_153_loss: 2.9169 - dense_155_loss: 2.9575 - dense_157_loss: 2.9685 - dense_159_loss: 2.9503 - dense_151_accuracy: 0.0773 - dense_153_accuracy: 0.0954 - dense_155_accuracy: 0.0966 - dense_157_accuracy: 0.0889 - dense_159_accuracy: 0.1005 - val_loss: 19.2629 - val_dense_151_loss: 7.6952 - val_dense_153_loss: 2.9164 - val_dense_155_loss: 2.9419 - val_dense_157_loss: 2.9528 - val_dense_159_loss: 2.9501 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.5004 - dense_151_loss: 2.6903 - dense_153_loss: 2.9419 - dense_155_loss: 2.9571 - dense_157_loss: 2.9701 - dense_159_loss: 2.9567 - dense_151_accuracy: 0.0773 - dense_153_accuracy: 0.0863 - dense_155_accuracy: 0.0941 - dense_157_accuracy: 0.0992 - dense_159_accuracy: 0.0941 - val_loss: 19.2508 - val_dense_151_loss: 7.6969 - val_dense_153_loss: 2.9166 - val_dense_155_loss: 2.9424 - val_dense_157_loss: 2.9532 - val_dense_159_loss: 2.9457 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4827 - dense_151_loss: 2.6998 - dense_153_loss: 2.9302 - dense_155_loss: 2.9414 - dense_157_loss: 2.9530 - dense_159_loss: 2.9643 - dense_151_accuracy: 0.0786 - dense_153_accuracy: 0.0941 - dense_155_accuracy: 0.0954 - dense_157_accuracy: 0.0747 - dense_159_accuracy: 0.0954 - val_loss: 19.3225 - val_dense_151_loss: 7.7729 - val_dense_153_loss: 2.9168 - val_dense_155_loss: 2.9408 - val_dense_157_loss: 2.9536 - val_dense_159_loss: 2.9468 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4479 - dense_151_loss: 2.6808 - dense_153_loss: 2.9107 - dense_155_loss: 2.9520 - dense_157_loss: 2.9522 - dense_159_loss: 2.9504 - dense_151_accuracy: 0.0838 - dense_153_accuracy: 0.0863 - dense_155_accuracy: 0.0954 - dense_157_accuracy: 0.0954 - dense_159_accuracy: 0.0966 - val_loss: 19.3286 - val_dense_151_loss: 7.7902 - val_dense_153_loss: 2.9146 - val_dense_155_loss: 2.9422 - val_dense_157_loss: 2.9553 - val_dense_159_loss: 2.9463 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4453 - dense_151_loss: 2.6912 - dense_153_loss: 2.9155 - dense_155_loss: 2.9500 - dense_157_loss: 2.9457 - dense_159_loss: 2.9414 - dense_151_accuracy: 0.0812 - dense_153_accuracy: 0.0812 - dense_155_accuracy: 0.0941 - dense_157_accuracy: 0.0902 - dense_159_accuracy: 0.1005 - val_loss: 19.3798 - val_dense_151_loss: 7.8463 - val_dense_153_loss: 2.9137 - val_dense_155_loss: 2.9433 - val_dense_157_loss: 2.9563 - val_dense_159_loss: 2.9397 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4221 - dense_151_loss: 2.6863 - dense_153_loss: 2.9299 - dense_155_loss: 2.9334 - dense_157_loss: 2.9449 - dense_159_loss: 2.9267 - dense_151_accuracy: 0.0773 - dense_153_accuracy: 0.0915 - dense_155_accuracy: 0.0954 - dense_157_accuracy: 0.0863 - dense_159_accuracy: 0.1031 - val_loss: 19.3769 - val_dense_151_loss: 7.8567 - val_dense_153_loss: 2.9126 - val_dense_155_loss: 2.9442 - val_dense_157_loss: 2.9545 - val_dense_159_loss: 2.9414 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.4267 - dense_151_loss: 2.6916 - dense_153_loss: 2.9195 - dense_155_loss: 2.9368 - dense_157_loss: 2.9474 - dense_159_loss: 2.9373 - dense_151_accuracy: 0.0799 - dense_153_accuracy: 0.1070 - dense_155_accuracy: 0.0954 - dense_157_accuracy: 0.0825 - dense_159_accuracy: 0.1082 - val_loss: 19.3348 - val_dense_151_loss: 7.8266 - val_dense_153_loss: 2.9120 - val_dense_155_loss: 2.9442 - val_dense_157_loss: 2.9548 - val_dense_159_loss: 2.9449 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4327 - dense_151_loss: 2.6841 - dense_153_loss: 2.9140 - dense_155_loss: 2.9410 - dense_157_loss: 2.9423 - dense_159_loss: 2.9442 - dense_151_accuracy: 0.0954 - dense_153_accuracy: 0.1082 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0812 - dense_159_accuracy: 0.1070 - val_loss: 19.3963 - val_dense_151_loss: 7.8922 - val_dense_153_loss: 2.9078 - val_dense_155_loss: 2.9438 - val_dense_157_loss: 2.9527 - val_dense_159_loss: 2.9466 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4427 - dense_151_loss: 2.6888 - dense_153_loss: 2.9234 - dense_155_loss: 2.9395 - dense_157_loss: 2.9428 - dense_159_loss: 2.9497 - dense_151_accuracy: 0.0657 - dense_153_accuracy: 0.0979 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0863 - dense_159_accuracy: 0.1070 - val_loss: 19.4547 - val_dense_151_loss: 7.9521 - val_dense_153_loss: 2.9049 - val_dense_155_loss: 2.9450 - val_dense_157_loss: 2.9534 - val_dense_159_loss: 2.9492 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.4264 - dense_151_loss: 2.6835 - dense_153_loss: 2.9048 - dense_155_loss: 2.9428 - dense_157_loss: 2.9448 - dense_159_loss: 2.9444 - dense_151_accuracy: 0.0670 - dense_153_accuracy: 0.0954 - dense_155_accuracy: 0.0941 - dense_157_accuracy: 0.0889 - dense_159_accuracy: 0.1044 - val_loss: 19.5283 - val_dense_151_loss: 8.0284 - val_dense_153_loss: 2.9020 - val_dense_155_loss: 2.9453 - val_dense_157_loss: 2.9520 - val_dense_159_loss: 2.9487 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4297 - dense_151_loss: 2.6762 - dense_153_loss: 2.9237 - dense_155_loss: 2.9472 - dense_157_loss: 2.9476 - dense_159_loss: 2.9365 - dense_151_accuracy: 0.0838 - dense_153_accuracy: 0.0992 - dense_155_accuracy: 0.0992 - dense_157_accuracy: 0.0812 - dense_159_accuracy: 0.1095 - val_loss: 19.5796 - val_dense_151_loss: 8.0594 - val_dense_153_loss: 2.9276 - val_dense_155_loss: 2.9451 - val_dense_157_loss: 2.9539 - val_dense_159_loss: 2.9511 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4211 - dense_151_loss: 2.6765 - dense_153_loss: 2.9350 - dense_155_loss: 2.9364 - dense_157_loss: 2.9360 - dense_159_loss: 2.9357 - dense_151_accuracy: 0.0812 - dense_153_accuracy: 0.1031 - dense_155_accuracy: 0.0966 - dense_157_accuracy: 0.0889 - dense_159_accuracy: 0.1057 - val_loss: 19.6168 - val_dense_151_loss: 8.1264 - val_dense_153_loss: 2.8963 - val_dense_155_loss: 2.9444 - val_dense_157_loss: 2.9534 - val_dense_159_loss: 2.9495 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4367 - dense_151_loss: 2.6832 - dense_153_loss: 2.9193 - dense_155_loss: 2.9409 - dense_157_loss: 2.9428 - dense_159_loss: 2.9478 - dense_151_accuracy: 0.0863 - dense_153_accuracy: 0.1095 - dense_155_accuracy: 0.1005 - dense_157_accuracy: 0.0889 - dense_159_accuracy: 0.1044 - val_loss: 19.6440 - val_dense_151_loss: 8.1572 - val_dense_153_loss: 2.8953 - val_dense_155_loss: 2.9433 - val_dense_157_loss: 2.9533 - val_dense_159_loss: 2.9573 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4125 - dense_151_loss: 2.6838 - dense_153_loss: 2.9035 - dense_155_loss: 2.9415 - dense_157_loss: 2.9446 - dense_159_loss: 2.9402 - dense_151_accuracy: 0.0786 - dense_153_accuracy: 0.1057 - dense_155_accuracy: 0.0941 - dense_157_accuracy: 0.0966 - dense_159_accuracy: 0.1018 - val_loss: 19.6812 - val_dense_151_loss: 8.2046 - val_dense_153_loss: 2.8916 - val_dense_155_loss: 2.9435 - val_dense_157_loss: 2.9490 - val_dense_159_loss: 2.9512 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4184 - dense_151_loss: 2.6705 - dense_153_loss: 2.9123 - dense_155_loss: 2.9474 - dense_157_loss: 2.9521 - dense_159_loss: 2.9288 - dense_151_accuracy: 0.0876 - dense_153_accuracy: 0.1057 - dense_155_accuracy: 0.0902 - dense_157_accuracy: 0.0979 - dense_159_accuracy: 0.1018 - val_loss: 19.6960 - val_dense_151_loss: 8.2182 - val_dense_153_loss: 2.8979 - val_dense_155_loss: 2.9437 - val_dense_157_loss: 2.9508 - val_dense_159_loss: 2.9538 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4051 - dense_151_loss: 2.6912 - dense_153_loss: 2.9011 - dense_155_loss: 2.9376 - dense_157_loss: 2.9408 - dense_159_loss: 2.9320 - dense_151_accuracy: 0.0683 - dense_153_accuracy: 0.0992 - dense_155_accuracy: 0.0954 - dense_157_accuracy: 0.0941 - dense_159_accuracy: 0.1031 - val_loss: 19.7366 - val_dense_151_loss: 8.2634 - val_dense_153_loss: 2.8950 - val_dense_155_loss: 2.9434 - val_dense_157_loss: 2.9507 - val_dense_159_loss: 2.9538 - val_dense_151_accuracy: 0.0000e+00 - val_dense_153_accuracy: 0.0773 - val_dense_155_accuracy: 0.0979 - val_dense_157_accuracy: 0.0979 - val_dense_159_accuracy: 0.1392\n"
     ]
    }
   ],
   "source": [
    "model=act_2_create_model();\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 1ms/sample - loss: 21.8860 - dense_151_loss: 10.1206 - dense_153_loss: 2.9310 - dense_155_loss: 2.9354 - dense_157_loss: 2.9354 - dense_159_loss: 2.9351 - dense_151_accuracy: 0.0000e+00 - dense_153_accuracy: 0.0500 - dense_155_accuracy: 0.1200 - dense_157_accuracy: 0.1000 - dense_159_accuracy: 0.0800\n",
      "Test Loss and accuracy: [21.83528533935547, 10.120579, 2.931044, 2.9354043, 2.9353945, 2.9350548, 0.0, 0.05, 0.12, 0.1, 0.08]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(X_test,[y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]],verbose=1)\n",
    "print('Test Loss and accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh has decreased the accuracy drastically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part c: Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function is usually a function defined on a data point, prediction and label, and measures the penalty. For example:\n",
    "\n",
    "    square loss l(f(xi|θ),yi)=(f(xi|θ)−yi)2\n",
    "\n",
    ", used in linear regression\n",
    "hinge loss l(f(xi|θ),yi)=max(0,1−f(xi|θ)yi)\n",
    ", used in SVM\n",
    "0/1 loss l(f(xi|θ),yi)=1⟺f(xi|θ)≠yi\n",
    "\n",
    "    , used in theoretical analysis and definition of accuracy\n",
    "\n",
    "Cost function is usually more general. It might be a sum of loss functions over your training set plus some model complexity penalty (regularization). For example:\n",
    "\n",
    "    Mean Squared Error MSE(θ)=1N∑Ni=1(f(xi|θ)−yi)2\n",
    "\n",
    "SVM cost function SVM(θ)=∥θ∥2+C∑Ni=1ξi\n",
    "(there are additional constraints connecting ξi with C and with training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def cost_create_model(cost_function):\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='tanh')(img)\n",
    "    #model.add(LeakyReLU(alpha=0.05))\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='tanh')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='tanh')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='tanh')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss=cost_function, optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 50, 200, 16)  160         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 50, 32)   128         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 5600)         0           max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_170 (Dense)               (None, 64)           358464      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_172 (Dense)               (None, 64)           358464      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 64)           358464      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_176 (Dense)               (None, 64)           358464      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_178 (Dense)               (None, 64)           358464      flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 64)           0           dense_170[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 64)           0           dense_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 64)           0           dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 64)           0           dense_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 64)           0           dense_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_171 (Dense)               (None, 19)           1235        dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_173 (Dense)               (None, 19)           1235        dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 19)           1235        dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_177 (Dense)               (None, 19)           1235        dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 19)           1235        dropout_89[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: 15.3541 - dense_171_loss: 2.9295 - dense_173_loss: 3.0634 - dense_175_loss: 3.0942 - dense_177_loss: 3.1073 - dense_179_loss: 3.1577 - dense_171_accuracy: 0.0657 - dense_173_accuracy: 0.0979 - dense_175_accuracy: 0.0554 - dense_177_accuracy: 0.0786 - dense_179_accuracy: 0.0425 - val_loss: 16.5528 - val_dense_171_loss: 4.7153 - val_dense_173_loss: 2.9305 - val_dense_175_loss: 3.0362 - val_dense_177_loss: 3.1477 - val_dense_179_loss: 3.0189 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.0567\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.9593 - dense_171_loss: 2.7692 - dense_173_loss: 3.0220 - dense_175_loss: 3.0286 - dense_177_loss: 3.0538 - dense_179_loss: 3.0484 - dense_171_accuracy: 0.0851 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0799 - dense_177_accuracy: 0.0825 - dense_179_accuracy: 0.0670 - val_loss: 17.0912 - val_dense_171_loss: 5.4262 - val_dense_173_loss: 2.9310 - val_dense_175_loss: 2.9770 - val_dense_177_loss: 3.0690 - val_dense_179_loss: 2.9822 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.0567\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.8005 - dense_171_loss: 2.7345 - dense_173_loss: 2.9746 - dense_175_loss: 3.0396 - dense_177_loss: 3.0158 - dense_179_loss: 3.0133 - dense_171_accuracy: 0.0773 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0644 - dense_177_accuracy: 0.0838 - dense_179_accuracy: 0.0644 - val_loss: 17.5503 - val_dense_171_loss: 5.9730 - val_dense_173_loss: 2.9252 - val_dense_175_loss: 2.9579 - val_dense_177_loss: 2.9994 - val_dense_179_loss: 2.9641 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.7188 - dense_171_loss: 2.7286 - dense_173_loss: 2.9694 - dense_175_loss: 2.9853 - dense_177_loss: 3.0346 - dense_179_loss: 2.9875 - dense_171_accuracy: 0.0644 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0786 - dense_177_accuracy: 0.0902 - dense_179_accuracy: 0.0760 - val_loss: 17.6964 - val_dense_171_loss: 6.1662 - val_dense_173_loss: 2.9370 - val_dense_175_loss: 2.9541 - val_dense_177_loss: 2.9699 - val_dense_179_loss: 2.9433 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.6356 - dense_171_loss: 2.7105 - dense_173_loss: 2.9676 - dense_175_loss: 3.0085 - dense_177_loss: 2.9609 - dense_179_loss: 2.9831 - dense_171_accuracy: 0.0902 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0876 - dense_177_accuracy: 0.0838 - dense_179_accuracy: 0.0825 - val_loss: 18.1069 - val_dense_171_loss: 6.5748 - val_dense_173_loss: 2.9364 - val_dense_175_loss: 2.9464 - val_dense_177_loss: 2.9601 - val_dense_179_loss: 2.9470 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.5829 - dense_171_loss: 2.6897 - dense_173_loss: 2.9713 - dense_175_loss: 2.9591 - dense_177_loss: 2.9838 - dense_179_loss: 2.9774 - dense_171_accuracy: 0.1018 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0876 - dense_177_accuracy: 0.0876 - dense_179_accuracy: 0.0876 - val_loss: 18.3214 - val_dense_171_loss: 6.7937 - val_dense_173_loss: 2.9333 - val_dense_175_loss: 2.9469 - val_dense_177_loss: 2.9580 - val_dense_179_loss: 2.9676 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.5606 - dense_171_loss: 2.6943 - dense_173_loss: 2.9593 - dense_175_loss: 2.9665 - dense_177_loss: 2.9535 - dense_179_loss: 2.9715 - dense_171_accuracy: 0.0696 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0786 - dense_177_accuracy: 0.0889 - dense_179_accuracy: 0.0760 - val_loss: 18.5022 - val_dense_171_loss: 6.9749 - val_dense_173_loss: 2.9357 - val_dense_175_loss: 2.9470 - val_dense_177_loss: 2.9585 - val_dense_179_loss: 2.9691 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.5497 - dense_171_loss: 2.7029 - dense_173_loss: 2.9686 - dense_175_loss: 2.9641 - dense_177_loss: 2.9670 - dense_179_loss: 2.9630 - dense_171_accuracy: 0.0773 - dense_173_accuracy: 0.1018 - dense_175_accuracy: 0.0966 - dense_177_accuracy: 0.0966 - dense_179_accuracy: 0.0889 - val_loss: 18.6202 - val_dense_171_loss: 7.1119 - val_dense_173_loss: 2.9343 - val_dense_175_loss: 2.9475 - val_dense_177_loss: 2.9508 - val_dense_179_loss: 2.9561 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.5181 - dense_171_loss: 2.7086 - dense_173_loss: 2.9584 - dense_175_loss: 2.9705 - dense_177_loss: 2.9508 - dense_179_loss: 2.9336 - dense_171_accuracy: 0.0683 - dense_173_accuracy: 0.1070 - dense_175_accuracy: 0.0786 - dense_177_accuracy: 0.1031 - dense_179_accuracy: 0.0747 - val_loss: 18.7499 - val_dense_171_loss: 7.2555 - val_dense_173_loss: 2.9333 - val_dense_175_loss: 2.9433 - val_dense_177_loss: 2.9450 - val_dense_179_loss: 2.9533 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.5340 - dense_171_loss: 2.7120 - dense_173_loss: 2.9669 - dense_175_loss: 2.9539 - dense_177_loss: 2.9505 - dense_179_loss: 2.9691 - dense_171_accuracy: 0.0696 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0863 - dense_177_accuracy: 0.0941 - dense_179_accuracy: 0.0773 - val_loss: 18.7479 - val_dense_171_loss: 7.2808 - val_dense_173_loss: 2.9343 - val_dense_175_loss: 2.9435 - val_dense_177_loss: 2.9412 - val_dense_179_loss: 2.9529 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.5177 - dense_171_loss: 2.7248 - dense_173_loss: 2.9448 - dense_175_loss: 2.9637 - dense_177_loss: 2.9398 - dense_179_loss: 2.9537 - dense_171_accuracy: 0.0735 - dense_173_accuracy: 0.0992 - dense_175_accuracy: 0.0786 - dense_177_accuracy: 0.0876 - dense_179_accuracy: 0.0876 - val_loss: 18.7604 - val_dense_171_loss: 7.3080 - val_dense_173_loss: 2.9351 - val_dense_175_loss: 2.9474 - val_dense_177_loss: 2.9449 - val_dense_179_loss: 2.9514 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4537 - dense_171_loss: 2.6867 - dense_173_loss: 2.9493 - dense_175_loss: 2.9392 - dense_177_loss: 2.9403 - dense_179_loss: 2.9400 - dense_171_accuracy: 0.0760 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0902 - dense_177_accuracy: 0.0979 - dense_179_accuracy: 0.0799 - val_loss: 18.6908 - val_dense_171_loss: 7.2297 - val_dense_173_loss: 2.9354 - val_dense_175_loss: 2.9466 - val_dense_177_loss: 2.9388 - val_dense_179_loss: 2.9506 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4842 - dense_171_loss: 2.6876 - dense_173_loss: 2.9526 - dense_175_loss: 2.9468 - dense_177_loss: 2.9359 - dense_179_loss: 2.9588 - dense_171_accuracy: 0.0747 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0709 - dense_177_accuracy: 0.1005 - dense_179_accuracy: 0.0928 - val_loss: 18.7991 - val_dense_171_loss: 7.3229 - val_dense_173_loss: 2.9360 - val_dense_175_loss: 2.9468 - val_dense_177_loss: 2.9350 - val_dense_179_loss: 2.9517 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4796 - dense_171_loss: 2.6948 - dense_173_loss: 2.9501 - dense_175_loss: 2.9455 - dense_177_loss: 2.9372 - dense_179_loss: 2.9482 - dense_171_accuracy: 0.0825 - dense_173_accuracy: 0.1018 - dense_175_accuracy: 0.0825 - dense_177_accuracy: 0.1044 - dense_179_accuracy: 0.0838 - val_loss: 18.9249 - val_dense_171_loss: 7.4563 - val_dense_173_loss: 2.9366 - val_dense_175_loss: 2.9467 - val_dense_177_loss: 2.9355 - val_dense_179_loss: 2.9498 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4666 - dense_171_loss: 2.6873 - dense_173_loss: 2.9516 - dense_175_loss: 2.9433 - dense_177_loss: 2.9388 - dense_179_loss: 2.9497 - dense_171_accuracy: 0.0747 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0941 - dense_177_accuracy: 0.0992 - dense_179_accuracy: 0.0941 - val_loss: 19.0324 - val_dense_171_loss: 7.5659 - val_dense_173_loss: 2.9371 - val_dense_175_loss: 2.9458 - val_dense_177_loss: 2.9360 - val_dense_179_loss: 2.9506 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4535 - dense_171_loss: 2.6937 - dense_173_loss: 2.9402 - dense_175_loss: 2.9255 - dense_177_loss: 2.9373 - dense_179_loss: 2.9423 - dense_171_accuracy: 0.0851 - dense_173_accuracy: 0.1031 - dense_175_accuracy: 0.0863 - dense_177_accuracy: 0.0889 - dense_179_accuracy: 0.0863 - val_loss: 19.1568 - val_dense_171_loss: 7.6841 - val_dense_173_loss: 2.9369 - val_dense_175_loss: 2.9461 - val_dense_177_loss: 2.9370 - val_dense_179_loss: 2.9595 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4471 - dense_171_loss: 2.6881 - dense_173_loss: 2.9364 - dense_175_loss: 2.9493 - dense_177_loss: 2.9308 - dense_179_loss: 2.9384 - dense_171_accuracy: 0.0863 - dense_173_accuracy: 0.1031 - dense_175_accuracy: 0.0825 - dense_177_accuracy: 0.0954 - dense_179_accuracy: 0.0954 - val_loss: 19.1840 - val_dense_171_loss: 7.7299 - val_dense_173_loss: 2.9371 - val_dense_175_loss: 2.9474 - val_dense_177_loss: 2.9331 - val_dense_179_loss: 2.9578 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4494 - dense_171_loss: 2.6786 - dense_173_loss: 2.9397 - dense_175_loss: 2.9545 - dense_177_loss: 2.9277 - dense_179_loss: 2.9484 - dense_171_accuracy: 0.0696 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0851 - dense_177_accuracy: 0.0889 - dense_179_accuracy: 0.0902 - val_loss: 19.2508 - val_dense_171_loss: 7.8100 - val_dense_173_loss: 2.9372 - val_dense_175_loss: 2.9458 - val_dense_177_loss: 2.9325 - val_dense_179_loss: 2.9568 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4340 - dense_171_loss: 2.6977 - dense_173_loss: 2.9330 - dense_175_loss: 2.9336 - dense_177_loss: 2.9243 - dense_179_loss: 2.9462 - dense_171_accuracy: 0.0735 - dense_173_accuracy: 0.1070 - dense_175_accuracy: 0.0876 - dense_177_accuracy: 0.0876 - dense_179_accuracy: 0.0683 - val_loss: 19.3205 - val_dense_171_loss: 7.8875 - val_dense_173_loss: 2.9364 - val_dense_175_loss: 2.9434 - val_dense_177_loss: 2.9265 - val_dense_179_loss: 2.9571 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4449 - dense_171_loss: 2.6844 - dense_173_loss: 2.9490 - dense_175_loss: 2.9484 - dense_177_loss: 2.9175 - dense_179_loss: 2.9446 - dense_171_accuracy: 0.0838 - dense_173_accuracy: 0.1070 - dense_175_accuracy: 0.1018 - dense_177_accuracy: 0.0979 - dense_179_accuracy: 0.0889 - val_loss: 19.4019 - val_dense_171_loss: 7.9761 - val_dense_173_loss: 2.9371 - val_dense_175_loss: 2.9432 - val_dense_177_loss: 2.9224 - val_dense_179_loss: 2.9536 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4299 - dense_171_loss: 2.6847 - dense_173_loss: 2.9455 - dense_175_loss: 2.9450 - dense_177_loss: 2.9196 - dense_179_loss: 2.9399 - dense_171_accuracy: 0.0838 - dense_173_accuracy: 0.1095 - dense_175_accuracy: 0.0851 - dense_177_accuracy: 0.0941 - dense_179_accuracy: 0.0915 - val_loss: 19.3941 - val_dense_171_loss: 7.9851 - val_dense_173_loss: 2.9363 - val_dense_175_loss: 2.9427 - val_dense_177_loss: 2.9217 - val_dense_179_loss: 2.9550 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4639 - dense_171_loss: 2.6933 - dense_173_loss: 2.9467 - dense_175_loss: 2.9411 - dense_177_loss: 2.9287 - dense_179_loss: 2.9462 - dense_171_accuracy: 0.0709 - dense_173_accuracy: 0.1057 - dense_175_accuracy: 0.0915 - dense_177_accuracy: 0.0992 - dense_179_accuracy: 0.0928 - val_loss: 19.1734 - val_dense_171_loss: 7.7490 - val_dense_173_loss: 2.9379 - val_dense_175_loss: 2.9412 - val_dense_177_loss: 2.9222 - val_dense_179_loss: 2.9563 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4468 - dense_171_loss: 2.6806 - dense_173_loss: 2.9493 - dense_175_loss: 2.9441 - dense_177_loss: 2.9270 - dense_179_loss: 2.9431 - dense_171_accuracy: 0.0760 - dense_173_accuracy: 0.1031 - dense_175_accuracy: 0.0838 - dense_177_accuracy: 0.0992 - dense_179_accuracy: 0.1070 - val_loss: 19.0999 - val_dense_171_loss: 7.6858 - val_dense_173_loss: 2.9382 - val_dense_175_loss: 2.9375 - val_dense_177_loss: 2.9236 - val_dense_179_loss: 2.9556 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.4242 - dense_171_loss: 2.6930 - dense_173_loss: 2.9423 - dense_175_loss: 2.9387 - dense_177_loss: 2.9095 - dense_179_loss: 2.9411 - dense_171_accuracy: 0.0915 - dense_173_accuracy: 0.1095 - dense_175_accuracy: 0.0915 - dense_177_accuracy: 0.1082 - dense_179_accuracy: 0.1005 - val_loss: 19.1765 - val_dense_171_loss: 7.7713 - val_dense_173_loss: 2.9384 - val_dense_175_loss: 2.9377 - val_dense_177_loss: 2.9224 - val_dense_179_loss: 2.9545 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.4349 - dense_171_loss: 2.6861 - dense_173_loss: 2.9396 - dense_175_loss: 2.9573 - dense_177_loss: 2.9038 - dense_179_loss: 2.9476 - dense_171_accuracy: 0.0760 - dense_173_accuracy: 0.0992 - dense_175_accuracy: 0.0902 - dense_177_accuracy: 0.0966 - dense_179_accuracy: 0.0915 - val_loss: 19.2687 - val_dense_171_loss: 7.8691 - val_dense_173_loss: 2.9379 - val_dense_175_loss: 2.9414 - val_dense_177_loss: 2.9207 - val_dense_179_loss: 2.9528 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4299 - dense_171_loss: 2.6962 - dense_173_loss: 2.9463 - dense_175_loss: 2.9371 - dense_177_loss: 2.9146 - dense_179_loss: 2.9436 - dense_171_accuracy: 0.0528 - dense_173_accuracy: 0.1005 - dense_175_accuracy: 0.0863 - dense_177_accuracy: 0.1031 - dense_179_accuracy: 0.0838 - val_loss: 19.2939 - val_dense_171_loss: 7.9132 - val_dense_173_loss: 2.9377 - val_dense_175_loss: 2.9384 - val_dense_177_loss: 2.9134 - val_dense_179_loss: 2.9533 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4312 - dense_171_loss: 2.6790 - dense_173_loss: 2.9335 - dense_175_loss: 2.9330 - dense_177_loss: 2.9329 - dense_179_loss: 2.9528 - dense_171_accuracy: 0.0773 - dense_173_accuracy: 0.1031 - dense_175_accuracy: 0.0825 - dense_177_accuracy: 0.0966 - dense_179_accuracy: 0.1005 - val_loss: 19.4335 - val_dense_171_loss: 8.0475 - val_dense_173_loss: 2.9380 - val_dense_175_loss: 2.9377 - val_dense_177_loss: 2.9110 - val_dense_179_loss: 2.9524 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4262 - dense_171_loss: 2.6801 - dense_173_loss: 2.9404 - dense_175_loss: 2.9451 - dense_177_loss: 2.9140 - dense_179_loss: 2.9462 - dense_171_accuracy: 0.0863 - dense_173_accuracy: 0.0979 - dense_175_accuracy: 0.0915 - dense_177_accuracy: 0.1044 - dense_179_accuracy: 0.0851 - val_loss: 19.5007 - val_dense_171_loss: 8.1174 - val_dense_173_loss: 2.9373 - val_dense_175_loss: 2.9413 - val_dense_177_loss: 2.9134 - val_dense_179_loss: 2.9489 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 7s 8ms/sample - loss: 14.4086 - dense_171_loss: 2.6830 - dense_173_loss: 2.9416 - dense_175_loss: 2.9334 - dense_177_loss: 2.9085 - dense_179_loss: 2.9396 - dense_171_accuracy: 0.0631 - dense_173_accuracy: 0.1044 - dense_175_accuracy: 0.0941 - dense_177_accuracy: 0.0966 - dense_179_accuracy: 0.1057 - val_loss: 19.5609 - val_dense_171_loss: 8.1900 - val_dense_173_loss: 2.9373 - val_dense_175_loss: 2.9405 - val_dense_177_loss: 2.9090 - val_dense_179_loss: 2.9495 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.3937 - dense_171_loss: 2.6868 - dense_173_loss: 2.9419 - dense_175_loss: 2.9307 - dense_177_loss: 2.8983 - dense_179_loss: 2.9395 - dense_171_accuracy: 0.0760 - dense_173_accuracy: 0.1031 - dense_175_accuracy: 0.0928 - dense_177_accuracy: 0.1018 - dense_179_accuracy: 0.0954 - val_loss: 19.5576 - val_dense_171_loss: 8.2018 - val_dense_173_loss: 2.9373 - val_dense_175_loss: 2.9382 - val_dense_177_loss: 2.9053 - val_dense_179_loss: 2.9468 - val_dense_171_accuracy: 0.0000e+00 - val_dense_173_accuracy: 0.0773 - val_dense_175_accuracy: 0.0979 - val_dense_177_accuracy: 0.0979 - val_dense_179_accuracy: 0.1392\n"
     ]
    }
   ],
   "source": [
    "# Passing 'categorical_crossentropy' cost_function \n",
    "model=cost_create_model('categorical_crossentropy');\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 50, 200, 16)  160         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 13, 50, 32)   128         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 5600)         0           max_pooling2d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 64)           358464      flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_182 (Dense)               (None, 64)           358464      flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_184 (Dense)               (None, 64)           358464      flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_186 (Dense)               (None, 64)           358464      flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (None, 64)           358464      flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 64)           0           dense_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 64)           0           dense_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 64)           0           dense_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 64)           0           dense_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 64)           0           dense_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_181 (Dense)               (None, 19)           1235        dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_183 (Dense)               (None, 19)           1235        dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_185 (Dense)               (None, 19)           1235        dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (None, 19)           1235        dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_189 (Dense)               (None, 19)           1235        dropout_94[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 1.9607 - dense_181_loss: 0.3972 - dense_183_loss: 0.4212 - dense_185_loss: 0.4498 - dense_187_loss: 0.3578 - dense_189_loss: 0.3158 - dense_181_accuracy: 0.0786 - dense_183_accuracy: 0.0541 - dense_185_accuracy: 0.0451 - dense_187_accuracy: 0.0709 - dense_189_accuracy: 0.0567 - val_loss: 1.0890 - val_dense_181_loss: 0.4730 - val_dense_183_loss: 0.2190 - val_dense_185_loss: 0.2104 - val_dense_187_loss: 0.1933 - val_dense_189_loss: 0.1580 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.9774 - dense_181_loss: 0.1882 - dense_183_loss: 0.2049 - dense_185_loss: 0.2284 - dense_187_loss: 0.1762 - dense_189_loss: 0.1641 - dense_181_accuracy: 0.0747 - dense_183_accuracy: 0.0567 - dense_185_accuracy: 0.0606 - dense_187_accuracy: 0.0799 - dense_189_accuracy: 0.0515 - val_loss: 0.6434 - val_dense_181_loss: 0.3742 - val_dense_183_loss: 0.1080 - val_dense_185_loss: 0.1038 - val_dense_187_loss: 0.0968 - val_dense_189_loss: 0.0803 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.5840 - dense_181_loss: 0.1159 - dense_183_loss: 0.1267 - dense_185_loss: 0.1266 - dense_187_loss: 0.1160 - dense_189_loss: 0.1025 - dense_181_accuracy: 0.0709 - dense_183_accuracy: 0.0567 - dense_185_accuracy: 0.0567 - dense_187_accuracy: 0.0722 - dense_189_accuracy: 0.0490 - val_loss: 0.4257 - val_dense_181_loss: 0.2975 - val_dense_183_loss: 0.0611 - val_dense_185_loss: 0.0600 - val_dense_187_loss: 0.0554 - val_dense_189_loss: 0.0484 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.3839 - dense_181_loss: 0.0749 - dense_183_loss: 0.0837 - dense_185_loss: 0.0806 - dense_187_loss: 0.0708 - dense_189_loss: 0.0739 - dense_181_accuracy: 0.0747 - dense_183_accuracy: 0.0528 - dense_185_accuracy: 0.0593 - dense_187_accuracy: 0.0644 - dense_189_accuracy: 0.0490 - val_loss: 0.3131 - val_dense_181_loss: 0.2449 - val_dense_183_loss: 0.0386 - val_dense_185_loss: 0.0399 - val_dense_187_loss: 0.0377 - val_dense_189_loss: 0.0315 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.2642 - dense_181_loss: 0.0450 - dense_183_loss: 0.0570 - dense_185_loss: 0.0591 - dense_187_loss: 0.0574 - dense_189_loss: 0.0452 - dense_181_accuracy: 0.0631 - dense_183_accuracy: 0.0580 - dense_185_accuracy: 0.0451 - dense_187_accuracy: 0.0657 - dense_189_accuracy: 0.0580 - val_loss: 0.2479 - val_dense_181_loss: 0.2083 - val_dense_183_loss: 0.0276 - val_dense_185_loss: 0.0281 - val_dense_187_loss: 0.0270 - val_dense_189_loss: 0.0227 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0258 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.2065 - dense_181_loss: 0.0375 - dense_183_loss: 0.0422 - dense_185_loss: 0.0493 - dense_187_loss: 0.0457 - dense_189_loss: 0.0308 - dense_181_accuracy: 0.0722 - dense_183_accuracy: 0.0631 - dense_185_accuracy: 0.0438 - dense_187_accuracy: 0.0631 - dense_189_accuracy: 0.0528 - val_loss: 0.2032 - val_dense_181_loss: 0.1785 - val_dense_183_loss: 0.0212 - val_dense_185_loss: 0.0211 - val_dense_187_loss: 0.0195 - val_dense_189_loss: 0.0175 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0258 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.1658 - dense_181_loss: 0.0322 - dense_183_loss: 0.0393 - dense_185_loss: 0.0331 - dense_187_loss: 0.0317 - dense_189_loss: 0.0326 - dense_181_accuracy: 0.0876 - dense_183_accuracy: 0.0593 - dense_185_accuracy: 0.0387 - dense_187_accuracy: 0.0567 - dense_189_accuracy: 0.0696 - val_loss: 0.1673 - val_dense_181_loss: 0.1508 - val_dense_183_loss: 0.0164 - val_dense_185_loss: 0.0165 - val_dense_187_loss: 0.0152 - val_dense_189_loss: 0.0140 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.1321 - dense_181_loss: 0.0247 - dense_183_loss: 0.0291 - dense_185_loss: 0.0269 - dense_187_loss: 0.0262 - dense_189_loss: 0.0247 - dense_181_accuracy: 0.0644 - dense_183_accuracy: 0.0554 - dense_185_accuracy: 0.0528 - dense_187_accuracy: 0.0670 - dense_189_accuracy: 0.0477 - val_loss: 0.1440 - val_dense_181_loss: 0.1315 - val_dense_183_loss: 0.0131 - val_dense_185_loss: 0.0136 - val_dense_187_loss: 0.0123 - val_dense_189_loss: 0.0111 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.1146 - dense_181_loss: 0.0242 - dense_183_loss: 0.0238 - dense_185_loss: 0.0249 - dense_187_loss: 0.0215 - dense_189_loss: 0.0202 - dense_181_accuracy: 0.0606 - dense_183_accuracy: 0.0451 - dense_185_accuracy: 0.0593 - dense_187_accuracy: 0.0593 - dense_189_accuracy: 0.0580 - val_loss: 0.1224 - val_dense_181_loss: 0.1126 - val_dense_183_loss: 0.0107 - val_dense_185_loss: 0.0112 - val_dense_187_loss: 0.0101 - val_dense_189_loss: 0.0092 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.0959 - dense_181_loss: 0.0170 - dense_183_loss: 0.0185 - dense_185_loss: 0.0216 - dense_187_loss: 0.0209 - dense_189_loss: 0.0179 - dense_181_accuracy: 0.0709 - dense_183_accuracy: 0.0477 - dense_185_accuracy: 0.0451 - dense_187_accuracy: 0.0657 - dense_189_accuracy: 0.0631 - val_loss: 0.1066 - val_dense_181_loss: 0.0984 - val_dense_183_loss: 0.0092 - val_dense_185_loss: 0.0093 - val_dense_187_loss: 0.0085 - val_dense_189_loss: 0.0077 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.0795 - dense_181_loss: 0.0151 - dense_183_loss: 0.0162 - dense_185_loss: 0.0164 - dense_187_loss: 0.0156 - dense_189_loss: 0.0163 - dense_181_accuracy: 0.0786 - dense_183_accuracy: 0.0528 - dense_185_accuracy: 0.0528 - dense_187_accuracy: 0.0722 - dense_189_accuracy: 0.0631 - val_loss: 0.0929 - val_dense_181_loss: 0.0856 - val_dense_183_loss: 0.0081 - val_dense_185_loss: 0.0081 - val_dense_187_loss: 0.0073 - val_dense_189_loss: 0.0066 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0742 - dense_181_loss: 0.0141 - dense_183_loss: 0.0159 - dense_185_loss: 0.0185 - dense_187_loss: 0.0134 - dense_189_loss: 0.0119 - dense_181_accuracy: 0.0812 - dense_183_accuracy: 0.0438 - dense_185_accuracy: 0.0515 - dense_187_accuracy: 0.0709 - dense_189_accuracy: 0.0541 - val_loss: 0.0825 - val_dense_181_loss: 0.0759 - val_dense_183_loss: 0.0070 - val_dense_185_loss: 0.0068 - val_dense_187_loss: 0.0064 - val_dense_189_loss: 0.0057 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0636 - dense_181_loss: 0.0120 - dense_183_loss: 0.0130 - dense_185_loss: 0.0134 - dense_187_loss: 0.0127 - dense_189_loss: 0.0115 - dense_181_accuracy: 0.0722 - dense_183_accuracy: 0.0541 - dense_185_accuracy: 0.0515 - dense_187_accuracy: 0.0606 - dense_189_accuracy: 0.0580 - val_loss: 0.0740 - val_dense_181_loss: 0.0679 - val_dense_183_loss: 0.0062 - val_dense_185_loss: 0.0060 - val_dense_187_loss: 0.0057 - val_dense_189_loss: 0.0050 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0608 - dense_181_loss: 0.0112 - dense_183_loss: 0.0111 - dense_185_loss: 0.0130 - dense_187_loss: 0.0125 - dense_189_loss: 0.0129 - dense_181_accuracy: 0.0657 - dense_183_accuracy: 0.0541 - dense_185_accuracy: 0.0644 - dense_187_accuracy: 0.0786 - dense_189_accuracy: 0.0541 - val_loss: 0.0669 - val_dense_181_loss: 0.0612 - val_dense_183_loss: 0.0055 - val_dense_185_loss: 0.0053 - val_dense_187_loss: 0.0050 - val_dense_189_loss: 0.0043 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.0527 - dense_181_loss: 0.0100 - dense_183_loss: 0.0103 - dense_185_loss: 0.0123 - dense_187_loss: 0.0103 - dense_189_loss: 0.0093 - dense_181_accuracy: 0.0644 - dense_183_accuracy: 0.0528 - dense_185_accuracy: 0.0451 - dense_187_accuracy: 0.0670 - dense_189_accuracy: 0.0580 - val_loss: 0.0607 - val_dense_181_loss: 0.0555 - val_dense_183_loss: 0.0049 - val_dense_185_loss: 0.0047 - val_dense_187_loss: 0.0045 - val_dense_189_loss: 0.0039 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0445 - dense_181_loss: 0.0075 - dense_183_loss: 0.0095 - dense_185_loss: 0.0095 - dense_187_loss: 0.0085 - dense_189_loss: 0.0097 - dense_181_accuracy: 0.0799 - dense_183_accuracy: 0.0567 - dense_185_accuracy: 0.0606 - dense_187_accuracy: 0.0709 - dense_189_accuracy: 0.0503 - val_loss: 0.0552 - val_dense_181_loss: 0.0504 - val_dense_183_loss: 0.0045 - val_dense_185_loss: 0.0042 - val_dense_187_loss: 0.0041 - val_dense_189_loss: 0.0035 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0451 - dense_181_loss: 0.0089 - dense_183_loss: 0.0093 - dense_185_loss: 0.0087 - dense_187_loss: 0.0103 - dense_189_loss: 0.0076 - dense_181_accuracy: 0.0644 - dense_183_accuracy: 0.0515 - dense_185_accuracy: 0.0374 - dense_187_accuracy: 0.0670 - dense_189_accuracy: 0.0593 - val_loss: 0.0507 - val_dense_181_loss: 0.0462 - val_dense_183_loss: 0.0041 - val_dense_185_loss: 0.0038 - val_dense_187_loss: 0.0036 - val_dense_189_loss: 0.0032 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0394 - dense_181_loss: 0.0077 - dense_183_loss: 0.0075 - dense_185_loss: 0.0087 - dense_187_loss: 0.0082 - dense_189_loss: 0.0070 - dense_181_accuracy: 0.0773 - dense_183_accuracy: 0.0477 - dense_185_accuracy: 0.0606 - dense_187_accuracy: 0.0657 - dense_189_accuracy: 0.0644 - val_loss: 0.0466 - val_dense_181_loss: 0.0424 - val_dense_183_loss: 0.0037 - val_dense_185_loss: 0.0035 - val_dense_187_loss: 0.0033 - val_dense_189_loss: 0.0029 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0351 - dense_181_loss: 0.0068 - dense_183_loss: 0.0081 - dense_185_loss: 0.0078 - dense_187_loss: 0.0062 - dense_189_loss: 0.0065 - dense_181_accuracy: 0.0786 - dense_183_accuracy: 0.0747 - dense_185_accuracy: 0.0399 - dense_187_accuracy: 0.0606 - dense_189_accuracy: 0.0631 - val_loss: 0.0432 - val_dense_181_loss: 0.0392 - val_dense_183_loss: 0.0034 - val_dense_185_loss: 0.0032 - val_dense_187_loss: 0.0030 - val_dense_189_loss: 0.0026 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0324 - dense_181_loss: 0.0052 - dense_183_loss: 0.0077 - dense_185_loss: 0.0071 - dense_187_loss: 0.0065 - dense_189_loss: 0.0060 - dense_181_accuracy: 0.0747 - dense_183_accuracy: 0.0554 - dense_185_accuracy: 0.0515 - dense_187_accuracy: 0.0593 - dense_189_accuracy: 0.0554 - val_loss: 0.0401 - val_dense_181_loss: 0.0363 - val_dense_183_loss: 0.0031 - val_dense_185_loss: 0.0029 - val_dense_187_loss: 0.0028 - val_dense_189_loss: 0.0024 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0329 - dense_181_loss: 0.0066 - dense_183_loss: 0.0067 - dense_185_loss: 0.0072 - dense_187_loss: 0.0065 - dense_189_loss: 0.0057 - dense_181_accuracy: 0.0825 - dense_183_accuracy: 0.0361 - dense_185_accuracy: 0.0503 - dense_187_accuracy: 0.0593 - dense_189_accuracy: 0.0567 - val_loss: 0.0372 - val_dense_181_loss: 0.0337 - val_dense_183_loss: 0.0028 - val_dense_185_loss: 0.0027 - val_dense_187_loss: 0.0026 - val_dense_189_loss: 0.0022 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.0270 - dense_181_loss: 0.0049 - dense_183_loss: 0.0058 - dense_185_loss: 0.0052 - dense_187_loss: 0.0056 - dense_189_loss: 0.0051 - dense_181_accuracy: 0.0735 - dense_183_accuracy: 0.0515 - dense_185_accuracy: 0.0619 - dense_187_accuracy: 0.0644 - dense_189_accuracy: 0.0593 - val_loss: 0.0348 - val_dense_181_loss: 0.0315 - val_dense_183_loss: 0.0026 - val_dense_185_loss: 0.0025 - val_dense_187_loss: 0.0024 - val_dense_189_loss: 0.0020 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.0255 - dense_181_loss: 0.0060 - dense_183_loss: 0.0055 - dense_185_loss: 0.0058 - dense_187_loss: 0.0049 - dense_189_loss: 0.0040 - dense_181_accuracy: 0.0876 - dense_183_accuracy: 0.0515 - dense_185_accuracy: 0.0490 - dense_187_accuracy: 0.0722 - dense_189_accuracy: 0.0747 - val_loss: 0.0325 - val_dense_181_loss: 0.0293 - val_dense_183_loss: 0.0024 - val_dense_185_loss: 0.0023 - val_dense_187_loss: 0.0022 - val_dense_189_loss: 0.0019 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.0256 - dense_181_loss: 0.0051 - dense_183_loss: 0.0050 - dense_185_loss: 0.0060 - dense_187_loss: 0.0052 - dense_189_loss: 0.0042 - dense_181_accuracy: 0.0851 - dense_183_accuracy: 0.0567 - dense_185_accuracy: 0.0503 - dense_187_accuracy: 0.0722 - dense_189_accuracy: 0.0541 - val_loss: 0.0303 - val_dense_181_loss: 0.0273 - val_dense_183_loss: 0.0022 - val_dense_185_loss: 0.0022 - val_dense_187_loss: 0.0020 - val_dense_189_loss: 0.0018 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.0221 - dense_181_loss: 0.0039 - dense_183_loss: 0.0050 - dense_185_loss: 0.0051 - dense_187_loss: 0.0040 - dense_189_loss: 0.0040 - dense_181_accuracy: 0.0683 - dense_183_accuracy: 0.0477 - dense_185_accuracy: 0.0593 - dense_187_accuracy: 0.0619 - dense_189_accuracy: 0.0528 - val_loss: 0.0285 - val_dense_181_loss: 0.0256 - val_dense_183_loss: 0.0021 - val_dense_185_loss: 0.0020 - val_dense_187_loss: 0.0019 - val_dense_189_loss: 0.0017 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.0203 - dense_181_loss: 0.0037 - dense_183_loss: 0.0045 - dense_185_loss: 0.0045 - dense_187_loss: 0.0038 - dense_189_loss: 0.0036 - dense_181_accuracy: 0.0683 - dense_183_accuracy: 0.0606 - dense_185_accuracy: 0.0490 - dense_187_accuracy: 0.0709 - dense_189_accuracy: 0.0580 - val_loss: 0.0269 - val_dense_181_loss: 0.0241 - val_dense_183_loss: 0.0020 - val_dense_185_loss: 0.0019 - val_dense_187_loss: 0.0018 - val_dense_189_loss: 0.0016 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 0.0214 - dense_181_loss: 0.0034 - dense_183_loss: 0.0048 - dense_185_loss: 0.0049 - dense_187_loss: 0.0036 - dense_189_loss: 0.0042 - dense_181_accuracy: 0.0966 - dense_183_accuracy: 0.0631 - dense_185_accuracy: 0.0567 - dense_187_accuracy: 0.0747 - dense_189_accuracy: 0.0631 - val_loss: 0.0254 - val_dense_181_loss: 0.0228 - val_dense_183_loss: 0.0018 - val_dense_185_loss: 0.0018 - val_dense_187_loss: 0.0017 - val_dense_189_loss: 0.0015 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 0.0192 - dense_181_loss: 0.0036 - dense_183_loss: 0.0041 - dense_185_loss: 0.0045 - dense_187_loss: 0.0044 - dense_189_loss: 0.0031 - dense_181_accuracy: 0.0644 - dense_183_accuracy: 0.0696 - dense_185_accuracy: 0.0644 - dense_187_accuracy: 0.0773 - dense_189_accuracy: 0.0631 - val_loss: 0.0241 - val_dense_181_loss: 0.0216 - val_dense_183_loss: 0.0017 - val_dense_185_loss: 0.0016 - val_dense_187_loss: 0.0016 - val_dense_189_loss: 0.0014 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 0.0183 - dense_181_loss: 0.0035 - dense_183_loss: 0.0039 - dense_185_loss: 0.0041 - dense_187_loss: 0.0036 - dense_189_loss: 0.0031 - dense_181_accuracy: 0.0825 - dense_183_accuracy: 0.0503 - dense_185_accuracy: 0.0451 - dense_187_accuracy: 0.0593 - dense_189_accuracy: 0.0683 - val_loss: 0.0229 - val_dense_181_loss: 0.0205 - val_dense_183_loss: 0.0016 - val_dense_185_loss: 0.0015 - val_dense_187_loss: 0.0015 - val_dense_189_loss: 0.0013 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 0.0178 - dense_181_loss: 0.0044 - dense_183_loss: 0.0033 - dense_185_loss: 0.0034 - dense_187_loss: 0.0037 - dense_189_loss: 0.0033 - dense_181_accuracy: 0.0606 - dense_183_accuracy: 0.0528 - dense_185_accuracy: 0.0503 - dense_187_accuracy: 0.0593 - dense_189_accuracy: 0.0657 - val_loss: 0.0217 - val_dense_181_loss: 0.0195 - val_dense_183_loss: 0.0015 - val_dense_185_loss: 0.0015 - val_dense_187_loss: 0.0014 - val_dense_189_loss: 0.0012 - val_dense_181_accuracy: 0.0000e+00 - val_dense_183_accuracy: 0.0464 - val_dense_185_accuracy: 0.0464 - val_dense_187_accuracy: 0.0979 - val_dense_189_accuracy: 0.0722\n"
     ]
    }
   ],
   "source": [
    "# Passing 'kullback_leibler_divergence' cost_function \n",
    "model=cost_create_model('kullback_leibler_divergence');\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 50, 200, 16)  160         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_63 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 13, 50, 32)   128         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_64 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 5600)         0           max_pooling2d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 64)           358464      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, 64)           358464      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_204 (Dense)               (None, 64)           358464      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_206 (Dense)               (None, 64)           358464      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_208 (Dense)               (None, 64)           358464      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 64)           0           dense_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 64)           0           dense_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 64)           0           dense_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 64)           0           dense_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 64)           0           dense_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, 19)           1235        dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (None, 19)           1235        dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_205 (Dense)               (None, 19)           1235        dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_207 (Dense)               (None, 19)           1235        dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_209 (Dense)               (None, 19)           1235        dropout_104[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: -1.0640 - dense_201_loss: -0.2327 - dense_203_loss: -0.2045 - dense_205_loss: -0.2147 - dense_207_loss: -0.2068 - dense_209_loss: -0.2081 - dense_201_accuracy: 0.0657 - dense_203_accuracy: 0.0528 - dense_205_accuracy: 0.0631 - dense_207_accuracy: 0.0528 - dense_209_accuracy: 0.0503 - val_loss: -0.9206 - val_dense_201_loss: -0.0418 - val_dense_203_loss: -0.2224 - val_dense_205_loss: -0.2174 - val_dense_207_loss: -0.2198 - val_dense_209_loss: -0.2298 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0361 - val_dense_207_accuracy: 0.0515 - val_dense_209_accuracy: 0.0515\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: -1.1231 - dense_201_loss: -0.2487 - dense_203_loss: -0.2177 - dense_205_loss: -0.2199 - dense_207_loss: -0.2161 - dense_209_loss: -0.2183 - dense_201_accuracy: 0.0696 - dense_203_accuracy: 0.0644 - dense_205_accuracy: 0.0709 - dense_207_accuracy: 0.0503 - dense_209_accuracy: 0.0644 - val_loss: -0.9177 - val_dense_201_loss: -0.0241 - val_dense_203_loss: -0.2259 - val_dense_205_loss: -0.2223 - val_dense_207_loss: -0.2229 - val_dense_209_loss: -0.2306 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0515 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: -1.1339 - dense_201_loss: -0.2533 - dense_203_loss: -0.2252 - dense_205_loss: -0.2186 - dense_207_loss: -0.2152 - dense_209_loss: -0.2198 - dense_201_accuracy: 0.0644 - dense_203_accuracy: 0.0593 - dense_205_accuracy: 0.0825 - dense_207_accuracy: 0.0619 - dense_209_accuracy: 0.0825 - val_loss: -0.9175 - val_dense_201_loss: -0.0171 - val_dense_203_loss: -0.2288 - val_dense_205_loss: -0.2241 - val_dense_207_loss: -0.2235 - val_dense_209_loss: -0.2298 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0515 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1530 - dense_201_loss: -0.2561 - dense_203_loss: -0.2265 - dense_205_loss: -0.2240 - dense_207_loss: -0.2191 - dense_209_loss: -0.2268 - dense_201_accuracy: 0.0825 - dense_203_accuracy: 0.0747 - dense_205_accuracy: 0.0722 - dense_207_accuracy: 0.0593 - dense_209_accuracy: 0.1005 - val_loss: -0.9237 - val_dense_201_loss: -0.0136 - val_dense_203_loss: -0.2327 - val_dense_205_loss: -0.2268 - val_dense_207_loss: -0.2248 - val_dense_209_loss: -0.2280 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1722 - dense_201_loss: -0.2621 - dense_203_loss: -0.2304 - dense_205_loss: -0.2260 - dense_207_loss: -0.2245 - dense_209_loss: -0.2265 - dense_201_accuracy: 0.0773 - dense_203_accuracy: 0.0760 - dense_205_accuracy: 0.0606 - dense_207_accuracy: 0.0915 - dense_209_accuracy: 0.0863 - val_loss: -0.9289 - val_dense_201_loss: -0.0129 - val_dense_203_loss: -0.2348 - val_dense_205_loss: -0.2272 - val_dense_207_loss: -0.2255 - val_dense_209_loss: -0.2272 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: -1.1787 - dense_201_loss: -0.2611 - dense_203_loss: -0.2318 - dense_205_loss: -0.2291 - dense_207_loss: -0.2259 - dense_209_loss: -0.2293 - dense_201_accuracy: 0.0747 - dense_203_accuracy: 0.0838 - dense_205_accuracy: 0.0889 - dense_207_accuracy: 0.0773 - dense_209_accuracy: 0.0992 - val_loss: -0.9317 - val_dense_201_loss: -0.0107 - val_dense_203_loss: -0.2362 - val_dense_205_loss: -0.2288 - val_dense_207_loss: -0.2255 - val_dense_209_loss: -0.2270 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1775 - dense_201_loss: -0.2587 - dense_203_loss: -0.2342 - dense_205_loss: -0.2315 - dense_207_loss: -0.2252 - dense_209_loss: -0.2279 - dense_201_accuracy: 0.0876 - dense_203_accuracy: 0.0825 - dense_205_accuracy: 0.0838 - dense_207_accuracy: 0.0812 - dense_209_accuracy: 0.0992 - val_loss: -0.9363 - val_dense_201_loss: -0.0105 - val_dense_203_loss: -0.2390 - val_dense_205_loss: -0.2305 - val_dense_207_loss: -0.2263 - val_dense_209_loss: -0.2277 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0515 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: -1.1794 - dense_201_loss: -0.2605 - dense_203_loss: -0.2347 - dense_205_loss: -0.2252 - dense_207_loss: -0.2248 - dense_209_loss: -0.2316 - dense_201_accuracy: 0.0657 - dense_203_accuracy: 0.0915 - dense_205_accuracy: 0.0863 - dense_207_accuracy: 0.0812 - dense_209_accuracy: 0.1070 - val_loss: -0.9384 - val_dense_201_loss: -0.0100 - val_dense_203_loss: -0.2402 - val_dense_205_loss: -0.2310 - val_dense_207_loss: -0.2260 - val_dense_209_loss: -0.2275 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0670 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1842 - dense_201_loss: -0.2613 - dense_203_loss: -0.2348 - dense_205_loss: -0.2287 - dense_207_loss: -0.2262 - dense_209_loss: -0.2324 - dense_201_accuracy: 0.0541 - dense_203_accuracy: 0.0799 - dense_205_accuracy: 0.0889 - dense_207_accuracy: 0.0799 - dense_209_accuracy: 0.1095 - val_loss: -0.9389 - val_dense_201_loss: -0.0092 - val_dense_203_loss: -0.2405 - val_dense_205_loss: -0.2311 - val_dense_207_loss: -0.2263 - val_dense_209_loss: -0.2276 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.1031 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1858 - dense_201_loss: -0.2598 - dense_203_loss: -0.2319 - dense_205_loss: -0.2312 - dense_207_loss: -0.2295 - dense_209_loss: -0.2308 - dense_201_accuracy: 0.0799 - dense_203_accuracy: 0.0928 - dense_205_accuracy: 0.0799 - dense_207_accuracy: 0.0902 - dense_209_accuracy: 0.0966 - val_loss: -0.9418 - val_dense_201_loss: -0.0095 - val_dense_203_loss: -0.2412 - val_dense_205_loss: -0.2321 - val_dense_207_loss: -0.2271 - val_dense_209_loss: -0.2268 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.1237 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: -1.1893 - dense_201_loss: -0.2648 - dense_203_loss: -0.2349 - dense_205_loss: -0.2327 - dense_207_loss: -0.2263 - dense_209_loss: -0.2290 - dense_201_accuracy: 0.0747 - dense_203_accuracy: 0.0889 - dense_205_accuracy: 0.0825 - dense_207_accuracy: 0.0876 - dense_209_accuracy: 0.1018 - val_loss: -0.9413 - val_dense_201_loss: -0.0086 - val_dense_203_loss: -0.2418 - val_dense_205_loss: -0.2316 - val_dense_207_loss: -0.2266 - val_dense_209_loss: -0.2276 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.1289 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: -1.1863 - dense_201_loss: -0.2622 - dense_203_loss: -0.2355 - dense_205_loss: -0.2317 - dense_207_loss: -0.2255 - dense_209_loss: -0.2313 - dense_201_accuracy: 0.0799 - dense_203_accuracy: 0.0954 - dense_205_accuracy: 0.0915 - dense_207_accuracy: 0.0941 - dense_209_accuracy: 0.1031 - val_loss: -0.9412 - val_dense_201_loss: -0.0084 - val_dense_203_loss: -0.2429 - val_dense_205_loss: -0.2328 - val_dense_207_loss: -0.2264 - val_dense_209_loss: -0.2270 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.1289 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: -1.1933 - dense_201_loss: -0.2634 - dense_203_loss: -0.2383 - dense_205_loss: -0.2345 - dense_207_loss: -0.2277 - dense_209_loss: -0.2301 - dense_201_accuracy: 0.0644 - dense_203_accuracy: 0.0954 - dense_205_accuracy: 0.0954 - dense_207_accuracy: 0.1018 - dense_209_accuracy: 0.1070 - val_loss: -0.9426 - val_dense_201_loss: -0.0076 - val_dense_203_loss: -0.2447 - val_dense_205_loss: -0.2329 - val_dense_207_loss: -0.2269 - val_dense_209_loss: -0.2270 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: -1.1969 - dense_201_loss: -0.2621 - dense_203_loss: -0.2369 - dense_205_loss: -0.2372 - dense_207_loss: -0.2274 - dense_209_loss: -0.2326 - dense_201_accuracy: 0.0760 - dense_203_accuracy: 0.0928 - dense_205_accuracy: 0.0902 - dense_207_accuracy: 0.0825 - dense_209_accuracy: 0.1031 - val_loss: -0.9416 - val_dense_201_loss: -0.0074 - val_dense_203_loss: -0.2439 - val_dense_205_loss: -0.2332 - val_dense_207_loss: -0.2267 - val_dense_209_loss: -0.2271 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: -1.1949 - dense_201_loss: -0.2609 - dense_203_loss: -0.2385 - dense_205_loss: -0.2316 - dense_207_loss: -0.2294 - dense_209_loss: -0.2338 - dense_201_accuracy: 0.0760 - dense_203_accuracy: 0.1005 - dense_205_accuracy: 0.0954 - dense_207_accuracy: 0.0851 - dense_209_accuracy: 0.1121 - val_loss: -0.9436 - val_dense_201_loss: -0.0081 - val_dense_203_loss: -0.2441 - val_dense_205_loss: -0.2339 - val_dense_207_loss: -0.2264 - val_dense_209_loss: -0.2286 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.1289 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: -1.2026 - dense_201_loss: -0.2638 - dense_203_loss: -0.2423 - dense_205_loss: -0.2353 - dense_207_loss: -0.2293 - dense_209_loss: -0.2307 - dense_201_accuracy: 0.0709 - dense_203_accuracy: 0.1121 - dense_205_accuracy: 0.1018 - dense_207_accuracy: 0.0979 - dense_209_accuracy: 0.1070 - val_loss: -0.9451 - val_dense_201_loss: -0.0082 - val_dense_203_loss: -0.2445 - val_dense_205_loss: -0.2345 - val_dense_207_loss: -0.2267 - val_dense_209_loss: -0.2284 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: -1.1980 - dense_201_loss: -0.2626 - dense_203_loss: -0.2378 - dense_205_loss: -0.2351 - dense_207_loss: -0.2292 - dense_209_loss: -0.2316 - dense_201_accuracy: 0.0786 - dense_203_accuracy: 0.0838 - dense_205_accuracy: 0.0928 - dense_207_accuracy: 0.1057 - dense_209_accuracy: 0.0979 - val_loss: -0.9466 - val_dense_201_loss: -0.0074 - val_dense_203_loss: -0.2463 - val_dense_205_loss: -0.2353 - val_dense_207_loss: -0.2263 - val_dense_209_loss: -0.2281 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1983 - dense_201_loss: -0.2620 - dense_203_loss: -0.2415 - dense_205_loss: -0.2327 - dense_207_loss: -0.2293 - dense_209_loss: -0.2315 - dense_201_accuracy: 0.0760 - dense_203_accuracy: 0.1044 - dense_205_accuracy: 0.1070 - dense_207_accuracy: 0.0773 - dense_209_accuracy: 0.1095 - val_loss: -0.9466 - val_dense_201_loss: -0.0077 - val_dense_203_loss: -0.2476 - val_dense_205_loss: -0.2348 - val_dense_207_loss: -0.2256 - val_dense_209_loss: -0.2296 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1972 - dense_201_loss: -0.2627 - dense_203_loss: -0.2420 - dense_205_loss: -0.2345 - dense_207_loss: -0.2261 - dense_209_loss: -0.2303 - dense_201_accuracy: 0.0722 - dense_203_accuracy: 0.1186 - dense_205_accuracy: 0.0992 - dense_207_accuracy: 0.0786 - dense_209_accuracy: 0.1070 - val_loss: -0.9487 - val_dense_201_loss: -0.0072 - val_dense_203_loss: -0.2493 - val_dense_205_loss: -0.2358 - val_dense_207_loss: -0.2260 - val_dense_209_loss: -0.2289 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: -1.2046 - dense_201_loss: -0.2625 - dense_203_loss: -0.2465 - dense_205_loss: -0.2364 - dense_207_loss: -0.2294 - dense_209_loss: -0.2320 - dense_201_accuracy: 0.0709 - dense_203_accuracy: 0.1173 - dense_205_accuracy: 0.0992 - dense_207_accuracy: 0.0799 - dense_209_accuracy: 0.1018 - val_loss: -0.9503 - val_dense_201_loss: -0.0071 - val_dense_203_loss: -0.2511 - val_dense_205_loss: -0.2357 - val_dense_207_loss: -0.2260 - val_dense_209_loss: -0.2288 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1995 - dense_201_loss: -0.2644 - dense_203_loss: -0.2415 - dense_205_loss: -0.2333 - dense_207_loss: -0.2285 - dense_209_loss: -0.2315 - dense_201_accuracy: 0.0773 - dense_203_accuracy: 0.1147 - dense_205_accuracy: 0.0966 - dense_207_accuracy: 0.0863 - dense_209_accuracy: 0.1147 - val_loss: -0.9518 - val_dense_201_loss: -0.0069 - val_dense_203_loss: -0.2517 - val_dense_205_loss: -0.2348 - val_dense_207_loss: -0.2260 - val_dense_209_loss: -0.2284 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.1982 - dense_201_loss: -0.2639 - dense_203_loss: -0.2422 - dense_205_loss: -0.2348 - dense_207_loss: -0.2293 - dense_209_loss: -0.2279 - dense_201_accuracy: 0.0773 - dense_203_accuracy: 0.1031 - dense_205_accuracy: 0.0941 - dense_207_accuracy: 0.0902 - dense_209_accuracy: 0.1095 - val_loss: -0.9530 - val_dense_201_loss: -0.0067 - val_dense_203_loss: -0.2515 - val_dense_205_loss: -0.2365 - val_dense_207_loss: -0.2261 - val_dense_209_loss: -0.2286 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2070 - dense_201_loss: -0.2639 - dense_203_loss: -0.2453 - dense_205_loss: -0.2365 - dense_207_loss: -0.2293 - dense_209_loss: -0.2322 - dense_201_accuracy: 0.0838 - dense_203_accuracy: 0.1173 - dense_205_accuracy: 0.0966 - dense_207_accuracy: 0.0928 - dense_209_accuracy: 0.1044 - val_loss: -0.9544 - val_dense_201_loss: -0.0062 - val_dense_203_loss: -0.2530 - val_dense_205_loss: -0.2356 - val_dense_207_loss: -0.2256 - val_dense_209_loss: -0.2281 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2019 - dense_201_loss: -0.2621 - dense_203_loss: -0.2450 - dense_205_loss: -0.2355 - dense_207_loss: -0.2311 - dense_209_loss: -0.2286 - dense_201_accuracy: 0.0696 - dense_203_accuracy: 0.1044 - dense_205_accuracy: 0.0979 - dense_207_accuracy: 0.0747 - dense_209_accuracy: 0.1005 - val_loss: -0.9501 - val_dense_201_loss: -0.0053 - val_dense_203_loss: -0.2485 - val_dense_205_loss: -0.2354 - val_dense_207_loss: -0.2259 - val_dense_209_loss: -0.2277 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2056 - dense_201_loss: -0.2638 - dense_203_loss: -0.2464 - dense_205_loss: -0.2349 - dense_207_loss: -0.2297 - dense_209_loss: -0.2322 - dense_201_accuracy: 0.0992 - dense_203_accuracy: 0.1134 - dense_205_accuracy: 0.1082 - dense_207_accuracy: 0.0915 - dense_209_accuracy: 0.1057 - val_loss: -0.9560 - val_dense_201_loss: -0.0057 - val_dense_203_loss: -0.2555 - val_dense_205_loss: -0.2362 - val_dense_207_loss: -0.2263 - val_dense_209_loss: -0.2252 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2062 - dense_201_loss: -0.2640 - dense_203_loss: -0.2484 - dense_205_loss: -0.2374 - dense_207_loss: -0.2277 - dense_209_loss: -0.2301 - dense_201_accuracy: 0.0722 - dense_203_accuracy: 0.1121 - dense_205_accuracy: 0.1031 - dense_207_accuracy: 0.0876 - dense_209_accuracy: 0.0992 - val_loss: -0.9581 - val_dense_201_loss: -0.0058 - val_dense_203_loss: -0.2591 - val_dense_205_loss: -0.2369 - val_dense_207_loss: -0.2268 - val_dense_209_loss: -0.2242 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: -1.2106 - dense_201_loss: -0.2632 - dense_203_loss: -0.2468 - dense_205_loss: -0.2392 - dense_207_loss: -0.2290 - dense_209_loss: -0.2323 - dense_201_accuracy: 0.0722 - dense_203_accuracy: 0.1108 - dense_205_accuracy: 0.1070 - dense_207_accuracy: 0.1018 - dense_209_accuracy: 0.1057 - val_loss: -0.9592 - val_dense_201_loss: -0.0057 - val_dense_203_loss: -0.2598 - val_dense_205_loss: -0.2360 - val_dense_207_loss: -0.2273 - val_dense_209_loss: -0.2252 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: -1.2043 - dense_201_loss: -0.2632 - dense_203_loss: -0.2457 - dense_205_loss: -0.2357 - dense_207_loss: -0.2291 - dense_209_loss: -0.2310 - dense_201_accuracy: 0.0644 - dense_203_accuracy: 0.1095 - dense_205_accuracy: 0.1031 - dense_207_accuracy: 0.1005 - dense_209_accuracy: 0.1044 - val_loss: -0.9611 - val_dense_201_loss: -0.0064 - val_dense_203_loss: -0.2592 - val_dense_205_loss: -0.2367 - val_dense_207_loss: -0.2276 - val_dense_209_loss: -0.2262 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2126 - dense_201_loss: -0.2640 - dense_203_loss: -0.2485 - dense_205_loss: -0.2381 - dense_207_loss: -0.2291 - dense_209_loss: -0.2318 - dense_201_accuracy: 0.0889 - dense_203_accuracy: 0.1147 - dense_205_accuracy: 0.1005 - dense_207_accuracy: 0.0812 - dense_209_accuracy: 0.1070 - val_loss: -0.9625 - val_dense_201_loss: -0.0068 - val_dense_203_loss: -0.2605 - val_dense_205_loss: -0.2363 - val_dense_207_loss: -0.2280 - val_dense_209_loss: -0.2270 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: -1.2117 - dense_201_loss: -0.2625 - dense_203_loss: -0.2473 - dense_205_loss: -0.2402 - dense_207_loss: -0.2301 - dense_209_loss: -0.2317 - dense_201_accuracy: 0.0786 - dense_203_accuracy: 0.1108 - dense_205_accuracy: 0.0979 - dense_207_accuracy: 0.1018 - dense_209_accuracy: 0.1108 - val_loss: -0.9630 - val_dense_201_loss: -0.0079 - val_dense_203_loss: -0.2589 - val_dense_205_loss: -0.2394 - val_dense_207_loss: -0.2281 - val_dense_209_loss: -0.2274 - val_dense_201_accuracy: 0.0000e+00 - val_dense_203_accuracy: 0.0773 - val_dense_205_accuracy: 0.0979 - val_dense_207_accuracy: 0.0979 - val_dense_209_accuracy: 0.1392\n"
     ]
    }
   ],
   "source": [
    "# Passing 'cosine_proximity' cost_function \n",
    "cosine_proximity = tf.keras.losses.CosineSimilarity(axis=1)\n",
    "model=cost_create_model(cosine_proximity);\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D : Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decreasing the number of epochs to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 50, 200, 16)  160         input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_65 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_66 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 13, 50, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 5600)         0           max_pooling2d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_210 (Dense)               (None, 64)           358464      flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_212 (Dense)               (None, 64)           358464      flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_214 (Dense)               (None, 64)           358464      flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_216 (Dense)               (None, 64)           358464      flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, 64)           358464      flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 64)           0           dense_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 64)           0           dense_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 64)           0           dense_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 64)           0           dense_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 64)           0           dense_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_211 (Dense)               (None, 19)           1235        dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_213 (Dense)               (None, 19)           1235        dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_215 (Dense)               (None, 19)           1235        dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, 19)           1235        dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_219 (Dense)               (None, 19)           1235        dropout_109[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/10\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 14.9591 - dense_211_loss: 2.8865 - dense_213_loss: 3.0054 - dense_215_loss: 3.0357 - dense_217_loss: 3.0153 - dense_219_loss: 3.0122 - dense_211_accuracy: 0.0851 - dense_213_accuracy: 0.0606 - dense_215_accuracy: 0.0438 - dense_217_accuracy: 0.0554 - dense_219_accuracy: 0.0799 - val_loss: 14.7877 - val_dense_211_loss: 3.0257 - val_dense_213_loss: 2.9413 - val_dense_215_loss: 2.9423 - val_dense_217_loss: 2.9449 - val_dense_219_loss: 2.9380 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.0773 - val_dense_215_accuracy: 0.0979 - val_dense_217_accuracy: 0.0773 - val_dense_219_accuracy: 0.1392\n",
      "Epoch 2/10\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.4618 - dense_211_loss: 2.7694 - dense_213_loss: 2.9293 - dense_215_loss: 2.9128 - dense_217_loss: 2.9261 - dense_219_loss: 2.9161 - dense_211_accuracy: 0.0851 - dense_213_accuracy: 0.0760 - dense_215_accuracy: 0.0812 - dense_217_accuracy: 0.0683 - dense_219_accuracy: 0.0979 - val_loss: 14.7687 - val_dense_211_loss: 3.0011 - val_dense_213_loss: 2.9415 - val_dense_215_loss: 2.9441 - val_dense_217_loss: 2.9444 - val_dense_219_loss: 2.9397 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.1082 - val_dense_215_accuracy: 0.0773 - val_dense_217_accuracy: 0.0928 - val_dense_219_accuracy: 0.1392\n",
      "Epoch 3/10\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.0737 - dense_211_loss: 2.5872 - dense_213_loss: 2.8419 - dense_215_loss: 2.8592 - dense_217_loss: 2.8949 - dense_219_loss: 2.8748 - dense_211_accuracy: 0.1637 - dense_213_accuracy: 0.1121 - dense_215_accuracy: 0.1031 - dense_217_accuracy: 0.0747 - dense_219_accuracy: 0.1057 - val_loss: 14.7355 - val_dense_211_loss: 3.0060 - val_dense_213_loss: 2.9266 - val_dense_215_loss: 2.9366 - val_dense_217_loss: 2.9444 - val_dense_219_loss: 2.9319 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.1186 - val_dense_215_accuracy: 0.1134 - val_dense_217_accuracy: 0.0361 - val_dense_219_accuracy: 0.1392\n",
      "Epoch 4/10\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 13.4497 - dense_211_loss: 2.3929 - dense_213_loss: 2.7257 - dense_215_loss: 2.7029 - dense_217_loss: 2.8415 - dense_219_loss: 2.7750 - dense_211_accuracy: 0.2539 - dense_213_accuracy: 0.1366 - dense_215_accuracy: 0.1662 - dense_217_accuracy: 0.1134 - dense_219_accuracy: 0.1276 - val_loss: 14.7065 - val_dense_211_loss: 3.0458 - val_dense_213_loss: 2.9046 - val_dense_215_loss: 2.9145 - val_dense_217_loss: 2.9289 - val_dense_219_loss: 2.9300 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.1959 - val_dense_215_accuracy: 0.1443 - val_dense_217_accuracy: 0.1289 - val_dense_219_accuracy: 0.1598\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 4s 6ms/sample - loss: 12.5964 - dense_211_loss: 2.1731 - dense_213_loss: 2.5271 - dense_215_loss: 2.5455 - dense_217_loss: 2.7168 - dense_219_loss: 2.6253 - dense_211_accuracy: 0.2771 - dense_213_accuracy: 0.2139 - dense_215_accuracy: 0.2049 - dense_217_accuracy: 0.1778 - dense_219_accuracy: 0.1727 - val_loss: 14.6571 - val_dense_211_loss: 3.1577 - val_dense_213_loss: 2.8557 - val_dense_215_loss: 2.8704 - val_dense_217_loss: 2.9020 - val_dense_219_loss: 2.9098 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.3144 - val_dense_215_accuracy: 0.2526 - val_dense_217_accuracy: 0.2216 - val_dense_219_accuracy: 0.2371\n",
      "Epoch 6/10\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 11.6522 - dense_211_loss: 1.9594 - dense_213_loss: 2.3212 - dense_215_loss: 2.3568 - dense_217_loss: 2.5343 - dense_219_loss: 2.4723 - dense_211_accuracy: 0.3827 - dense_213_accuracy: 0.2938 - dense_215_accuracy: 0.2964 - dense_217_accuracy: 0.2152 - dense_219_accuracy: 0.1997 - val_loss: 14.4260 - val_dense_211_loss: 3.1887 - val_dense_213_loss: 2.7708 - val_dense_215_loss: 2.8071 - val_dense_217_loss: 2.8489 - val_dense_219_loss: 2.8500 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.2887 - val_dense_215_accuracy: 0.3041 - val_dense_217_accuracy: 0.3093 - val_dense_219_accuracy: 0.2268\n",
      "Epoch 7/10\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 10.4431 - dense_211_loss: 1.6620 - dense_213_loss: 2.0528 - dense_215_loss: 2.0830 - dense_217_loss: 2.3748 - dense_219_loss: 2.2646 - dense_211_accuracy: 0.4652 - dense_213_accuracy: 0.3570 - dense_215_accuracy: 0.3505 - dense_217_accuracy: 0.2616 - dense_219_accuracy: 0.2500 - val_loss: 14.2077 - val_dense_211_loss: 3.1977 - val_dense_213_loss: 2.6852 - val_dense_215_loss: 2.7584 - val_dense_217_loss: 2.8036 - val_dense_219_loss: 2.7885 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.3557 - val_dense_215_accuracy: 0.4175 - val_dense_217_accuracy: 0.4124 - val_dense_219_accuracy: 0.2526\n",
      "Epoch 8/10\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 9.3105 - dense_211_loss: 1.3502 - dense_213_loss: 1.7550 - dense_215_loss: 1.9190 - dense_217_loss: 2.1759 - dense_219_loss: 2.1039 - dense_211_accuracy: 0.5760 - dense_213_accuracy: 0.4381 - dense_215_accuracy: 0.4265 - dense_217_accuracy: 0.2964 - dense_219_accuracy: 0.2861 - val_loss: 13.8282 - val_dense_211_loss: 3.3393 - val_dense_213_loss: 2.5164 - val_dense_215_loss: 2.6444 - val_dense_217_loss: 2.7185 - val_dense_219_loss: 2.6941 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.6392 - val_dense_215_accuracy: 0.4845 - val_dense_217_accuracy: 0.4536 - val_dense_219_accuracy: 0.3041\n",
      "Epoch 9/10\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 8.2382 - dense_211_loss: 1.1515 - dense_213_loss: 1.5299 - dense_215_loss: 1.6110 - dense_217_loss: 2.0072 - dense_219_loss: 1.9216 - dense_211_accuracy: 0.6611 - dense_213_accuracy: 0.5271 - dense_215_accuracy: 0.4742 - dense_217_accuracy: 0.3763 - dense_219_accuracy: 0.3363 - val_loss: 13.5701 - val_dense_211_loss: 3.6682 - val_dense_213_loss: 2.3489 - val_dense_215_loss: 2.4469 - val_dense_217_loss: 2.5996 - val_dense_219_loss: 2.5478 - val_dense_211_accuracy: 0.0000e+00 - val_dense_213_accuracy: 0.6959 - val_dense_215_accuracy: 0.5876 - val_dense_217_accuracy: 0.4330 - val_dense_219_accuracy: 0.3402\n",
      "Epoch 10/10\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 7.2253 - dense_211_loss: 0.8794 - dense_213_loss: 1.3119 - dense_215_loss: 1.5127 - dense_217_loss: 1.7996 - dense_219_loss: 1.7485 - dense_211_accuracy: 0.7320 - dense_213_accuracy: 0.5786 - dense_215_accuracy: 0.5219 - dense_217_accuracy: 0.4562 - dense_219_accuracy: 0.3776 - val_loss: 12.7132 - val_dense_211_loss: 3.4221 - val_dense_213_loss: 2.1862 - val_dense_215_loss: 2.3390 - val_dense_217_loss: 2.4525 - val_dense_219_loss: 2.4031 - val_dense_211_accuracy: 0.0052 - val_dense_213_accuracy: 0.8041 - val_dense_215_accuracy: 0.6804 - val_dense_217_accuracy: 0.5670 - val_dense_219_accuracy: 0.4948\n"
     ]
    }
   ],
   "source": [
    "model=create_model();\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=10,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Increasing the number of epochs to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 50, 200, 16)  160         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_68 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 50, 32)   128         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 5600)         0           max_pooling2d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_220 (Dense)               (None, 64)           358464      flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, 64)           358464      flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_224 (Dense)               (None, 64)           358464      flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_226 (Dense)               (None, 64)           358464      flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_228 (Dense)               (None, 64)           358464      flatten_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 64)           0           dense_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 64)           0           dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 64)           0           dense_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 64)           0           dense_226[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 64)           0           dense_228[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, 19)           1235        dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, 19)           1235        dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_225 (Dense)               (None, 19)           1235        dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_227 (Dense)               (None, 19)           1235        dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_229 (Dense)               (None, 19)           1235        dropout_114[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/50\n",
      "776/776 [==============================] - 7s 10ms/sample - loss: 15.0963 - dense_221_loss: 2.9373 - dense_223_loss: 3.0441 - dense_225_loss: 3.0284 - dense_227_loss: 3.0308 - dense_229_loss: 3.0319 - dense_221_accuracy: 0.0567 - dense_223_accuracy: 0.0670 - dense_225_accuracy: 0.0644 - dense_227_accuracy: 0.0709 - dense_229_accuracy: 0.0567 - val_loss: 14.8033 - val_dense_221_loss: 3.0520 - val_dense_223_loss: 2.9383 - val_dense_225_loss: 2.9380 - val_dense_227_loss: 2.9384 - val_dense_229_loss: 2.9417 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.0515 - val_dense_225_accuracy: 0.0567 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.0412\n",
      "Epoch 2/50\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.4173 - dense_221_loss: 2.7476 - dense_223_loss: 2.9008 - dense_225_loss: 2.9158 - dense_227_loss: 2.9378 - dense_229_loss: 2.9190 - dense_221_accuracy: 0.0851 - dense_223_accuracy: 0.0889 - dense_225_accuracy: 0.0838 - dense_227_accuracy: 0.0786 - dense_229_accuracy: 0.0889 - val_loss: 14.8607 - val_dense_221_loss: 3.1057 - val_dense_223_loss: 2.9292 - val_dense_225_loss: 2.9383 - val_dense_227_loss: 2.9427 - val_dense_229_loss: 2.9446 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.0773 - val_dense_225_accuracy: 0.0979 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.0722\n",
      "Epoch 3/50\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.2076 - dense_221_loss: 2.6287 - dense_223_loss: 2.8705 - dense_225_loss: 2.8711 - dense_227_loss: 2.9157 - dense_229_loss: 2.9163 - dense_221_accuracy: 0.1289 - dense_223_accuracy: 0.1057 - dense_225_accuracy: 0.0889 - dense_227_accuracy: 0.0992 - dense_229_accuracy: 0.1095 - val_loss: 14.8341 - val_dense_221_loss: 3.0961 - val_dense_223_loss: 2.9293 - val_dense_225_loss: 2.9301 - val_dense_227_loss: 2.9421 - val_dense_229_loss: 2.9373 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.0825 - val_dense_225_accuracy: 0.0979 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.1598\n",
      "Epoch 4/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.9232 - dense_221_loss: 2.5076 - dense_223_loss: 2.8269 - dense_225_loss: 2.8175 - dense_227_loss: 2.9083 - dense_229_loss: 2.8681 - dense_221_accuracy: 0.1495 - dense_223_accuracy: 0.1147 - dense_225_accuracy: 0.1031 - dense_227_accuracy: 0.0915 - dense_229_accuracy: 0.1134 - val_loss: 14.7989 - val_dense_221_loss: 3.0849 - val_dense_223_loss: 2.9234 - val_dense_225_loss: 2.9186 - val_dense_227_loss: 2.9453 - val_dense_229_loss: 2.9314 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.1031 - val_dense_225_accuracy: 0.1031 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.1392\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.5297 - dense_221_loss: 2.3606 - dense_223_loss: 2.7498 - dense_225_loss: 2.7326 - dense_227_loss: 2.8593 - dense_229_loss: 2.8228 - dense_221_accuracy: 0.1946 - dense_223_accuracy: 0.1263 - dense_225_accuracy: 0.1392 - dense_227_accuracy: 0.0825 - dense_229_accuracy: 0.1379 - val_loss: 14.8757 - val_dense_221_loss: 3.2417 - val_dense_223_loss: 2.8864 - val_dense_225_loss: 2.8929 - val_dense_227_loss: 2.9343 - val_dense_229_loss: 2.9118 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.1237 - val_dense_225_accuracy: 0.1082 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.1649\n",
      "Epoch 6/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.1593 - dense_221_loss: 2.1909 - dense_223_loss: 2.6928 - dense_225_loss: 2.6689 - dense_227_loss: 2.8364 - dense_229_loss: 2.7819 - dense_221_accuracy: 0.1997 - dense_223_accuracy: 0.1469 - dense_225_accuracy: 0.1353 - dense_227_accuracy: 0.0863 - dense_229_accuracy: 0.1173 - val_loss: 14.6768 - val_dense_221_loss: 3.0807 - val_dense_223_loss: 2.8956 - val_dense_225_loss: 2.8925 - val_dense_227_loss: 2.9137 - val_dense_229_loss: 2.8990 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.1186 - val_dense_225_accuracy: 0.1082 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.1804\n",
      "Epoch 7/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 12.8105 - dense_221_loss: 2.0939 - dense_223_loss: 2.6123 - dense_225_loss: 2.5952 - dense_227_loss: 2.7817 - dense_229_loss: 2.7222 - dense_221_accuracy: 0.2539 - dense_223_accuracy: 0.1521 - dense_225_accuracy: 0.1572 - dense_227_accuracy: 0.1018 - dense_229_accuracy: 0.1405 - val_loss: 14.5466 - val_dense_221_loss: 3.1513 - val_dense_223_loss: 2.8218 - val_dense_225_loss: 2.8398 - val_dense_227_loss: 2.8920 - val_dense_229_loss: 2.8610 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.1701 - val_dense_225_accuracy: 0.1959 - val_dense_227_accuracy: 0.0979 - val_dense_229_accuracy: 0.2062\n",
      "Epoch 8/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 12.2581 - dense_221_loss: 1.8942 - dense_223_loss: 2.5192 - dense_225_loss: 2.4928 - dense_227_loss: 2.6973 - dense_229_loss: 2.6470 - dense_221_accuracy: 0.2693 - dense_223_accuracy: 0.2075 - dense_225_accuracy: 0.1598 - dense_227_accuracy: 0.1134 - dense_229_accuracy: 0.1637 - val_loss: 14.4796 - val_dense_221_loss: 3.1849 - val_dense_223_loss: 2.8027 - val_dense_225_loss: 2.8055 - val_dense_227_loss: 2.8703 - val_dense_229_loss: 2.8373 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.2732 - val_dense_225_accuracy: 0.1753 - val_dense_227_accuracy: 0.1031 - val_dense_229_accuracy: 0.1753\n",
      "Epoch 9/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 11.6746 - dense_221_loss: 1.7027 - dense_223_loss: 2.3990 - dense_225_loss: 2.4022 - dense_227_loss: 2.6355 - dense_229_loss: 2.5318 - dense_221_accuracy: 0.3570 - dense_223_accuracy: 0.2448 - dense_225_accuracy: 0.1701 - dense_227_accuracy: 0.1302 - dense_229_accuracy: 0.1753 - val_loss: 14.2572 - val_dense_221_loss: 3.2378 - val_dense_223_loss: 2.7165 - val_dense_225_loss: 2.7591 - val_dense_227_loss: 2.8319 - val_dense_229_loss: 2.7727 - val_dense_221_accuracy: 0.0000e+00 - val_dense_223_accuracy: 0.2680 - val_dense_225_accuracy: 0.1753 - val_dense_227_accuracy: 0.1082 - val_dense_229_accuracy: 0.1959\n",
      "Epoch 10/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 11.0435 - dense_221_loss: 1.4081 - dense_223_loss: 2.3070 - dense_225_loss: 2.3694 - dense_227_loss: 2.5441 - dense_229_loss: 2.4134 - dense_221_accuracy: 0.4781 - dense_223_accuracy: 0.2461 - dense_225_accuracy: 0.1959 - dense_227_accuracy: 0.1366 - dense_229_accuracy: 0.1959 - val_loss: 13.8830 - val_dense_221_loss: 3.2571 - val_dense_223_loss: 2.5712 - val_dense_225_loss: 2.7063 - val_dense_227_loss: 2.7368 - val_dense_229_loss: 2.6881 - val_dense_221_accuracy: 0.0155 - val_dense_223_accuracy: 0.3093 - val_dense_225_accuracy: 0.1856 - val_dense_227_accuracy: 0.1031 - val_dense_229_accuracy: 0.1804\n",
      "Epoch 11/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 10.3091 - dense_221_loss: 1.1951 - dense_223_loss: 2.0834 - dense_225_loss: 2.2818 - dense_227_loss: 2.4332 - dense_229_loss: 2.3341 - dense_221_accuracy: 0.5657 - dense_223_accuracy: 0.2977 - dense_225_accuracy: 0.2320 - dense_227_accuracy: 0.1508 - dense_229_accuracy: 0.2165 - val_loss: 13.8821 - val_dense_221_loss: 3.5476 - val_dense_223_loss: 2.5211 - val_dense_225_loss: 2.5999 - val_dense_227_loss: 2.7448 - val_dense_229_loss: 2.6646 - val_dense_221_accuracy: 0.0052 - val_dense_223_accuracy: 0.4278 - val_dense_225_accuracy: 0.2216 - val_dense_227_accuracy: 0.1804 - val_dense_229_accuracy: 0.2113\n",
      "Epoch 12/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 9.5026 - dense_221_loss: 0.9725 - dense_223_loss: 1.9109 - dense_225_loss: 2.1480 - dense_227_loss: 2.3123 - dense_229_loss: 2.1367 - dense_221_accuracy: 0.6276 - dense_223_accuracy: 0.3737 - dense_225_accuracy: 0.2371 - dense_227_accuracy: 0.1637 - dense_229_accuracy: 0.2539 - val_loss: 13.2482 - val_dense_221_loss: 3.6327 - val_dense_223_loss: 2.2575 - val_dense_225_loss: 2.4990 - val_dense_227_loss: 2.6193 - val_dense_229_loss: 2.4385 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.5979 - val_dense_225_accuracy: 0.2577 - val_dense_227_accuracy: 0.2268 - val_dense_229_accuracy: 0.3196\n",
      "Epoch 13/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 8.7739 - dense_221_loss: 0.8323 - dense_223_loss: 1.6459 - dense_225_loss: 2.0356 - dense_227_loss: 2.1988 - dense_229_loss: 2.0309 - dense_221_accuracy: 0.6830 - dense_223_accuracy: 0.4265 - dense_225_accuracy: 0.2977 - dense_227_accuracy: 0.2062 - dense_229_accuracy: 0.2990 - val_loss: 13.0874 - val_dense_221_loss: 4.2968 - val_dense_223_loss: 1.9736 - val_dense_225_loss: 2.3264 - val_dense_227_loss: 2.4880 - val_dense_229_loss: 2.3119 - val_dense_221_accuracy: 0.0052 - val_dense_223_accuracy: 0.6237 - val_dense_225_accuracy: 0.3866 - val_dense_227_accuracy: 0.2784 - val_dense_229_accuracy: 0.3454\n",
      "Epoch 14/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 7.9127 - dense_221_loss: 0.7386 - dense_223_loss: 1.3711 - dense_225_loss: 1.8446 - dense_227_loss: 2.0498 - dense_229_loss: 1.9232 - dense_221_accuracy: 0.7397 - dense_223_accuracy: 0.5180 - dense_225_accuracy: 0.3235 - dense_227_accuracy: 0.2410 - dense_229_accuracy: 0.3286 - val_loss: 12.9101 - val_dense_221_loss: 4.7550 - val_dense_223_loss: 1.7143 - val_dense_225_loss: 2.0850 - val_dense_227_loss: 2.3979 - val_dense_229_loss: 2.1616 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.7268 - val_dense_225_accuracy: 0.5155 - val_dense_227_accuracy: 0.3196 - val_dense_229_accuracy: 0.3041\n",
      "Epoch 15/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 7.3352 - dense_221_loss: 0.6128 - dense_223_loss: 1.2242 - dense_225_loss: 1.7283 - dense_227_loss: 1.9725 - dense_229_loss: 1.7694 - dense_221_accuracy: 0.7693 - dense_223_accuracy: 0.5786 - dense_225_accuracy: 0.3943 - dense_227_accuracy: 0.2771 - dense_229_accuracy: 0.3827 - val_loss: 12.2669 - val_dense_221_loss: 4.8240 - val_dense_223_loss: 1.3880 - val_dense_225_loss: 1.9259 - val_dense_227_loss: 2.2492 - val_dense_229_loss: 2.0080 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.7474 - val_dense_225_accuracy: 0.4536 - val_dense_227_accuracy: 0.2526 - val_dense_229_accuracy: 0.5258\n",
      "Epoch 16/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 6.7049 - dense_221_loss: 0.5572 - dense_223_loss: 1.1201 - dense_225_loss: 1.5838 - dense_227_loss: 1.8025 - dense_229_loss: 1.6487 - dense_221_accuracy: 0.7938 - dense_223_accuracy: 0.6198 - dense_225_accuracy: 0.4755 - dense_227_accuracy: 0.3247 - dense_229_accuracy: 0.4394 - val_loss: 11.5145 - val_dense_221_loss: 5.1304 - val_dense_223_loss: 1.1911 - val_dense_225_loss: 1.6997 - val_dense_227_loss: 2.0339 - val_dense_229_loss: 1.7725 - val_dense_221_accuracy: 0.0412 - val_dense_223_accuracy: 0.7320 - val_dense_225_accuracy: 0.5979 - val_dense_227_accuracy: 0.5412 - val_dense_229_accuracy: 0.4742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 6.0284 - dense_221_loss: 0.4680 - dense_223_loss: 0.9627 - dense_225_loss: 1.3746 - dense_227_loss: 1.7061 - dense_229_loss: 1.4888 - dense_221_accuracy: 0.8454 - dense_223_accuracy: 0.6469 - dense_225_accuracy: 0.5180 - dense_227_accuracy: 0.3943 - dense_229_accuracy: 0.4807 - val_loss: 12.1275 - val_dense_221_loss: 7.1003 - val_dense_223_loss: 0.9383 - val_dense_225_loss: 1.5271 - val_dense_227_loss: 1.7608 - val_dense_229_loss: 1.5216 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.7938 - val_dense_225_accuracy: 0.6443 - val_dense_227_accuracy: 0.5876 - val_dense_229_accuracy: 0.6082\n",
      "Epoch 18/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 5.4104 - dense_221_loss: 0.4489 - dense_223_loss: 0.8591 - dense_225_loss: 1.1936 - dense_227_loss: 1.5104 - dense_229_loss: 1.4178 - dense_221_accuracy: 0.8286 - dense_223_accuracy: 0.6830 - dense_225_accuracy: 0.5825 - dense_227_accuracy: 0.4304 - dense_229_accuracy: 0.4987 - val_loss: 11.1494 - val_dense_221_loss: 6.3040 - val_dense_223_loss: 0.8399 - val_dense_225_loss: 1.2290 - val_dense_227_loss: 1.5673 - val_dense_229_loss: 1.3827 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.8299 - val_dense_225_accuracy: 0.6649 - val_dense_227_accuracy: 0.6546 - val_dense_229_accuracy: 0.6443\n",
      "Epoch 19/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 4.7818 - dense_221_loss: 0.3789 - dense_223_loss: 0.7335 - dense_225_loss: 1.0649 - dense_227_loss: 1.4470 - dense_229_loss: 1.1976 - dense_221_accuracy: 0.8389 - dense_223_accuracy: 0.7281 - dense_225_accuracy: 0.6250 - dense_227_accuracy: 0.4729 - dense_229_accuracy: 0.5722 - val_loss: 11.4718 - val_dense_221_loss: 7.0422 - val_dense_223_loss: 0.8164 - val_dense_225_loss: 1.0448 - val_dense_227_loss: 1.4666 - val_dense_229_loss: 1.2873 - val_dense_221_accuracy: 0.0412 - val_dense_223_accuracy: 0.8144 - val_dense_225_accuracy: 0.6649 - val_dense_227_accuracy: 0.6134 - val_dense_229_accuracy: 0.6753\n",
      "Epoch 20/50\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 4.5160 - dense_221_loss: 0.4041 - dense_223_loss: 0.6652 - dense_225_loss: 0.9582 - dense_227_loss: 1.3344 - dense_229_loss: 1.1377 - dense_221_accuracy: 0.8595 - dense_223_accuracy: 0.7448 - dense_225_accuracy: 0.6753 - dense_227_accuracy: 0.5052 - dense_229_accuracy: 0.6082 - val_loss: 11.0706 - val_dense_221_loss: 7.3530 - val_dense_223_loss: 0.7164 - val_dense_225_loss: 1.0101 - val_dense_227_loss: 1.1722 - val_dense_229_loss: 1.0134 - val_dense_221_accuracy: 0.0515 - val_dense_223_accuracy: 0.8196 - val_dense_225_accuracy: 0.6598 - val_dense_227_accuracy: 0.6753 - val_dense_229_accuracy: 0.7423\n",
      "Epoch 21/50\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 4.0764 - dense_221_loss: 0.3303 - dense_223_loss: 0.6568 - dense_225_loss: 0.9152 - dense_227_loss: 1.1808 - dense_229_loss: 0.9998 - dense_221_accuracy: 0.8789 - dense_223_accuracy: 0.7513 - dense_225_accuracy: 0.6546 - dense_227_accuracy: 0.5554 - dense_229_accuracy: 0.6224 - val_loss: 12.8615 - val_dense_221_loss: 9.1551 - val_dense_223_loss: 0.6514 - val_dense_225_loss: 1.0446 - val_dense_227_loss: 1.2926 - val_dense_229_loss: 0.8213 - val_dense_221_accuracy: 0.0258 - val_dense_223_accuracy: 0.8557 - val_dense_225_accuracy: 0.6856 - val_dense_227_accuracy: 0.6546 - val_dense_229_accuracy: 0.7784\n",
      "Epoch 22/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.8450 - dense_221_loss: 0.3308 - dense_223_loss: 0.5518 - dense_225_loss: 0.8427 - dense_227_loss: 1.0956 - dense_229_loss: 0.9996 - dense_221_accuracy: 0.8763 - dense_223_accuracy: 0.8041 - dense_225_accuracy: 0.7010 - dense_227_accuracy: 0.5851 - dense_229_accuracy: 0.6469 - val_loss: 12.3424 - val_dense_221_loss: 9.6846 - val_dense_223_loss: 0.5935 - val_dense_225_loss: 0.8846 - val_dense_227_loss: 0.9522 - val_dense_229_loss: 0.7683 - val_dense_221_accuracy: 0.0103 - val_dense_223_accuracy: 0.8557 - val_dense_225_accuracy: 0.6907 - val_dense_227_accuracy: 0.7320 - val_dense_229_accuracy: 0.7990\n",
      "Epoch 23/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.4740 - dense_221_loss: 0.2934 - dense_223_loss: 0.5289 - dense_225_loss: 0.7394 - dense_227_loss: 1.0277 - dense_229_loss: 0.9052 - dense_221_accuracy: 0.8930 - dense_223_accuracy: 0.8196 - dense_225_accuracy: 0.7371 - dense_227_accuracy: 0.6070 - dense_229_accuracy: 0.6598 - val_loss: 12.0441 - val_dense_221_loss: 8.8145 - val_dense_223_loss: 0.6594 - val_dense_225_loss: 0.8557 - val_dense_227_loss: 1.0376 - val_dense_229_loss: 0.7295 - val_dense_221_accuracy: 0.0258 - val_dense_223_accuracy: 0.8454 - val_dense_225_accuracy: 0.7165 - val_dense_227_accuracy: 0.7113 - val_dense_229_accuracy: 0.8041\n",
      "Epoch 24/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.2016 - dense_221_loss: 0.2597 - dense_223_loss: 0.4633 - dense_225_loss: 0.7142 - dense_227_loss: 0.9516 - dense_229_loss: 0.7632 - dense_221_accuracy: 0.9072 - dense_223_accuracy: 0.8299 - dense_225_accuracy: 0.7358 - dense_227_accuracy: 0.6289 - dense_229_accuracy: 0.7088 - val_loss: 12.2819 - val_dense_221_loss: 9.7649 - val_dense_223_loss: 0.6144 - val_dense_225_loss: 0.7627 - val_dense_227_loss: 0.9611 - val_dense_229_loss: 0.7996 - val_dense_221_accuracy: 0.0567 - val_dense_223_accuracy: 0.8247 - val_dense_225_accuracy: 0.7320 - val_dense_227_accuracy: 0.7216 - val_dense_229_accuracy: 0.7577\n",
      "Epoch 25/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.9964 - dense_221_loss: 0.2417 - dense_223_loss: 0.4250 - dense_225_loss: 0.6954 - dense_227_loss: 0.9324 - dense_229_loss: 0.6842 - dense_221_accuracy: 0.9072 - dense_223_accuracy: 0.8402 - dense_225_accuracy: 0.7693 - dense_227_accuracy: 0.6405 - dense_229_accuracy: 0.7668 - val_loss: 10.8962 - val_dense_221_loss: 8.7055 - val_dense_223_loss: 0.5565 - val_dense_225_loss: 0.7257 - val_dense_227_loss: 0.8804 - val_dense_229_loss: 0.9553 - val_dense_221_accuracy: 0.1495 - val_dense_223_accuracy: 0.8608 - val_dense_225_accuracy: 0.7474 - val_dense_227_accuracy: 0.7268 - val_dense_229_accuracy: 0.7577\n",
      "Epoch 26/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.9148 - dense_221_loss: 0.2448 - dense_223_loss: 0.4227 - dense_225_loss: 0.6096 - dense_227_loss: 0.8500 - dense_229_loss: 0.7744 - dense_221_accuracy: 0.9201 - dense_223_accuracy: 0.8402 - dense_225_accuracy: 0.7603 - dense_227_accuracy: 0.6534 - dense_229_accuracy: 0.7165 - val_loss: 12.4028 - val_dense_221_loss: 10.4554 - val_dense_223_loss: 0.5510 - val_dense_225_loss: 0.7565 - val_dense_227_loss: 0.7146 - val_dense_229_loss: 0.5793 - val_dense_221_accuracy: 0.0928 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.7526 - val_dense_227_accuracy: 0.7938 - val_dense_229_accuracy: 0.8351\n",
      "Epoch 27/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.5853 - dense_221_loss: 0.2119 - dense_223_loss: 0.3958 - dense_225_loss: 0.5459 - dense_227_loss: 0.7794 - dense_229_loss: 0.6381 - dense_221_accuracy: 0.9188 - dense_223_accuracy: 0.8518 - dense_225_accuracy: 0.7719 - dense_227_accuracy: 0.6985 - dense_229_accuracy: 0.7693 - val_loss: 13.9011 - val_dense_221_loss: 11.7420 - val_dense_223_loss: 0.5329 - val_dense_225_loss: 0.7629 - val_dense_227_loss: 0.6872 - val_dense_229_loss: 0.6119 - val_dense_221_accuracy: 0.0206 - val_dense_223_accuracy: 0.8660 - val_dense_225_accuracy: 0.7474 - val_dense_227_accuracy: 0.7887 - val_dense_229_accuracy: 0.7990\n",
      "Epoch 28/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.4858 - dense_221_loss: 0.1805 - dense_223_loss: 0.3687 - dense_225_loss: 0.5818 - dense_227_loss: 0.8329 - dense_229_loss: 0.5604 - dense_221_accuracy: 0.9446 - dense_223_accuracy: 0.8570 - dense_225_accuracy: 0.7822 - dense_227_accuracy: 0.6701 - dense_229_accuracy: 0.7784 - val_loss: 12.6438 - val_dense_221_loss: 10.7167 - val_dense_223_loss: 0.5670 - val_dense_225_loss: 0.7216 - val_dense_227_loss: 0.6252 - val_dense_229_loss: 0.5263 - val_dense_221_accuracy: 0.0825 - val_dense_223_accuracy: 0.8814 - val_dense_225_accuracy: 0.7732 - val_dense_227_accuracy: 0.7887 - val_dense_229_accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.4172 - dense_221_loss: 0.1810 - dense_223_loss: 0.3488 - dense_225_loss: 0.5356 - dense_227_loss: 0.7558 - dense_229_loss: 0.5707 - dense_221_accuracy: 0.9265 - dense_223_accuracy: 0.8582 - dense_225_accuracy: 0.7745 - dense_227_accuracy: 0.6946 - dense_229_accuracy: 0.7925 - val_loss: 13.7718 - val_dense_221_loss: 11.5839 - val_dense_223_loss: 0.5571 - val_dense_225_loss: 0.7185 - val_dense_227_loss: 0.7064 - val_dense_229_loss: 0.6626 - val_dense_221_accuracy: 0.0258 - val_dense_223_accuracy: 0.8454 - val_dense_225_accuracy: 0.7887 - val_dense_227_accuracy: 0.7680 - val_dense_229_accuracy: 0.7990\n",
      "Epoch 30/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.3457 - dense_221_loss: 0.1704 - dense_223_loss: 0.3548 - dense_225_loss: 0.4836 - dense_227_loss: 0.7850 - dense_229_loss: 0.5446 - dense_221_accuracy: 0.9265 - dense_223_accuracy: 0.8698 - dense_225_accuracy: 0.8183 - dense_227_accuracy: 0.6778 - dense_229_accuracy: 0.7861 - val_loss: 12.7271 - val_dense_221_loss: 10.8131 - val_dense_223_loss: 0.5717 - val_dense_225_loss: 0.7363 - val_dense_227_loss: 0.6088 - val_dense_229_loss: 0.5039 - val_dense_221_accuracy: 0.0876 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.7887 - val_dense_227_accuracy: 0.7990 - val_dense_229_accuracy: 0.8247\n",
      "Epoch 31/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.1763 - dense_221_loss: 0.1639 - dense_223_loss: 0.2946 - dense_225_loss: 0.4911 - dense_227_loss: 0.7127 - dense_229_loss: 0.4967 - dense_221_accuracy: 0.9459 - dense_223_accuracy: 0.8698 - dense_225_accuracy: 0.8119 - dense_227_accuracy: 0.7229 - dense_229_accuracy: 0.8041 - val_loss: 13.1153 - val_dense_221_loss: 11.0902 - val_dense_223_loss: 0.5261 - val_dense_225_loss: 0.7322 - val_dense_227_loss: 0.6727 - val_dense_229_loss: 0.6128 - val_dense_221_accuracy: 0.0619 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.7629 - val_dense_227_accuracy: 0.7526 - val_dense_229_accuracy: 0.8196\n",
      "Epoch 32/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.1496 - dense_221_loss: 0.1627 - dense_223_loss: 0.3143 - dense_225_loss: 0.4494 - dense_227_loss: 0.7614 - dense_229_loss: 0.4607 - dense_221_accuracy: 0.9369 - dense_223_accuracy: 0.8776 - dense_225_accuracy: 0.8144 - dense_227_accuracy: 0.6765 - dense_229_accuracy: 0.8260 - val_loss: 12.9142 - val_dense_221_loss: 10.9980 - val_dense_223_loss: 0.6451 - val_dense_225_loss: 0.6721 - val_dense_227_loss: 0.6165 - val_dense_229_loss: 0.4882 - val_dense_221_accuracy: 0.0464 - val_dense_223_accuracy: 0.8608 - val_dense_225_accuracy: 0.8093 - val_dense_227_accuracy: 0.8247 - val_dense_229_accuracy: 0.8557\n",
      "Epoch 33/50\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.9900 - dense_221_loss: 0.1688 - dense_223_loss: 0.2636 - dense_225_loss: 0.3989 - dense_227_loss: 0.7031 - dense_229_loss: 0.4253 - dense_221_accuracy: 0.9433 - dense_223_accuracy: 0.9059 - dense_225_accuracy: 0.8518 - dense_227_accuracy: 0.7062 - dense_229_accuracy: 0.8183 - val_loss: 13.7589 - val_dense_221_loss: 11.3337 - val_dense_223_loss: 0.6819 - val_dense_225_loss: 0.9809 - val_dense_227_loss: 0.6606 - val_dense_229_loss: 0.4576 - val_dense_221_accuracy: 0.0876 - val_dense_223_accuracy: 0.8763 - val_dense_225_accuracy: 0.7680 - val_dense_227_accuracy: 0.8093 - val_dense_229_accuracy: 0.8608\n",
      "Epoch 34/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.8647 - dense_221_loss: 0.1621 - dense_223_loss: 0.2456 - dense_225_loss: 0.4395 - dense_227_loss: 0.6292 - dense_229_loss: 0.3828 - dense_221_accuracy: 0.9485 - dense_223_accuracy: 0.8943 - dense_225_accuracy: 0.8325 - dense_227_accuracy: 0.7332 - dense_229_accuracy: 0.8466 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.7636 - val_dense_225_loss: 0.8699 - val_dense_227_loss: 0.6243 - val_dense_229_loss: 0.5440 - val_dense_221_accuracy: 0.1031 - val_dense_223_accuracy: 0.8454 - val_dense_225_accuracy: 0.7938 - val_dense_227_accuracy: 0.8093 - val_dense_229_accuracy: 0.8454\n",
      "Epoch 35/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.8564 - dense_221_loss: 0.1584 - dense_223_loss: 0.2416 - dense_225_loss: 0.3991 - dense_227_loss: 0.6216 - dense_229_loss: 0.4288 - dense_221_accuracy: 0.9369 - dense_223_accuracy: 0.9072 - dense_225_accuracy: 0.8363 - dense_227_accuracy: 0.7642 - dense_229_accuracy: 0.8415 - val_loss: 12.8611 - val_dense_221_loss: 10.8439 - val_dense_223_loss: 0.6684 - val_dense_225_loss: 0.7641 - val_dense_227_loss: 0.5779 - val_dense_229_loss: 0.6350 - val_dense_221_accuracy: 0.0773 - val_dense_223_accuracy: 0.8814 - val_dense_225_accuracy: 0.7835 - val_dense_227_accuracy: 0.8144 - val_dense_229_accuracy: 0.8402\n",
      "Epoch 36/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.8098 - dense_221_loss: 0.1367 - dense_223_loss: 0.2730 - dense_225_loss: 0.4066 - dense_227_loss: 0.6202 - dense_229_loss: 0.3472 - dense_221_accuracy: 0.9433 - dense_223_accuracy: 0.8930 - dense_225_accuracy: 0.8415 - dense_227_accuracy: 0.7487 - dense_229_accuracy: 0.8686 - val_loss: 12.9911 - val_dense_221_loss: 10.7503 - val_dense_223_loss: 0.7345 - val_dense_225_loss: 0.8280 - val_dense_227_loss: 0.6264 - val_dense_229_loss: 0.4887 - val_dense_221_accuracy: 0.1082 - val_dense_223_accuracy: 0.8814 - val_dense_225_accuracy: 0.7938 - val_dense_227_accuracy: 0.8144 - val_dense_229_accuracy: 0.8608\n",
      "Epoch 37/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.6023 - dense_221_loss: 0.1139 - dense_223_loss: 0.2179 - dense_225_loss: 0.3404 - dense_227_loss: 0.6064 - dense_229_loss: 0.3160 - dense_221_accuracy: 0.9588 - dense_223_accuracy: 0.9059 - dense_225_accuracy: 0.8621 - dense_227_accuracy: 0.7590 - dense_229_accuracy: 0.8802 - val_loss: 14.0974 - val_dense_221_loss: 11.5536 - val_dense_223_loss: 0.6836 - val_dense_225_loss: 0.9953 - val_dense_227_loss: 0.6662 - val_dense_229_loss: 0.4989 - val_dense_221_accuracy: 0.0722 - val_dense_223_accuracy: 0.8918 - val_dense_225_accuracy: 0.7938 - val_dense_227_accuracy: 0.8454 - val_dense_229_accuracy: 0.8763\n",
      "Epoch 38/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.5856 - dense_221_loss: 0.1120 - dense_223_loss: 0.2299 - dense_225_loss: 0.3698 - dense_227_loss: 0.5240 - dense_229_loss: 0.3537 - dense_221_accuracy: 0.9562 - dense_223_accuracy: 0.9021 - dense_225_accuracy: 0.8582 - dense_227_accuracy: 0.7912 - dense_229_accuracy: 0.8750 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.6854 - val_dense_225_loss: 0.7868 - val_dense_227_loss: 0.5706 - val_dense_229_loss: 0.4978 - val_dense_221_accuracy: 0.0825 - val_dense_223_accuracy: 0.8763 - val_dense_225_accuracy: 0.7990 - val_dense_227_accuracy: 0.8351 - val_dense_229_accuracy: 0.8763\n",
      "Epoch 39/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.6462 - dense_221_loss: 0.0896 - dense_223_loss: 0.2186 - dense_225_loss: 0.3635 - dense_227_loss: 0.5800 - dense_229_loss: 0.3926 - dense_221_accuracy: 0.9704 - dense_223_accuracy: 0.9240 - dense_225_accuracy: 0.8647 - dense_227_accuracy: 0.7642 - dense_229_accuracy: 0.8505 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.8431 - val_dense_225_loss: 0.8479 - val_dense_227_loss: 0.5989 - val_dense_229_loss: 0.5880 - val_dense_221_accuracy: 0.0876 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.8041 - val_dense_227_accuracy: 0.8402 - val_dense_229_accuracy: 0.8763\n",
      "Epoch 40/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.5695 - dense_221_loss: 0.0933 - dense_223_loss: 0.2452 - dense_225_loss: 0.3171 - dense_227_loss: 0.5929 - dense_229_loss: 0.3271 - dense_221_accuracy: 0.9691 - dense_223_accuracy: 0.9046 - dense_225_accuracy: 0.8802 - dense_227_accuracy: 0.7513 - dense_229_accuracy: 0.8776 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.6903 - val_dense_225_loss: 0.8683 - val_dense_227_loss: 0.6297 - val_dense_229_loss: 0.5342 - val_dense_221_accuracy: 0.1392 - val_dense_223_accuracy: 0.8814 - val_dense_225_accuracy: 0.8041 - val_dense_227_accuracy: 0.8351 - val_dense_229_accuracy: 0.8660\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.5121 - dense_221_loss: 0.0924 - dense_223_loss: 0.2611 - dense_225_loss: 0.3259 - dense_227_loss: 0.5402 - dense_229_loss: 0.2740 - dense_221_accuracy: 0.9652 - dense_223_accuracy: 0.8892 - dense_225_accuracy: 0.8634 - dense_227_accuracy: 0.7784 - dense_229_accuracy: 0.8853 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.6347 - val_dense_225_loss: 0.8074 - val_dense_227_loss: 0.6076 - val_dense_229_loss: 0.5259 - val_dense_221_accuracy: 0.0619 - val_dense_223_accuracy: 0.8763 - val_dense_225_accuracy: 0.7990 - val_dense_227_accuracy: 0.8041 - val_dense_229_accuracy: 0.8608\n",
      "Epoch 42/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.4136 - dense_221_loss: 0.1023 - dense_223_loss: 0.1901 - dense_225_loss: 0.3517 - dense_227_loss: 0.4783 - dense_229_loss: 0.3012 - dense_221_accuracy: 0.9678 - dense_223_accuracy: 0.9201 - dense_225_accuracy: 0.8647 - dense_227_accuracy: 0.8067 - dense_229_accuracy: 0.8982 - val_loss: 12.3388 - val_dense_221_loss: 10.3972 - val_dense_223_loss: 0.6507 - val_dense_225_loss: 0.7619 - val_dense_227_loss: 0.5763 - val_dense_229_loss: 0.5103 - val_dense_221_accuracy: 0.1959 - val_dense_223_accuracy: 0.8814 - val_dense_225_accuracy: 0.7990 - val_dense_227_accuracy: 0.8041 - val_dense_229_accuracy: 0.8608\n",
      "Epoch 43/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.4536 - dense_221_loss: 0.0893 - dense_223_loss: 0.2205 - dense_225_loss: 0.3238 - dense_227_loss: 0.5367 - dense_229_loss: 0.2915 - dense_221_accuracy: 0.9665 - dense_223_accuracy: 0.9188 - dense_225_accuracy: 0.8698 - dense_227_accuracy: 0.7912 - dense_229_accuracy: 0.8802 - val_loss: 13.2892 - val_dense_221_loss: 11.2779 - val_dense_223_loss: 0.6411 - val_dense_225_loss: 0.7610 - val_dense_227_loss: 0.5192 - val_dense_229_loss: 0.4985 - val_dense_221_accuracy: 0.0979 - val_dense_223_accuracy: 0.8866 - val_dense_225_accuracy: 0.8041 - val_dense_227_accuracy: 0.8196 - val_dense_229_accuracy: 0.8660\n",
      "Epoch 44/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.4694 - dense_221_loss: 0.1114 - dense_223_loss: 0.2119 - dense_225_loss: 0.3252 - dense_227_loss: 0.5240 - dense_229_loss: 0.2816 - dense_221_accuracy: 0.9523 - dense_223_accuracy: 0.9008 - dense_225_accuracy: 0.8582 - dense_227_accuracy: 0.7822 - dense_229_accuracy: 0.8853 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.7687 - val_dense_225_loss: 0.9614 - val_dense_227_loss: 0.5656 - val_dense_229_loss: 0.5441 - val_dense_221_accuracy: 0.1546 - val_dense_223_accuracy: 0.8763 - val_dense_225_accuracy: 0.7835 - val_dense_227_accuracy: 0.8402 - val_dense_229_accuracy: 0.8299\n",
      "Epoch 45/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.3357 - dense_221_loss: 0.0751 - dense_223_loss: 0.1860 - dense_225_loss: 0.2998 - dense_227_loss: 0.4849 - dense_229_loss: 0.2660 - dense_221_accuracy: 0.9704 - dense_223_accuracy: 0.9188 - dense_225_accuracy: 0.8763 - dense_227_accuracy: 0.8015 - dense_229_accuracy: 0.9021 - val_loss: 13.5784 - val_dense_221_loss: 11.4274 - val_dense_223_loss: 0.6469 - val_dense_225_loss: 0.8734 - val_dense_227_loss: 0.5170 - val_dense_229_loss: 0.4680 - val_dense_221_accuracy: 0.1082 - val_dense_223_accuracy: 0.8660 - val_dense_225_accuracy: 0.8041 - val_dense_227_accuracy: 0.8557 - val_dense_229_accuracy: 0.8711\n",
      "Epoch 46/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.3135 - dense_221_loss: 0.1106 - dense_223_loss: 0.1915 - dense_225_loss: 0.2660 - dense_227_loss: 0.4661 - dense_229_loss: 0.2948 - dense_221_accuracy: 0.9601 - dense_223_accuracy: 0.9317 - dense_225_accuracy: 0.8956 - dense_227_accuracy: 0.8015 - dense_229_accuracy: 0.8905 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.6469 - val_dense_225_loss: 0.7952 - val_dense_227_loss: 0.6290 - val_dense_229_loss: 0.4568 - val_dense_221_accuracy: 0.0722 - val_dense_223_accuracy: 0.8763 - val_dense_225_accuracy: 0.8041 - val_dense_227_accuracy: 0.8454 - val_dense_229_accuracy: 0.8660\n",
      "Epoch 47/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.2581 - dense_221_loss: 0.0705 - dense_223_loss: 0.1814 - dense_225_loss: 0.2698 - dense_227_loss: 0.4553 - dense_229_loss: 0.2627 - dense_221_accuracy: 0.9768 - dense_223_accuracy: 0.9291 - dense_225_accuracy: 0.9046 - dense_227_accuracy: 0.8247 - dense_229_accuracy: 0.8969 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.6406 - val_dense_225_loss: 0.8900 - val_dense_227_loss: 0.5435 - val_dense_229_loss: 0.5764 - val_dense_221_accuracy: 0.1907 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.8093 - val_dense_227_accuracy: 0.8454 - val_dense_229_accuracy: 0.8351\n",
      "Epoch 48/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.2106 - dense_221_loss: 0.0697 - dense_223_loss: 0.1520 - dense_225_loss: 0.2912 - dense_227_loss: 0.4546 - dense_229_loss: 0.2665 - dense_221_accuracy: 0.9716 - dense_223_accuracy: 0.9356 - dense_225_accuracy: 0.8802 - dense_227_accuracy: 0.8183 - dense_229_accuracy: 0.9059 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.8685 - val_dense_225_loss: 0.9117 - val_dense_227_loss: 0.5835 - val_dense_229_loss: 0.5134 - val_dense_221_accuracy: 0.0928 - val_dense_223_accuracy: 0.8918 - val_dense_225_accuracy: 0.8144 - val_dense_227_accuracy: 0.8557 - val_dense_229_accuracy: 0.8505\n",
      "Epoch 49/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.2127 - dense_221_loss: 0.0728 - dense_223_loss: 0.1840 - dense_225_loss: 0.2840 - dense_227_loss: 0.4193 - dense_229_loss: 0.2628 - dense_221_accuracy: 0.9768 - dense_223_accuracy: 0.9407 - dense_225_accuracy: 0.8789 - dense_227_accuracy: 0.8260 - dense_229_accuracy: 0.8982 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: nan - val_dense_225_loss: 0.8231 - val_dense_227_loss: 0.5301 - val_dense_229_loss: 0.5134 - val_dense_221_accuracy: 0.0464 - val_dense_223_accuracy: 0.8660 - val_dense_225_accuracy: 0.7990 - val_dense_227_accuracy: 0.8351 - val_dense_229_accuracy: 0.8557\n",
      "Epoch 50/50\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.2538 - dense_221_loss: 0.1045 - dense_223_loss: 0.1901 - dense_225_loss: 0.2790 - dense_227_loss: 0.4423 - dense_229_loss: 0.2569 - dense_221_accuracy: 0.9639 - dense_223_accuracy: 0.9214 - dense_225_accuracy: 0.8840 - dense_227_accuracy: 0.8209 - dense_229_accuracy: 0.9111 - val_loss: nan - val_dense_221_loss: nan - val_dense_223_loss: 0.8450 - val_dense_225_loss: 0.9437 - val_dense_227_loss: 0.6303 - val_dense_229_loss: 0.4529 - val_dense_221_accuracy: 0.0515 - val_dense_223_accuracy: 0.8711 - val_dense_225_accuracy: 0.8196 - val_dense_227_accuracy: 0.8660 - val_dense_229_accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "model=create_model();\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=50,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E : Gradient Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def grad_create_model(gradient_est):\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=gradient_est,metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 50, 200, 16)  160         input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 13, 50, 32)   128         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 5600)         0           max_pooling2d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 64)           358464      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_242 (Dense)               (None, 64)           358464      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_244 (Dense)               (None, 64)           358464      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_246 (Dense)               (None, 64)           358464      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_248 (Dense)               (None, 64)           358464      flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 64)           0           dense_240[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 64)           0           dense_242[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 64)           0           dense_244[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 64)           0           dense_246[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 64)           0           dense_248[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_241 (Dense)               (None, 19)           1235        dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_243 (Dense)               (None, 19)           1235        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_245 (Dense)               (None, 19)           1235        dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_247 (Dense)               (None, 19)           1235        dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_249 (Dense)               (None, 19)           1235        dropout_124[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 12s 15ms/sample - loss: 14.7872 - dense_241_loss: 2.8881 - dense_243_loss: 2.9780 - dense_245_loss: 2.9654 - dense_247_loss: 2.9867 - dense_249_loss: 2.9592 - dense_241_accuracy: 0.0889 - dense_243_accuracy: 0.0696 - dense_245_accuracy: 0.0619 - dense_247_accuracy: 0.0606 - dense_249_accuracy: 0.0915 - val_loss: 14.7549 - val_dense_241_loss: 2.9916 - val_dense_243_loss: 2.9365 - val_dense_245_loss: 2.9422 - val_dense_247_loss: 2.9447 - val_dense_249_loss: 2.9432 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.0773 - val_dense_245_accuracy: 0.0464 - val_dense_247_accuracy: 0.0464 - val_dense_249_accuracy: 0.0773\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 7s 8ms/sample - loss: 13.8124 - dense_241_loss: 2.5375 - dense_243_loss: 2.7609 - dense_245_loss: 2.8165 - dense_247_loss: 2.8396 - dense_249_loss: 2.8287 - dense_241_accuracy: 0.2139 - dense_243_accuracy: 0.1765 - dense_245_accuracy: 0.1198 - dense_247_accuracy: 0.0928 - dense_249_accuracy: 0.1147 - val_loss: 14.7016 - val_dense_241_loss: 2.9958 - val_dense_243_loss: 2.9235 - val_dense_245_loss: 2.9308 - val_dense_247_loss: 2.9327 - val_dense_249_loss: 2.9259 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.2320 - val_dense_245_accuracy: 0.1701 - val_dense_247_accuracy: 0.1701 - val_dense_249_accuracy: 0.1598\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 12.3377 - dense_241_loss: 2.1282 - dense_243_loss: 2.4274 - dense_245_loss: 2.5862 - dense_247_loss: 2.6430 - dense_249_loss: 2.5446 - dense_241_accuracy: 0.3518 - dense_243_accuracy: 0.2590 - dense_245_accuracy: 0.1907 - dense_247_accuracy: 0.1869 - dense_249_accuracy: 0.2062 - val_loss: 14.6569 - val_dense_241_loss: 3.0376 - val_dense_243_loss: 2.8974 - val_dense_245_loss: 2.8992 - val_dense_247_loss: 2.9130 - val_dense_249_loss: 2.9101 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.4072 - val_dense_245_accuracy: 0.1959 - val_dense_247_accuracy: 0.2680 - val_dense_249_accuracy: 0.1907\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 10.8204 - dense_241_loss: 1.6532 - dense_243_loss: 2.0725 - dense_245_loss: 2.3547 - dense_247_loss: 2.4179 - dense_249_loss: 2.3123 - dense_241_accuracy: 0.5322 - dense_243_accuracy: 0.4008 - dense_245_accuracy: 0.2874 - dense_247_accuracy: 0.2526 - dense_249_accuracy: 0.2899 - val_loss: 14.5610 - val_dense_241_loss: 3.0917 - val_dense_243_loss: 2.8358 - val_dense_245_loss: 2.8636 - val_dense_247_loss: 2.8858 - val_dense_249_loss: 2.8806 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.3660 - val_dense_245_accuracy: 0.3093 - val_dense_247_accuracy: 0.2371 - val_dense_249_accuracy: 0.2526\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 6s 8ms/sample - loss: 9.0059 - dense_241_loss: 1.1867 - dense_243_loss: 1.6478 - dense_245_loss: 2.0242 - dense_247_loss: 2.1463 - dense_249_loss: 1.9927 - dense_241_accuracy: 0.6649 - dense_243_accuracy: 0.5296 - dense_245_accuracy: 0.4253 - dense_247_accuracy: 0.3634 - dense_249_accuracy: 0.3776 - val_loss: 14.4993 - val_dense_241_loss: 3.1119 - val_dense_243_loss: 2.7995 - val_dense_245_loss: 2.8317 - val_dense_247_loss: 2.8859 - val_dense_249_loss: 2.8633 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.3969 - val_dense_245_accuracy: 0.0619 - val_dense_247_accuracy: 0.1031 - val_dense_249_accuracy: 0.1856\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 7.5602 - dense_241_loss: 0.8594 - dense_243_loss: 1.3226 - dense_245_loss: 1.6825 - dense_247_loss: 1.8744 - dense_249_loss: 1.7706 - dense_241_accuracy: 0.7758 - dense_243_accuracy: 0.6237 - dense_245_accuracy: 0.4948 - dense_247_accuracy: 0.4330 - dense_249_accuracy: 0.4691 - val_loss: 13.9910 - val_dense_241_loss: 3.1417 - val_dense_243_loss: 2.6484 - val_dense_245_loss: 2.7064 - val_dense_247_loss: 2.7646 - val_dense_249_loss: 2.7568 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.6856 - val_dense_245_accuracy: 0.3299 - val_dense_247_accuracy: 0.3402 - val_dense_249_accuracy: 0.2474\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 6.0249 - dense_241_loss: 0.6474 - dense_243_loss: 0.9887 - dense_245_loss: 1.3208 - dense_247_loss: 1.5853 - dense_249_loss: 1.4509 - dense_241_accuracy: 0.8286 - dense_243_accuracy: 0.7126 - dense_245_accuracy: 0.6173 - dense_247_accuracy: 0.5361 - dense_249_accuracy: 0.5412 - val_loss: 13.6485 - val_dense_241_loss: 3.2375 - val_dense_243_loss: 2.5148 - val_dense_245_loss: 2.5941 - val_dense_247_loss: 2.6814 - val_dense_249_loss: 2.6228 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.6340 - val_dense_245_accuracy: 0.3299 - val_dense_247_accuracy: 0.2990 - val_dense_249_accuracy: 0.2629\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 5.0844 - dense_241_loss: 0.4873 - dense_243_loss: 0.7478 - dense_245_loss: 1.1391 - dense_247_loss: 1.4417 - dense_249_loss: 1.2750 - dense_241_accuracy: 0.8634 - dense_243_accuracy: 0.7861 - dense_245_accuracy: 0.6714 - dense_247_accuracy: 0.5992 - dense_249_accuracy: 0.6121 - val_loss: 13.4409 - val_dense_241_loss: 3.2292 - val_dense_243_loss: 2.4404 - val_dense_245_loss: 2.5486 - val_dense_247_loss: 2.6172 - val_dense_249_loss: 2.6026 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.7216 - val_dense_245_accuracy: 0.3969 - val_dense_247_accuracy: 0.4485 - val_dense_249_accuracy: 0.3608\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 4.2549 - dense_241_loss: 0.4500 - dense_243_loss: 0.5851 - dense_245_loss: 0.9287 - dense_247_loss: 1.1857 - dense_249_loss: 1.1040 - dense_241_accuracy: 0.8892 - dense_243_accuracy: 0.8531 - dense_245_accuracy: 0.7384 - dense_247_accuracy: 0.6598 - dense_249_accuracy: 0.6649 - val_loss: 12.7740 - val_dense_241_loss: 3.2883 - val_dense_243_loss: 2.2535 - val_dense_245_loss: 2.3879 - val_dense_247_loss: 2.4748 - val_dense_249_loss: 2.4268 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.7732 - val_dense_245_accuracy: 0.5876 - val_dense_247_accuracy: 0.4948 - val_dense_249_accuracy: 0.5876\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.4596 - dense_241_loss: 0.3234 - dense_243_loss: 0.4964 - dense_245_loss: 0.8225 - dense_247_loss: 0.8886 - dense_249_loss: 0.9005 - dense_241_accuracy: 0.9240 - dense_243_accuracy: 0.8776 - dense_245_accuracy: 0.7526 - dense_247_accuracy: 0.7216 - dense_249_accuracy: 0.7139 - val_loss: 12.4598 - val_dense_241_loss: 3.4177 - val_dense_243_loss: 2.1780 - val_dense_245_loss: 2.2522 - val_dense_247_loss: 2.3582 - val_dense_249_loss: 2.3377 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.7784 - val_dense_245_accuracy: 0.5155 - val_dense_247_accuracy: 0.5206 - val_dense_249_accuracy: 0.5309\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.0691 - dense_241_loss: 0.2894 - dense_243_loss: 0.4548 - dense_245_loss: 0.6521 - dense_247_loss: 0.8408 - dense_249_loss: 0.8436 - dense_241_accuracy: 0.9188 - dense_243_accuracy: 0.8776 - dense_245_accuracy: 0.8015 - dense_247_accuracy: 0.7668 - dense_249_accuracy: 0.7564 - val_loss: 11.4597 - val_dense_241_loss: 3.4853 - val_dense_243_loss: 1.9123 - val_dense_245_loss: 2.0404 - val_dense_247_loss: 2.0817 - val_dense_249_loss: 2.1040 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.8351 - val_dense_245_accuracy: 0.5619 - val_dense_247_accuracy: 0.5567 - val_dense_249_accuracy: 0.6340\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 2.4996 - dense_241_loss: 0.2599 - dense_243_loss: 0.3630 - dense_245_loss: 0.5377 - dense_247_loss: 0.6336 - dense_249_loss: 0.6959 - dense_241_accuracy: 0.9291 - dense_243_accuracy: 0.8892 - dense_245_accuracy: 0.8415 - dense_247_accuracy: 0.8080 - dense_249_accuracy: 0.7977 - val_loss: 10.8040 - val_dense_241_loss: 3.5472 - val_dense_243_loss: 1.7306 - val_dense_245_loss: 1.8143 - val_dense_247_loss: 1.9108 - val_dense_249_loss: 1.9396 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.8608 - val_dense_245_accuracy: 0.6392 - val_dense_247_accuracy: 0.6134 - val_dense_249_accuracy: 0.6959\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 2.3318 - dense_241_loss: 0.2549 - dense_243_loss: 0.3002 - dense_245_loss: 0.4851 - dense_247_loss: 0.5782 - dense_249_loss: 0.7041 - dense_241_accuracy: 0.9291 - dense_243_accuracy: 0.9278 - dense_245_accuracy: 0.8582 - dense_247_accuracy: 0.8286 - dense_249_accuracy: 0.7758 - val_loss: 9.9846 - val_dense_241_loss: 3.6465 - val_dense_243_loss: 1.4628 - val_dense_245_loss: 1.5614 - val_dense_247_loss: 1.7428 - val_dense_249_loss: 1.7482 - val_dense_241_accuracy: 0.0000e+00 - val_dense_243_accuracy: 0.8299 - val_dense_245_accuracy: 0.6856 - val_dense_247_accuracy: 0.6753 - val_dense_249_accuracy: 0.7474\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.9635 - dense_241_loss: 0.1829 - dense_243_loss: 0.2487 - dense_245_loss: 0.4828 - dense_247_loss: 0.4909 - dense_249_loss: 0.5411 - dense_241_accuracy: 0.9407 - dense_243_accuracy: 0.9149 - dense_245_accuracy: 0.8376 - dense_247_accuracy: 0.8299 - dense_249_accuracy: 0.8209 - val_loss: 9.4190 - val_dense_241_loss: 4.1021 - val_dense_243_loss: 1.1481 - val_dense_245_loss: 1.3818 - val_dense_247_loss: 1.4872 - val_dense_249_loss: 1.4361 - val_dense_241_accuracy: 0.0052 - val_dense_243_accuracy: 0.8711 - val_dense_245_accuracy: 0.6856 - val_dense_247_accuracy: 0.6959 - val_dense_249_accuracy: 0.7784\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.8049 - dense_241_loss: 0.1879 - dense_243_loss: 0.2644 - dense_245_loss: 0.3674 - dense_247_loss: 0.4656 - dense_249_loss: 0.5343 - dense_241_accuracy: 0.9459 - dense_243_accuracy: 0.9317 - dense_245_accuracy: 0.8866 - dense_247_accuracy: 0.8608 - dense_249_accuracy: 0.8325 - val_loss: 9.1408 - val_dense_241_loss: 4.5064 - val_dense_243_loss: 0.9526 - val_dense_245_loss: 1.2147 - val_dense_247_loss: 1.3899 - val_dense_249_loss: 1.3164 - val_dense_241_accuracy: 0.0103 - val_dense_243_accuracy: 0.8814 - val_dense_245_accuracy: 0.7165 - val_dense_247_accuracy: 0.7010 - val_dense_249_accuracy: 0.7990\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.6024 - dense_241_loss: 0.1593 - dense_243_loss: 0.2189 - dense_245_loss: 0.3744 - dense_247_loss: 0.3801 - dense_249_loss: 0.4462 - dense_241_accuracy: 0.9485 - dense_243_accuracy: 0.9304 - dense_245_accuracy: 0.8763 - dense_247_accuracy: 0.8840 - dense_249_accuracy: 0.8802 - val_loss: 8.6639 - val_dense_241_loss: 5.1519 - val_dense_243_loss: 0.8113 - val_dense_245_loss: 0.9394 - val_dense_247_loss: 1.0647 - val_dense_249_loss: 0.9486 - val_dense_241_accuracy: 0.0103 - val_dense_243_accuracy: 0.8711 - val_dense_245_accuracy: 0.7680 - val_dense_247_accuracy: 0.7526 - val_dense_249_accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.3687 - dense_241_loss: 0.1116 - dense_243_loss: 0.2246 - dense_245_loss: 0.3100 - dense_247_loss: 0.3390 - dense_249_loss: 0.3769 - dense_241_accuracy: 0.9665 - dense_243_accuracy: 0.9304 - dense_245_accuracy: 0.8969 - dense_247_accuracy: 0.8827 - dense_249_accuracy: 0.8724 - val_loss: 8.1292 - val_dense_241_loss: 5.0781 - val_dense_243_loss: 0.6551 - val_dense_245_loss: 0.7918 - val_dense_247_loss: 0.9752 - val_dense_249_loss: 0.7887 - val_dense_241_accuracy: 0.0361 - val_dense_243_accuracy: 0.8351 - val_dense_245_accuracy: 0.7577 - val_dense_247_accuracy: 0.7835 - val_dense_249_accuracy: 0.8351\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 1.2916 - dense_241_loss: 0.1356 - dense_243_loss: 0.1618 - dense_245_loss: 0.3015 - dense_247_loss: 0.3197 - dense_249_loss: 0.3513 - dense_241_accuracy: 0.9626 - dense_243_accuracy: 0.9510 - dense_245_accuracy: 0.9059 - dense_247_accuracy: 0.8995 - dense_249_accuracy: 0.8956 - val_loss: 8.5511 - val_dense_241_loss: 5.6937 - val_dense_243_loss: 0.6525 - val_dense_245_loss: 0.7769 - val_dense_247_loss: 0.9171 - val_dense_249_loss: 0.8339 - val_dense_241_accuracy: 0.0412 - val_dense_243_accuracy: 0.8763 - val_dense_245_accuracy: 0.7887 - val_dense_247_accuracy: 0.7887 - val_dense_249_accuracy: 0.8505\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.2245 - dense_241_loss: 0.1294 - dense_243_loss: 0.1864 - dense_245_loss: 0.2482 - dense_247_loss: 0.3268 - dense_249_loss: 0.3291 - dense_241_accuracy: 0.9626 - dense_243_accuracy: 0.9343 - dense_245_accuracy: 0.9291 - dense_247_accuracy: 0.8943 - dense_249_accuracy: 0.8905 - val_loss: 8.3822 - val_dense_241_loss: 5.9125 - val_dense_243_loss: 0.5792 - val_dense_245_loss: 0.6978 - val_dense_247_loss: 0.8622 - val_dense_249_loss: 0.7130 - val_dense_241_accuracy: 0.0412 - val_dense_243_accuracy: 0.8814 - val_dense_245_accuracy: 0.7680 - val_dense_247_accuracy: 0.8041 - val_dense_249_accuracy: 0.8866\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.0784 - dense_241_loss: 0.1116 - dense_243_loss: 0.1971 - dense_245_loss: 0.2137 - dense_247_loss: 0.2524 - dense_249_loss: 0.3022 - dense_241_accuracy: 0.9652 - dense_243_accuracy: 0.9330 - dense_245_accuracy: 0.9420 - dense_247_accuracy: 0.9265 - dense_249_accuracy: 0.8969 - val_loss: 8.8188 - val_dense_241_loss: 6.3341 - val_dense_243_loss: 0.5706 - val_dense_245_loss: 0.6714 - val_dense_247_loss: 0.8608 - val_dense_249_loss: 0.6577 - val_dense_241_accuracy: 0.0361 - val_dense_243_accuracy: 0.8711 - val_dense_245_accuracy: 0.7577 - val_dense_247_accuracy: 0.7835 - val_dense_249_accuracy: 0.8454\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.0809 - dense_241_loss: 0.1073 - dense_243_loss: 0.1826 - dense_245_loss: 0.2074 - dense_247_loss: 0.2699 - dense_249_loss: 0.3200 - dense_241_accuracy: 0.9665 - dense_243_accuracy: 0.9472 - dense_245_accuracy: 0.9343 - dense_247_accuracy: 0.9162 - dense_249_accuracy: 0.9085 - val_loss: 9.1150 - val_dense_241_loss: 6.9268 - val_dense_243_loss: 0.6929 - val_dense_245_loss: 0.6279 - val_dense_247_loss: 0.7497 - val_dense_249_loss: 0.6121 - val_dense_241_accuracy: 0.0464 - val_dense_243_accuracy: 0.8557 - val_dense_245_accuracy: 0.8041 - val_dense_247_accuracy: 0.8093 - val_dense_249_accuracy: 0.8660\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.9557 - dense_241_loss: 0.1257 - dense_243_loss: 0.1361 - dense_245_loss: 0.1872 - dense_247_loss: 0.2293 - dense_249_loss: 0.2829 - dense_241_accuracy: 0.9665 - dense_243_accuracy: 0.9652 - dense_245_accuracy: 0.9459 - dense_247_accuracy: 0.9175 - dense_249_accuracy: 0.9162 - val_loss: 9.1311 - val_dense_241_loss: 7.0758 - val_dense_243_loss: 0.5715 - val_dense_245_loss: 0.5904 - val_dense_247_loss: 0.7578 - val_dense_249_loss: 0.5182 - val_dense_241_accuracy: 0.0619 - val_dense_243_accuracy: 0.8866 - val_dense_245_accuracy: 0.8196 - val_dense_247_accuracy: 0.8247 - val_dense_249_accuracy: 0.8711\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 0.9086 - dense_241_loss: 0.0955 - dense_243_loss: 0.1359 - dense_245_loss: 0.1897 - dense_247_loss: 0.2088 - dense_249_loss: 0.2765 - dense_241_accuracy: 0.9729 - dense_243_accuracy: 0.9613 - dense_245_accuracy: 0.9381 - dense_247_accuracy: 0.9253 - dense_249_accuracy: 0.9098 - val_loss: 11.3984 - val_dense_241_loss: 9.0566 - val_dense_243_loss: 0.6964 - val_dense_245_loss: 0.6130 - val_dense_247_loss: 0.7526 - val_dense_249_loss: 0.4406 - val_dense_241_accuracy: 0.0515 - val_dense_243_accuracy: 0.8454 - val_dense_245_accuracy: 0.7938 - val_dense_247_accuracy: 0.8351 - val_dense_249_accuracy: 0.8814\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 0.8537 - dense_241_loss: 0.0835 - dense_243_loss: 0.1038 - dense_245_loss: 0.1639 - dense_247_loss: 0.2285 - dense_249_loss: 0.2826 - dense_241_accuracy: 0.9794 - dense_243_accuracy: 0.9678 - dense_245_accuracy: 0.9472 - dense_247_accuracy: 0.9278 - dense_249_accuracy: 0.9059 - val_loss: 12.5255 - val_dense_241_loss: 10.4384 - val_dense_243_loss: 0.6618 - val_dense_245_loss: 0.6569 - val_dense_247_loss: 0.9039 - val_dense_249_loss: 0.5016 - val_dense_241_accuracy: 0.1031 - val_dense_243_accuracy: 0.8557 - val_dense_245_accuracy: 0.8144 - val_dense_247_accuracy: 0.8041 - val_dense_249_accuracy: 0.8454\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 7s 10ms/sample - loss: 0.8219 - dense_241_loss: 0.0695 - dense_243_loss: 0.1111 - dense_245_loss: 0.1807 - dense_247_loss: 0.2291 - dense_249_loss: 0.2335 - dense_241_accuracy: 0.9807 - dense_243_accuracy: 0.9665 - dense_245_accuracy: 0.9420 - dense_247_accuracy: 0.9381 - dense_249_accuracy: 0.9149 - val_loss: 12.1230 - val_dense_241_loss: 10.2226 - val_dense_243_loss: 0.5509 - val_dense_245_loss: 0.6473 - val_dense_247_loss: 0.7750 - val_dense_249_loss: 0.4726 - val_dense_241_accuracy: 0.1237 - val_dense_243_accuracy: 0.8918 - val_dense_245_accuracy: 0.8247 - val_dense_247_accuracy: 0.8196 - val_dense_249_accuracy: 0.8608\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: 0.7255 - dense_241_loss: 0.0826 - dense_243_loss: 0.1120 - dense_245_loss: 0.1450 - dense_247_loss: 0.1869 - dense_249_loss: 0.2122 - dense_241_accuracy: 0.9678 - dense_243_accuracy: 0.9652 - dense_245_accuracy: 0.9588 - dense_247_accuracy: 0.9394 - dense_249_accuracy: 0.9265 - val_loss: 12.4799 - val_dense_241_loss: 10.4237 - val_dense_243_loss: 0.6070 - val_dense_245_loss: 0.6321 - val_dense_247_loss: 0.7158 - val_dense_249_loss: 0.4177 - val_dense_241_accuracy: 0.0928 - val_dense_243_accuracy: 0.8814 - val_dense_245_accuracy: 0.8247 - val_dense_247_accuracy: 0.8402 - val_dense_249_accuracy: 0.8505\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 7s 10ms/sample - loss: 0.7472 - dense_241_loss: 0.0825 - dense_243_loss: 0.0906 - dense_245_loss: 0.1653 - dense_247_loss: 0.1741 - dense_249_loss: 0.2261 - dense_241_accuracy: 0.9755 - dense_243_accuracy: 0.9704 - dense_245_accuracy: 0.9497 - dense_247_accuracy: 0.9343 - dense_249_accuracy: 0.9214 - val_loss: 13.9109 - val_dense_241_loss: 11.4088 - val_dense_243_loss: 0.8287 - val_dense_245_loss: 0.7406 - val_dense_247_loss: 0.9048 - val_dense_249_loss: 0.5788 - val_dense_241_accuracy: 0.0670 - val_dense_243_accuracy: 0.8814 - val_dense_245_accuracy: 0.8351 - val_dense_247_accuracy: 0.7887 - val_dense_249_accuracy: 0.8711\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 0.7101 - dense_241_loss: 0.0736 - dense_243_loss: 0.1290 - dense_245_loss: 0.1243 - dense_247_loss: 0.1635 - dense_249_loss: 0.2170 - dense_241_accuracy: 0.9716 - dense_243_accuracy: 0.9601 - dense_245_accuracy: 0.9523 - dense_247_accuracy: 0.9485 - dense_249_accuracy: 0.9317 - val_loss: 12.2375 - val_dense_241_loss: 10.0915 - val_dense_243_loss: 0.5783 - val_dense_245_loss: 0.7711 - val_dense_247_loss: 0.7669 - val_dense_249_loss: 0.5534 - val_dense_241_accuracy: 0.1237 - val_dense_243_accuracy: 0.8660 - val_dense_245_accuracy: 0.8041 - val_dense_247_accuracy: 0.8351 - val_dense_249_accuracy: 0.8402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: 0.7190 - dense_241_loss: 0.1044 - dense_243_loss: 0.0962 - dense_245_loss: 0.1514 - dense_247_loss: 0.1683 - dense_249_loss: 0.1886 - dense_241_accuracy: 0.9652 - dense_243_accuracy: 0.9729 - dense_245_accuracy: 0.9523 - dense_247_accuracy: 0.9356 - dense_249_accuracy: 0.9394 - val_loss: 12.9850 - val_dense_241_loss: 10.5855 - val_dense_243_loss: 0.7126 - val_dense_245_loss: 0.8262 - val_dense_247_loss: 0.7581 - val_dense_249_loss: 0.5203 - val_dense_241_accuracy: 0.0825 - val_dense_243_accuracy: 0.8608 - val_dense_245_accuracy: 0.7938 - val_dense_247_accuracy: 0.8247 - val_dense_249_accuracy: 0.8814\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 7s 9ms/sample - loss: 0.6359 - dense_241_loss: 0.0514 - dense_243_loss: 0.0942 - dense_245_loss: 0.1305 - dense_247_loss: 0.1532 - dense_249_loss: 0.2034 - dense_241_accuracy: 0.9820 - dense_243_accuracy: 0.9678 - dense_245_accuracy: 0.9626 - dense_247_accuracy: 0.9420 - dense_249_accuracy: 0.9381 - val_loss: 14.3503 - val_dense_241_loss: 11.8179 - val_dense_243_loss: 0.6324 - val_dense_245_loss: 0.8160 - val_dense_247_loss: 0.9179 - val_dense_249_loss: 0.8533 - val_dense_241_accuracy: 0.0670 - val_dense_243_accuracy: 0.8969 - val_dense_245_accuracy: 0.8144 - val_dense_247_accuracy: 0.8093 - val_dense_249_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "gradient_est = 'Nadam'\n",
    "model = grad_create_model(gradient_est)\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 50, 200, 16)  160         input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 13, 50, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 5600)         0           max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_250 (Dense)               (None, 64)           358464      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_252 (Dense)               (None, 64)           358464      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 64)           358464      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 64)           358464      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 64)           358464      flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 64)           0           dense_250[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 64)           0           dense_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 64)           0           dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 64)           0           dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 64)           0           dense_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_251 (Dense)               (None, 19)           1235        dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 19)           1235        dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 19)           1235        dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 19)           1235        dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_259 (Dense)               (None, 19)           1235        dropout_129[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 14.7950 - dense_251_loss: 2.9286 - dense_253_loss: 2.9646 - dense_255_loss: 2.9833 - dense_257_loss: 2.9659 - dense_259_loss: 2.9517 - dense_251_accuracy: 0.0696 - dense_253_accuracy: 0.0593 - dense_255_accuracy: 0.0451 - dense_257_accuracy: 0.0567 - dense_259_accuracy: 0.0709 - val_loss: 14.7139 - val_dense_251_loss: 2.9660 - val_dense_253_loss: 2.9412 - val_dense_255_loss: 2.9339 - val_dense_257_loss: 2.9427 - val_dense_259_loss: 2.9395 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.0825 - val_dense_255_accuracy: 0.0361 - val_dense_257_accuracy: 0.0722 - val_dense_259_accuracy: 0.1546\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 4s 5ms/sample - loss: 14.5618 - dense_251_loss: 2.8469 - dense_253_loss: 2.9104 - dense_255_loss: 2.9430 - dense_257_loss: 2.9329 - dense_259_loss: 2.9262 - dense_251_accuracy: 0.0889 - dense_253_accuracy: 0.0812 - dense_255_accuracy: 0.0696 - dense_257_accuracy: 0.0760 - dense_259_accuracy: 0.1005 - val_loss: 14.7261 - val_dense_251_loss: 2.9792 - val_dense_253_loss: 2.9393 - val_dense_255_loss: 2.9362 - val_dense_257_loss: 2.9414 - val_dense_259_loss: 2.9386 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.0773 - val_dense_255_accuracy: 0.0979 - val_dense_257_accuracy: 0.0722 - val_dense_259_accuracy: 0.0979\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 4s 5ms/sample - loss: 14.4308 - dense_251_loss: 2.8101 - dense_253_loss: 2.8884 - dense_255_loss: 2.9100 - dense_257_loss: 2.9270 - dense_259_loss: 2.8810 - dense_251_accuracy: 0.0992 - dense_253_accuracy: 0.0889 - dense_255_accuracy: 0.0747 - dense_257_accuracy: 0.0670 - dense_259_accuracy: 0.0941 - val_loss: 14.7335 - val_dense_251_loss: 3.0012 - val_dense_253_loss: 2.9341 - val_dense_255_loss: 2.9335 - val_dense_257_loss: 2.9426 - val_dense_259_loss: 2.9363 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.0567 - val_dense_255_accuracy: 0.0979 - val_dense_257_accuracy: 0.0979 - val_dense_259_accuracy: 0.1340\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 14.2554 - dense_251_loss: 2.7667 - dense_253_loss: 2.8475 - dense_255_loss: 2.8894 - dense_257_loss: 2.8995 - dense_259_loss: 2.8565 - dense_251_accuracy: 0.0889 - dense_253_accuracy: 0.1082 - dense_255_accuracy: 0.0851 - dense_257_accuracy: 0.1044 - dense_259_accuracy: 0.1160 - val_loss: 14.7298 - val_dense_251_loss: 2.9987 - val_dense_253_loss: 2.9311 - val_dense_255_loss: 2.9350 - val_dense_257_loss: 2.9364 - val_dense_259_loss: 2.9327 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.0722 - val_dense_255_accuracy: 0.0619 - val_dense_257_accuracy: 0.0619 - val_dense_259_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 4s 5ms/sample - loss: 14.0702 - dense_251_loss: 2.7126 - dense_253_loss: 2.7966 - dense_255_loss: 2.8645 - dense_257_loss: 2.8822 - dense_259_loss: 2.8081 - dense_251_accuracy: 0.1044 - dense_253_accuracy: 0.1263 - dense_255_accuracy: 0.1044 - dense_257_accuracy: 0.1070 - dense_259_accuracy: 0.1211 - val_loss: 14.7074 - val_dense_251_loss: 3.0150 - val_dense_253_loss: 2.9248 - val_dense_255_loss: 2.9303 - val_dense_257_loss: 2.9338 - val_dense_259_loss: 2.9274 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.1649 - val_dense_255_accuracy: 0.0928 - val_dense_257_accuracy: 0.0773 - val_dense_259_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 13.7807 - dense_251_loss: 2.6410 - dense_253_loss: 2.6919 - dense_255_loss: 2.8152 - dense_257_loss: 2.8384 - dense_259_loss: 2.7772 - dense_251_accuracy: 0.1353 - dense_253_accuracy: 0.1572 - dense_255_accuracy: 0.1198 - dense_257_accuracy: 0.1250 - dense_259_accuracy: 0.1366 - val_loss: 14.7385 - val_dense_251_loss: 3.1027 - val_dense_253_loss: 2.8977 - val_dense_255_loss: 2.9217 - val_dense_257_loss: 2.9264 - val_dense_259_loss: 2.9207 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.2113 - val_dense_255_accuracy: 0.0361 - val_dense_257_accuracy: 0.1031 - val_dense_259_accuracy: 0.0876\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 4s 5ms/sample - loss: 13.4174 - dense_251_loss: 2.5704 - dense_253_loss: 2.6095 - dense_255_loss: 2.7689 - dense_257_loss: 2.7652 - dense_259_loss: 2.6922 - dense_251_accuracy: 0.1688 - dense_253_accuracy: 0.2371 - dense_255_accuracy: 0.1211 - dense_257_accuracy: 0.1482 - dense_259_accuracy: 0.1572 - val_loss: 14.6795 - val_dense_251_loss: 3.1150 - val_dense_253_loss: 2.8846 - val_dense_255_loss: 2.9102 - val_dense_257_loss: 2.9102 - val_dense_259_loss: 2.9007 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.1546 - val_dense_255_accuracy: 0.0361 - val_dense_257_accuracy: 0.1392 - val_dense_259_accuracy: 0.1186\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 4s 5ms/sample - loss: 13.0503 - dense_251_loss: 2.5163 - dense_253_loss: 2.5087 - dense_255_loss: 2.7043 - dense_257_loss: 2.7211 - dense_259_loss: 2.6119 - dense_251_accuracy: 0.1907 - dense_253_accuracy: 0.2603 - dense_255_accuracy: 0.1289 - dense_257_accuracy: 0.1804 - dense_259_accuracy: 0.1881 - val_loss: 14.5115 - val_dense_251_loss: 3.0465 - val_dense_253_loss: 2.8246 - val_dense_255_loss: 2.8923 - val_dense_257_loss: 2.8901 - val_dense_259_loss: 2.8711 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.0876 - val_dense_255_accuracy: 0.0361 - val_dense_257_accuracy: 0.1134 - val_dense_259_accuracy: 0.1340\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 12.6581 - dense_251_loss: 2.4330 - dense_253_loss: 2.4216 - dense_255_loss: 2.6313 - dense_257_loss: 2.6349 - dense_259_loss: 2.5192 - dense_251_accuracy: 0.2307 - dense_253_accuracy: 0.3054 - dense_255_accuracy: 0.1740 - dense_257_accuracy: 0.2049 - dense_259_accuracy: 0.2139 - val_loss: 14.4085 - val_dense_251_loss: 3.1964 - val_dense_253_loss: 2.7535 - val_dense_255_loss: 2.8567 - val_dense_257_loss: 2.8605 - val_dense_259_loss: 2.8306 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.3196 - val_dense_255_accuracy: 0.0773 - val_dense_257_accuracy: 0.2320 - val_dense_259_accuracy: 0.1649\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 4s 5ms/sample - loss: 12.1956 - dense_251_loss: 2.3259 - dense_253_loss: 2.3053 - dense_255_loss: 2.5513 - dense_257_loss: 2.5670 - dense_259_loss: 2.4568 - dense_251_accuracy: 0.2577 - dense_253_accuracy: 0.3235 - dense_255_accuracy: 0.1714 - dense_257_accuracy: 0.2191 - dense_259_accuracy: 0.2216 - val_loss: 14.2283 - val_dense_251_loss: 3.2051 - val_dense_253_loss: 2.7036 - val_dense_255_loss: 2.8219 - val_dense_257_loss: 2.8253 - val_dense_259_loss: 2.7758 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.4175 - val_dense_255_accuracy: 0.1289 - val_dense_257_accuracy: 0.2216 - val_dense_259_accuracy: 0.3402\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 11.7340 - dense_251_loss: 2.2644 - dense_253_loss: 2.1715 - dense_255_loss: 2.4580 - dense_257_loss: 2.4502 - dense_259_loss: 2.3823 - dense_251_accuracy: 0.3312 - dense_253_accuracy: 0.3892 - dense_255_accuracy: 0.2539 - dense_257_accuracy: 0.2784 - dense_259_accuracy: 0.2887 - val_loss: 14.2248 - val_dense_251_loss: 3.3183 - val_dense_253_loss: 2.6336 - val_dense_255_loss: 2.7775 - val_dense_257_loss: 2.8425 - val_dense_259_loss: 2.7785 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.4691 - val_dense_255_accuracy: 0.1495 - val_dense_257_accuracy: 0.2474 - val_dense_259_accuracy: 0.1804\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 11.3106 - dense_251_loss: 2.1429 - dense_253_loss: 2.0792 - dense_255_loss: 2.3747 - dense_257_loss: 2.4010 - dense_259_loss: 2.3087 - dense_251_accuracy: 0.3428 - dense_253_accuracy: 0.4021 - dense_255_accuracy: 0.2680 - dense_257_accuracy: 0.2964 - dense_259_accuracy: 0.3119 - val_loss: 13.7310 - val_dense_251_loss: 3.3530 - val_dense_253_loss: 2.4632 - val_dense_255_loss: 2.7264 - val_dense_257_loss: 2.6908 - val_dense_259_loss: 2.6755 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.5206 - val_dense_255_accuracy: 0.0979 - val_dense_257_accuracy: 0.4124 - val_dense_259_accuracy: 0.3041\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 10.8596 - dense_251_loss: 2.0844 - dense_253_loss: 1.9330 - dense_255_loss: 2.3133 - dense_257_loss: 2.3127 - dense_259_loss: 2.2020 - dense_251_accuracy: 0.4085 - dense_253_accuracy: 0.4820 - dense_255_accuracy: 0.2796 - dense_257_accuracy: 0.3015 - dense_259_accuracy: 0.3209 - val_loss: 13.2440 - val_dense_251_loss: 3.2964 - val_dense_253_loss: 2.2883 - val_dense_255_loss: 2.6351 - val_dense_257_loss: 2.6311 - val_dense_259_loss: 2.5495 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.6186 - val_dense_255_accuracy: 0.1959 - val_dense_257_accuracy: 0.3299 - val_dense_259_accuracy: 0.3557\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 10.3619 - dense_251_loss: 1.9280 - dense_253_loss: 1.8452 - dense_255_loss: 2.2377 - dense_257_loss: 2.2000 - dense_259_loss: 2.1434 - dense_251_accuracy: 0.4343 - dense_253_accuracy: 0.5000 - dense_255_accuracy: 0.2796 - dense_257_accuracy: 0.3312 - dense_259_accuracy: 0.3621 - val_loss: 13.1552 - val_dense_251_loss: 3.5036 - val_dense_253_loss: 2.2032 - val_dense_255_loss: 2.5697 - val_dense_257_loss: 2.6032 - val_dense_259_loss: 2.5149 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.4794 - val_dense_255_accuracy: 0.1392 - val_dense_257_accuracy: 0.3041 - val_dense_259_accuracy: 0.3505\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 9.6293 - dense_251_loss: 1.7904 - dense_253_loss: 1.6321 - dense_255_loss: 2.1200 - dense_257_loss: 2.0500 - dense_259_loss: 2.0281 - dense_251_accuracy: 0.4948 - dense_253_accuracy: 0.5232 - dense_255_accuracy: 0.3402 - dense_257_accuracy: 0.3827 - dense_259_accuracy: 0.3995 - val_loss: 12.3131 - val_dense_251_loss: 3.9144 - val_dense_253_loss: 1.7148 - val_dense_255_loss: 2.3139 - val_dense_257_loss: 2.3180 - val_dense_259_loss: 2.3127 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.6907 - val_dense_255_accuracy: 0.3196 - val_dense_257_accuracy: 0.2835 - val_dense_259_accuracy: 0.4433\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 4s 6ms/sample - loss: 9.2340 - dense_251_loss: 1.6319 - dense_253_loss: 1.5039 - dense_255_loss: 2.0910 - dense_257_loss: 2.0343 - dense_259_loss: 1.9711 - dense_251_accuracy: 0.5271 - dense_253_accuracy: 0.5567 - dense_255_accuracy: 0.3724 - dense_257_accuracy: 0.4072 - dense_259_accuracy: 0.3995 - val_loss: 11.6994 - val_dense_251_loss: 3.6462 - val_dense_253_loss: 1.5331 - val_dense_255_loss: 2.4146 - val_dense_257_loss: 2.2082 - val_dense_259_loss: 2.1723 - val_dense_251_accuracy: 0.0206 - val_dense_253_accuracy: 0.7526 - val_dense_255_accuracy: 0.2474 - val_dense_257_accuracy: 0.4897 - val_dense_259_accuracy: 0.4845\n",
      "Epoch 17/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 8.6353 - dense_251_loss: 1.5148 - dense_253_loss: 1.3810 - dense_255_loss: 1.9421 - dense_257_loss: 1.9021 - dense_259_loss: 1.8656 - dense_251_accuracy: 0.5709 - dense_253_accuracy: 0.6302 - dense_255_accuracy: 0.4034 - dense_257_accuracy: 0.4472 - dense_259_accuracy: 0.4394 - val_loss: 11.6536 - val_dense_251_loss: 4.2875 - val_dense_253_loss: 1.4238 - val_dense_255_loss: 2.1056 - val_dense_257_loss: 2.0260 - val_dense_259_loss: 2.0900 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.7165 - val_dense_255_accuracy: 0.4588 - val_dense_257_accuracy: 0.4948 - val_dense_259_accuracy: 0.4433\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 7.9739 - dense_251_loss: 1.3952 - dense_253_loss: 1.1850 - dense_255_loss: 1.8338 - dense_257_loss: 1.8226 - dense_259_loss: 1.7450 - dense_251_accuracy: 0.6018 - dense_253_accuracy: 0.6534 - dense_255_accuracy: 0.4497 - dense_257_accuracy: 0.4536 - dense_259_accuracy: 0.4923 - val_loss: 11.1893 - val_dense_251_loss: 3.9220 - val_dense_253_loss: 1.2388 - val_dense_255_loss: 2.2006 - val_dense_257_loss: 2.1181 - val_dense_259_loss: 2.0121 - val_dense_251_accuracy: 0.0258 - val_dense_253_accuracy: 0.7577 - val_dense_255_accuracy: 0.3247 - val_dense_257_accuracy: 0.4845 - val_dense_259_accuracy: 0.4794\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 7.4554 - dense_251_loss: 1.2206 - dense_253_loss: 1.1138 - dense_255_loss: 1.7929 - dense_257_loss: 1.6974 - dense_259_loss: 1.6082 - dense_251_accuracy: 0.6534 - dense_253_accuracy: 0.6881 - dense_255_accuracy: 0.4781 - dense_257_accuracy: 0.5026 - dense_259_accuracy: 0.5438 - val_loss: 11.3756 - val_dense_251_loss: 5.0640 - val_dense_253_loss: 1.0773 - val_dense_255_loss: 2.1482 - val_dense_257_loss: 1.6984 - val_dense_259_loss: 1.6972 - val_dense_251_accuracy: 0.0103 - val_dense_253_accuracy: 0.7526 - val_dense_255_accuracy: 0.2113 - val_dense_257_accuracy: 0.5206 - val_dense_259_accuracy: 0.5670\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 6.5979 - dense_251_loss: 0.9719 - dense_253_loss: 0.9411 - dense_255_loss: 1.6193 - dense_257_loss: 1.5653 - dense_259_loss: 1.5121 - dense_251_accuracy: 0.7436 - dense_253_accuracy: 0.7397 - dense_255_accuracy: 0.5503 - dense_257_accuracy: 0.5541 - dense_259_accuracy: 0.5799 - val_loss: 10.8492 - val_dense_251_loss: 4.7887 - val_dense_253_loss: 1.1027 - val_dense_255_loss: 1.6502 - val_dense_257_loss: 1.7035 - val_dense_259_loss: 1.8827 - val_dense_251_accuracy: 0.0103 - val_dense_253_accuracy: 0.7062 - val_dense_255_accuracy: 0.6392 - val_dense_257_accuracy: 0.5567 - val_dense_259_accuracy: 0.4536\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 6.2532 - dense_251_loss: 0.8756 - dense_253_loss: 0.9683 - dense_255_loss: 1.5332 - dense_257_loss: 1.4476 - dense_259_loss: 1.4248 - dense_251_accuracy: 0.7590 - dense_253_accuracy: 0.7577 - dense_255_accuracy: 0.5670 - dense_257_accuracy: 0.5412 - dense_259_accuracy: 0.5799 - val_loss: 10.6670 - val_dense_251_loss: 5.0379 - val_dense_253_loss: 1.0020 - val_dense_255_loss: 1.5545 - val_dense_257_loss: 1.4391 - val_dense_259_loss: 1.7684 - val_dense_251_accuracy: 0.0103 - val_dense_253_accuracy: 0.7371 - val_dense_255_accuracy: 0.5722 - val_dense_257_accuracy: 0.6443 - val_dense_259_accuracy: 0.4330\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 5.7935 - dense_251_loss: 0.7984 - dense_253_loss: 0.8548 - dense_255_loss: 1.3750 - dense_257_loss: 1.4495 - dense_259_loss: 1.3186 - dense_251_accuracy: 0.7745 - dense_253_accuracy: 0.7771 - dense_255_accuracy: 0.5992 - dense_257_accuracy: 0.5838 - dense_259_accuracy: 0.6031 - val_loss: 11.9325 - val_dense_251_loss: 7.1911 - val_dense_253_loss: 0.8644 - val_dense_255_loss: 1.4625 - val_dense_257_loss: 1.2242 - val_dense_259_loss: 1.5041 - val_dense_251_accuracy: 0.0000e+00 - val_dense_253_accuracy: 0.7474 - val_dense_255_accuracy: 0.5361 - val_dense_257_accuracy: 0.6649 - val_dense_259_accuracy: 0.5825\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 5.2030 - dense_251_loss: 0.7057 - dense_253_loss: 0.7191 - dense_255_loss: 1.2871 - dense_257_loss: 1.2724 - dense_259_loss: 1.1998 - dense_251_accuracy: 0.8286 - dense_253_accuracy: 0.8299 - dense_255_accuracy: 0.6572 - dense_257_accuracy: 0.6418 - dense_259_accuracy: 0.6340 - val_loss: 10.6222 - val_dense_251_loss: 6.4835 - val_dense_253_loss: 0.6913 - val_dense_255_loss: 1.1749 - val_dense_257_loss: 1.2055 - val_dense_259_loss: 1.3181 - val_dense_251_accuracy: 0.0206 - val_dense_253_accuracy: 0.8041 - val_dense_255_accuracy: 0.5515 - val_dense_257_accuracy: 0.6443 - val_dense_259_accuracy: 0.6546\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 4.6347 - dense_251_loss: 0.6125 - dense_253_loss: 0.6451 - dense_255_loss: 1.1219 - dense_257_loss: 1.1753 - dense_259_loss: 1.1196 - dense_251_accuracy: 0.8286 - dense_253_accuracy: 0.8402 - dense_255_accuracy: 0.7023 - dense_257_accuracy: 0.6675 - dense_259_accuracy: 0.6521 - val_loss: 9.4942 - val_dense_251_loss: 4.4366 - val_dense_253_loss: 1.0175 - val_dense_255_loss: 1.2611 - val_dense_257_loss: 1.8021 - val_dense_259_loss: 1.4081 - val_dense_251_accuracy: 0.2320 - val_dense_253_accuracy: 0.7320 - val_dense_255_accuracy: 0.6031 - val_dense_257_accuracy: 0.5206 - val_dense_259_accuracy: 0.6031\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 4.3622 - dense_251_loss: 0.6228 - dense_253_loss: 0.6331 - dense_255_loss: 1.0177 - dense_257_loss: 1.0868 - dense_259_loss: 0.9878 - dense_251_accuracy: 0.8505 - dense_253_accuracy: 0.8363 - dense_255_accuracy: 0.7461 - dense_257_accuracy: 0.6946 - dense_259_accuracy: 0.7101 - val_loss: 12.8199 - val_dense_251_loss: 7.3136 - val_dense_253_loss: 0.9774 - val_dense_255_loss: 1.9508 - val_dense_257_loss: 1.1565 - val_dense_259_loss: 1.7032 - val_dense_251_accuracy: 0.0309 - val_dense_253_accuracy: 0.7474 - val_dense_255_accuracy: 0.5052 - val_dense_257_accuracy: 0.6546 - val_dense_259_accuracy: 0.5309\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 4.0281 - dense_251_loss: 0.5376 - dense_253_loss: 0.6023 - dense_255_loss: 0.9894 - dense_257_loss: 0.9903 - dense_259_loss: 0.9091 - dense_251_accuracy: 0.8750 - dense_253_accuracy: 0.8518 - dense_255_accuracy: 0.7552 - dense_257_accuracy: 0.7139 - dense_259_accuracy: 0.7320 - val_loss: 9.9039 - val_dense_251_loss: 6.9191 - val_dense_253_loss: 0.6758 - val_dense_255_loss: 0.7906 - val_dense_257_loss: 0.8206 - val_dense_259_loss: 1.1078 - val_dense_251_accuracy: 0.0464 - val_dense_253_accuracy: 0.8454 - val_dense_255_accuracy: 0.7216 - val_dense_257_accuracy: 0.7526 - val_dense_259_accuracy: 0.6753\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 3.7432 - dense_251_loss: 0.5053 - dense_253_loss: 0.4790 - dense_255_loss: 0.8879 - dense_257_loss: 0.9931 - dense_259_loss: 0.8863 - dense_251_accuracy: 0.8673 - dense_253_accuracy: 0.8853 - dense_255_accuracy: 0.7668 - dense_257_accuracy: 0.7204 - dense_259_accuracy: 0.7539 - val_loss: 12.2049 - val_dense_251_loss: 8.6981 - val_dense_253_loss: 0.6391 - val_dense_255_loss: 0.8363 - val_dense_257_loss: 1.1315 - val_dense_259_loss: 1.2117 - val_dense_251_accuracy: 0.0052 - val_dense_253_accuracy: 0.8608 - val_dense_255_accuracy: 0.7010 - val_dense_257_accuracy: 0.6495 - val_dense_259_accuracy: 0.6340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 3.3684 - dense_251_loss: 0.4281 - dense_253_loss: 0.4439 - dense_255_loss: 0.8158 - dense_257_loss: 0.9054 - dense_259_loss: 0.7836 - dense_251_accuracy: 0.8930 - dense_253_accuracy: 0.8840 - dense_255_accuracy: 0.7964 - dense_257_accuracy: 0.7539 - dense_259_accuracy: 0.7745 - val_loss: 12.0063 - val_dense_251_loss: 9.0896 - val_dense_253_loss: 0.6250 - val_dense_255_loss: 0.7280 - val_dense_257_loss: 0.7516 - val_dense_259_loss: 0.9686 - val_dense_251_accuracy: 0.0052 - val_dense_253_accuracy: 0.8608 - val_dense_255_accuracy: 0.7629 - val_dense_257_accuracy: 0.7784 - val_dense_259_accuracy: 0.6804\n",
      "Epoch 29/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 3.2061 - dense_251_loss: 0.4617 - dense_253_loss: 0.4172 - dense_255_loss: 0.7685 - dense_257_loss: 0.8270 - dense_259_loss: 0.7588 - dense_251_accuracy: 0.8853 - dense_253_accuracy: 0.9072 - dense_255_accuracy: 0.8183 - dense_257_accuracy: 0.7835 - dense_259_accuracy: 0.7874 - val_loss: 11.0860 - val_dense_251_loss: 7.9276 - val_dense_253_loss: 0.6032 - val_dense_255_loss: 0.8003 - val_dense_257_loss: 0.7995 - val_dense_259_loss: 0.9812 - val_dense_251_accuracy: 0.0155 - val_dense_253_accuracy: 0.8454 - val_dense_255_accuracy: 0.7423 - val_dense_257_accuracy: 0.7320 - val_dense_259_accuracy: 0.7474\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 2.9819 - dense_251_loss: 0.3856 - dense_253_loss: 0.3833 - dense_255_loss: 0.7302 - dense_257_loss: 0.7561 - dense_259_loss: 0.7168 - dense_251_accuracy: 0.9137 - dense_253_accuracy: 0.9098 - dense_255_accuracy: 0.8338 - dense_257_accuracy: 0.7938 - dense_259_accuracy: 0.8041 - val_loss: 9.4305 - val_dense_251_loss: 6.6292 - val_dense_253_loss: 0.6366 - val_dense_255_loss: 0.6662 - val_dense_257_loss: 0.7451 - val_dense_259_loss: 0.9572 - val_dense_251_accuracy: 0.0515 - val_dense_253_accuracy: 0.8402 - val_dense_255_accuracy: 0.7629 - val_dense_257_accuracy: 0.7784 - val_dense_259_accuracy: 0.7320\n"
     ]
    }
   ],
   "source": [
    "gradient_est = 'sgd'\n",
    "model = grad_create_model(gradient_est)\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 50, 200, 16)  160         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_86[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_87 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_87[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 13, 50, 32)   128         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_88 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 5600)         0           max_pooling2d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_280 (Dense)               (None, 64)           358464      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_282 (Dense)               (None, 64)           358464      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_284 (Dense)               (None, 64)           358464      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_286 (Dense)               (None, 64)           358464      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_288 (Dense)               (None, 64)           358464      flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 64)           0           dense_280[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 64)           0           dense_282[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 64)           0           dense_284[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 64)           0           dense_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 64)           0           dense_288[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_281 (Dense)               (None, 19)           1235        dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_283 (Dense)               (None, 19)           1235        dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_285 (Dense)               (None, 19)           1235        dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_287 (Dense)               (None, 19)           1235        dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_289 (Dense)               (None, 19)           1235        dropout_144[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 8s 10ms/sample - loss: 14.7286 - dense_281_loss: 2.8370 - dense_283_loss: 2.9739 - dense_285_loss: 2.9661 - dense_287_loss: 2.9785 - dense_289_loss: 2.9608 - dense_281_accuracy: 0.0889 - dense_283_accuracy: 0.0760 - dense_285_accuracy: 0.0554 - dense_287_accuracy: 0.0722 - dense_289_accuracy: 0.0812 - val_loss: 14.8124 - val_dense_281_loss: 3.0424 - val_dense_283_loss: 2.9428 - val_dense_285_loss: 2.9420 - val_dense_287_loss: 2.9408 - val_dense_289_loss: 2.9434 - val_dense_281_accuracy: 0.0000e+00 - val_dense_283_accuracy: 0.0361 - val_dense_285_accuracy: 0.0258 - val_dense_287_accuracy: 0.0515 - val_dense_289_accuracy: 0.1392\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.4145 - dense_281_loss: 2.7298 - dense_283_loss: 2.9154 - dense_285_loss: 2.9274 - dense_287_loss: 2.9294 - dense_289_loss: 2.9229 - dense_281_accuracy: 0.0992 - dense_283_accuracy: 0.0941 - dense_285_accuracy: 0.0889 - dense_287_accuracy: 0.0863 - dense_289_accuracy: 0.0954 - val_loss: 14.7933 - val_dense_281_loss: 3.0213 - val_dense_283_loss: 2.9453 - val_dense_285_loss: 2.9418 - val_dense_287_loss: 2.9416 - val_dense_289_loss: 2.9427 - val_dense_281_accuracy: 0.0000e+00 - val_dense_283_accuracy: 0.0361 - val_dense_285_accuracy: 0.0361 - val_dense_287_accuracy: 0.1392 - val_dense_289_accuracy: 0.0722\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 14.1729 - dense_281_loss: 2.6147 - dense_283_loss: 2.8748 - dense_285_loss: 2.8775 - dense_287_loss: 2.8891 - dense_289_loss: 2.9066 - dense_281_accuracy: 0.1405 - dense_283_accuracy: 0.1121 - dense_285_accuracy: 0.0838 - dense_287_accuracy: 0.1211 - dense_289_accuracy: 0.0992 - val_loss: 14.8156 - val_dense_281_loss: 3.0657 - val_dense_283_loss: 2.9352 - val_dense_285_loss: 2.9328 - val_dense_287_loss: 2.9356 - val_dense_289_loss: 2.9400 - val_dense_281_accuracy: 0.0000e+00 - val_dense_283_accuracy: 0.0773 - val_dense_285_accuracy: 0.1031 - val_dense_287_accuracy: 0.1082 - val_dense_289_accuracy: 0.0825\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 13.6810 - dense_281_loss: 2.4197 - dense_283_loss: 2.7725 - dense_285_loss: 2.8111 - dense_287_loss: 2.8305 - dense_289_loss: 2.8600 - dense_281_accuracy: 0.2075 - dense_283_accuracy: 0.1662 - dense_285_accuracy: 0.1314 - dense_287_accuracy: 0.1198 - dense_289_accuracy: 0.1005 - val_loss: 14.7309 - val_dense_281_loss: 3.0117 - val_dense_283_loss: 2.9354 - val_dense_285_loss: 2.9285 - val_dense_287_loss: 2.9315 - val_dense_289_loss: 2.9349 - val_dense_281_accuracy: 0.0000e+00 - val_dense_283_accuracy: 0.0464 - val_dense_285_accuracy: 0.1340 - val_dense_287_accuracy: 0.1546 - val_dense_289_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 4s 6ms/sample - loss: 12.9563 - dense_281_loss: 2.1533 - dense_283_loss: 2.5713 - dense_285_loss: 2.7067 - dense_287_loss: 2.7222 - dense_289_loss: 2.7745 - dense_281_accuracy: 0.3209 - dense_283_accuracy: 0.2345 - dense_285_accuracy: 0.1765 - dense_287_accuracy: 0.1637 - dense_289_accuracy: 0.1508 - val_loss: 14.6253 - val_dense_281_loss: 3.0368 - val_dense_283_loss: 2.8823 - val_dense_285_loss: 2.8987 - val_dense_287_loss: 2.9066 - val_dense_289_loss: 2.9176 - val_dense_281_accuracy: 0.0000e+00 - val_dense_283_accuracy: 0.2887 - val_dense_285_accuracy: 0.2268 - val_dense_287_accuracy: 0.2165 - val_dense_289_accuracy: 0.1443\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 12.0723 - dense_281_loss: 1.8981 - dense_283_loss: 2.3833 - dense_285_loss: 2.5736 - dense_287_loss: 2.5568 - dense_289_loss: 2.6516 - dense_281_accuracy: 0.4291 - dense_283_accuracy: 0.2887 - dense_285_accuracy: 0.2423 - dense_287_accuracy: 0.1869 - dense_289_accuracy: 0.1869 - val_loss: 14.5105 - val_dense_281_loss: 2.9841 - val_dense_283_loss: 2.8717 - val_dense_285_loss: 2.8805 - val_dense_287_loss: 2.8915 - val_dense_289_loss: 2.9066 - val_dense_281_accuracy: 0.0052 - val_dense_283_accuracy: 0.3557 - val_dense_285_accuracy: 0.2526 - val_dense_287_accuracy: 0.2062 - val_dense_289_accuracy: 0.1753\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 11.0571 - dense_281_loss: 1.5940 - dense_283_loss: 2.1437 - dense_285_loss: 2.4193 - dense_287_loss: 2.3619 - dense_289_loss: 2.5162 - dense_281_accuracy: 0.5232 - dense_283_accuracy: 0.3660 - dense_285_accuracy: 0.2655 - dense_287_accuracy: 0.2384 - dense_289_accuracy: 0.2113 - val_loss: 14.2833 - val_dense_281_loss: 3.0001 - val_dense_283_loss: 2.7837 - val_dense_285_loss: 2.8117 - val_dense_287_loss: 2.8411 - val_dense_289_loss: 2.8770 - val_dense_281_accuracy: 0.0052 - val_dense_283_accuracy: 0.4742 - val_dense_285_accuracy: 0.2216 - val_dense_287_accuracy: 0.2320 - val_dense_289_accuracy: 0.2732\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 4s 6ms/sample - loss: 10.1114 - dense_281_loss: 1.3087 - dense_283_loss: 1.9169 - dense_285_loss: 2.2339 - dense_287_loss: 2.2718 - dense_289_loss: 2.3691 - dense_281_accuracy: 0.6186 - dense_283_accuracy: 0.4407 - dense_285_accuracy: 0.3235 - dense_287_accuracy: 0.3067 - dense_289_accuracy: 0.2564 - val_loss: 14.1268 - val_dense_281_loss: 3.0512 - val_dense_283_loss: 2.7271 - val_dense_285_loss: 2.7657 - val_dense_287_loss: 2.7865 - val_dense_289_loss: 2.8520 - val_dense_281_accuracy: 0.0309 - val_dense_283_accuracy: 0.5361 - val_dense_285_accuracy: 0.3711 - val_dense_287_accuracy: 0.3557 - val_dense_289_accuracy: 0.2835\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 9.0452 - dense_281_loss: 1.0704 - dense_283_loss: 1.6410 - dense_285_loss: 2.0385 - dense_287_loss: 2.0563 - dense_289_loss: 2.2316 - dense_281_accuracy: 0.6894 - dense_283_accuracy: 0.5335 - dense_285_accuracy: 0.4072 - dense_287_accuracy: 0.3518 - dense_289_accuracy: 0.3247 - val_loss: 13.7487 - val_dense_281_loss: 3.0210 - val_dense_283_loss: 2.6069 - val_dense_285_loss: 2.6917 - val_dense_287_loss: 2.7356 - val_dense_289_loss: 2.7644 - val_dense_281_accuracy: 0.0464 - val_dense_283_accuracy: 0.7216 - val_dense_285_accuracy: 0.4948 - val_dense_287_accuracy: 0.4485 - val_dense_289_accuracy: 0.3866\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 8.2050 - dense_281_loss: 0.9374 - dense_283_loss: 1.4470 - dense_285_loss: 1.8549 - dense_287_loss: 1.8992 - dense_289_loss: 2.0700 - dense_281_accuracy: 0.7191 - dense_283_accuracy: 0.5825 - dense_285_accuracy: 0.4704 - dense_287_accuracy: 0.4214 - dense_289_accuracy: 0.3505 - val_loss: 13.2630 - val_dense_281_loss: 2.9640 - val_dense_283_loss: 2.5152 - val_dense_285_loss: 2.5594 - val_dense_287_loss: 2.6091 - val_dense_289_loss: 2.6727 - val_dense_281_accuracy: 0.0361 - val_dense_283_accuracy: 0.7062 - val_dense_285_accuracy: 0.4227 - val_dense_287_accuracy: 0.5309 - val_dense_289_accuracy: 0.4278\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 7.2941 - dense_281_loss: 0.7321 - dense_283_loss: 1.2238 - dense_285_loss: 1.7001 - dense_287_loss: 1.7081 - dense_289_loss: 1.9145 - dense_281_accuracy: 0.8028 - dense_283_accuracy: 0.6482 - dense_285_accuracy: 0.5219 - dense_287_accuracy: 0.4936 - dense_289_accuracy: 0.4149 - val_loss: 12.9306 - val_dense_281_loss: 3.0774 - val_dense_283_loss: 2.3265 - val_dense_285_loss: 2.5015 - val_dense_287_loss: 2.5280 - val_dense_289_loss: 2.5782 - val_dense_281_accuracy: 0.0155 - val_dense_283_accuracy: 0.7577 - val_dense_285_accuracy: 0.5928 - val_dense_287_accuracy: 0.5155 - val_dense_289_accuracy: 0.5361\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 6.3971 - dense_281_loss: 0.6394 - dense_283_loss: 0.9551 - dense_285_loss: 1.5069 - dense_287_loss: 1.5658 - dense_289_loss: 1.6937 - dense_281_accuracy: 0.8376 - dense_283_accuracy: 0.7358 - dense_285_accuracy: 0.5399 - dense_287_accuracy: 0.5284 - dense_289_accuracy: 0.4897 - val_loss: 12.0376 - val_dense_281_loss: 3.1733 - val_dense_283_loss: 2.0027 - val_dense_285_loss: 2.2426 - val_dense_287_loss: 2.3203 - val_dense_289_loss: 2.3931 - val_dense_281_accuracy: 0.0103 - val_dense_283_accuracy: 0.7474 - val_dense_285_accuracy: 0.5515 - val_dense_287_accuracy: 0.5722 - val_dense_289_accuracy: 0.5773\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 5.6813 - dense_281_loss: 0.5275 - dense_283_loss: 0.8554 - dense_285_loss: 1.3247 - dense_287_loss: 1.4353 - dense_289_loss: 1.5863 - dense_281_accuracy: 0.8827 - dense_283_accuracy: 0.7603 - dense_285_accuracy: 0.6250 - dense_287_accuracy: 0.5670 - dense_289_accuracy: 0.5116 - val_loss: 12.0937 - val_dense_281_loss: 3.6803 - val_dense_283_loss: 1.9259 - val_dense_285_loss: 2.0844 - val_dense_287_loss: 2.2629 - val_dense_289_loss: 2.2967 - val_dense_281_accuracy: 0.0155 - val_dense_283_accuracy: 0.7371 - val_dense_285_accuracy: 0.5928 - val_dense_287_accuracy: 0.4639 - val_dense_289_accuracy: 0.5258\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 5.1467 - dense_281_loss: 0.4649 - dense_283_loss: 0.7297 - dense_285_loss: 1.1577 - dense_287_loss: 1.3127 - dense_289_loss: 1.4714 - dense_281_accuracy: 0.8660 - dense_283_accuracy: 0.8003 - dense_285_accuracy: 0.6598 - dense_287_accuracy: 0.6186 - dense_289_accuracy: 0.5412 - val_loss: 11.2572 - val_dense_281_loss: 3.7473 - val_dense_283_loss: 1.6289 - val_dense_285_loss: 1.9791 - val_dense_287_loss: 1.9504 - val_dense_289_loss: 2.0598 - val_dense_281_accuracy: 0.0103 - val_dense_283_accuracy: 0.7887 - val_dense_285_accuracy: 0.6392 - val_dense_287_accuracy: 0.7216 - val_dense_289_accuracy: 0.6392\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 4.4812 - dense_281_loss: 0.4007 - dense_283_loss: 0.6459 - dense_285_loss: 1.0571 - dense_287_loss: 1.0982 - dense_289_loss: 1.2701 - dense_281_accuracy: 0.8943 - dense_283_accuracy: 0.8144 - dense_285_accuracy: 0.7101 - dense_287_accuracy: 0.6662 - dense_289_accuracy: 0.6211 - val_loss: 10.1985 - val_dense_281_loss: 3.9174 - val_dense_283_loss: 1.3139 - val_dense_285_loss: 1.6313 - val_dense_287_loss: 1.6562 - val_dense_289_loss: 1.8538 - val_dense_281_accuracy: 0.0825 - val_dense_283_accuracy: 0.8351 - val_dense_285_accuracy: 0.6959 - val_dense_287_accuracy: 0.7268 - val_dense_289_accuracy: 0.6134\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 4.0916 - dense_281_loss: 0.3253 - dense_283_loss: 0.5562 - dense_285_loss: 1.0177 - dense_287_loss: 1.0716 - dense_289_loss: 1.1006 - dense_281_accuracy: 0.9240 - dense_283_accuracy: 0.8518 - dense_285_accuracy: 0.7242 - dense_287_accuracy: 0.7062 - dense_289_accuracy: 0.6598 - val_loss: 9.7703 - val_dense_281_loss: 3.9291 - val_dense_283_loss: 1.1723 - val_dense_285_loss: 1.5792 - val_dense_287_loss: 1.5976 - val_dense_289_loss: 1.6890 - val_dense_281_accuracy: 0.0773 - val_dense_283_accuracy: 0.8247 - val_dense_285_accuracy: 0.6753 - val_dense_287_accuracy: 0.7423 - val_dense_289_accuracy: 0.7010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.5384 - dense_281_loss: 0.3099 - dense_283_loss: 0.5178 - dense_285_loss: 0.8380 - dense_287_loss: 0.8600 - dense_289_loss: 1.0389 - dense_281_accuracy: 0.9149 - dense_283_accuracy: 0.8698 - dense_285_accuracy: 0.7706 - dense_287_accuracy: 0.7448 - dense_289_accuracy: 0.6881 - val_loss: 10.2035 - val_dense_281_loss: 3.7197 - val_dense_283_loss: 1.2852 - val_dense_285_loss: 1.8619 - val_dense_287_loss: 1.6226 - val_dense_289_loss: 1.8485 - val_dense_281_accuracy: 0.0361 - val_dense_283_accuracy: 0.8402 - val_dense_285_accuracy: 0.4381 - val_dense_287_accuracy: 0.6907 - val_dense_289_accuracy: 0.7371\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 3.3366 - dense_281_loss: 0.2916 - dense_283_loss: 0.4545 - dense_285_loss: 0.7765 - dense_287_loss: 0.8295 - dense_289_loss: 1.0108 - dense_281_accuracy: 0.9265 - dense_283_accuracy: 0.8892 - dense_285_accuracy: 0.7861 - dense_287_accuracy: 0.7590 - dense_289_accuracy: 0.7049 - val_loss: 9.3313 - val_dense_281_loss: 4.7233 - val_dense_283_loss: 0.8799 - val_dense_285_loss: 1.0641 - val_dense_287_loss: 1.3744 - val_dense_289_loss: 1.3945 - val_dense_281_accuracy: 0.0567 - val_dense_283_accuracy: 0.8814 - val_dense_285_accuracy: 0.7474 - val_dense_287_accuracy: 0.6856 - val_dense_289_accuracy: 0.7216\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.9415 - dense_281_loss: 0.2624 - dense_283_loss: 0.3848 - dense_285_loss: 0.6612 - dense_287_loss: 0.7500 - dense_289_loss: 0.8802 - dense_281_accuracy: 0.9253 - dense_283_accuracy: 0.9059 - dense_285_accuracy: 0.8119 - dense_287_accuracy: 0.7577 - dense_289_accuracy: 0.7590 - val_loss: 8.8918 - val_dense_281_loss: 5.0489 - val_dense_283_loss: 0.7447 - val_dense_285_loss: 0.9415 - val_dense_287_loss: 1.1268 - val_dense_289_loss: 1.2595 - val_dense_281_accuracy: 0.0928 - val_dense_283_accuracy: 0.8660 - val_dense_285_accuracy: 0.7268 - val_dense_287_accuracy: 0.7526 - val_dense_289_accuracy: 0.7423\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.6682 - dense_281_loss: 0.2165 - dense_283_loss: 0.3721 - dense_285_loss: 0.5775 - dense_287_loss: 0.6539 - dense_289_loss: 0.8300 - dense_281_accuracy: 0.9510 - dense_283_accuracy: 0.9111 - dense_285_accuracy: 0.8299 - dense_287_accuracy: 0.8170 - dense_289_accuracy: 0.7668 - val_loss: 9.1655 - val_dense_281_loss: 5.8369 - val_dense_283_loss: 0.6321 - val_dense_285_loss: 0.8197 - val_dense_287_loss: 0.9344 - val_dense_289_loss: 1.0867 - val_dense_281_accuracy: 0.0515 - val_dense_283_accuracy: 0.8660 - val_dense_285_accuracy: 0.7784 - val_dense_287_accuracy: 0.7577 - val_dense_289_accuracy: 0.7320\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.4147 - dense_281_loss: 0.1705 - dense_283_loss: 0.3371 - dense_285_loss: 0.5534 - dense_287_loss: 0.6291 - dense_289_loss: 0.7270 - dense_281_accuracy: 0.9652 - dense_283_accuracy: 0.9175 - dense_285_accuracy: 0.8247 - dense_287_accuracy: 0.8170 - dense_289_accuracy: 0.7822 - val_loss: 9.8126 - val_dense_281_loss: 7.0103 - val_dense_283_loss: 0.6023 - val_dense_285_loss: 0.7852 - val_dense_287_loss: 0.8016 - val_dense_289_loss: 0.9977 - val_dense_281_accuracy: 0.0825 - val_dense_283_accuracy: 0.8557 - val_dense_285_accuracy: 0.7732 - val_dense_287_accuracy: 0.7835 - val_dense_289_accuracy: 0.7371\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.2229 - dense_281_loss: 0.1802 - dense_283_loss: 0.3226 - dense_285_loss: 0.5027 - dense_287_loss: 0.5927 - dense_289_loss: 0.6379 - dense_281_accuracy: 0.9536 - dense_283_accuracy: 0.9137 - dense_285_accuracy: 0.8686 - dense_287_accuracy: 0.8299 - dense_289_accuracy: 0.8183 - val_loss: 10.3567 - val_dense_281_loss: 7.5647 - val_dense_283_loss: 0.5344 - val_dense_285_loss: 0.7579 - val_dense_287_loss: 0.7898 - val_dense_289_loss: 0.8549 - val_dense_281_accuracy: 0.0206 - val_dense_283_accuracy: 0.8814 - val_dense_285_accuracy: 0.7732 - val_dense_287_accuracy: 0.7938 - val_dense_289_accuracy: 0.7887\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 2.1060 - dense_281_loss: 0.1773 - dense_283_loss: 0.3201 - dense_285_loss: 0.4767 - dense_287_loss: 0.5118 - dense_289_loss: 0.6116 - dense_281_accuracy: 0.9613 - dense_283_accuracy: 0.9046 - dense_285_accuracy: 0.8698 - dense_287_accuracy: 0.8454 - dense_289_accuracy: 0.8170 - val_loss: 10.3158 - val_dense_281_loss: 7.7109 - val_dense_283_loss: 0.4969 - val_dense_285_loss: 0.8231 - val_dense_287_loss: 0.7440 - val_dense_289_loss: 0.7217 - val_dense_281_accuracy: 0.0361 - val_dense_283_accuracy: 0.8711 - val_dense_285_accuracy: 0.7887 - val_dense_287_accuracy: 0.7680 - val_dense_289_accuracy: 0.7990\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.8992 - dense_281_loss: 0.1466 - dense_283_loss: 0.2361 - dense_285_loss: 0.4421 - dense_287_loss: 0.5003 - dense_289_loss: 0.5685 - dense_281_accuracy: 0.9665 - dense_283_accuracy: 0.9330 - dense_285_accuracy: 0.8647 - dense_287_accuracy: 0.8466 - dense_289_accuracy: 0.8376 - val_loss: 10.6656 - val_dense_281_loss: 8.6021 - val_dense_283_loss: 0.4844 - val_dense_285_loss: 0.7343 - val_dense_287_loss: 0.7187 - val_dense_289_loss: 0.6844 - val_dense_281_accuracy: 0.0464 - val_dense_283_accuracy: 0.8763 - val_dense_285_accuracy: 0.7732 - val_dense_287_accuracy: 0.7732 - val_dense_289_accuracy: 0.8196\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.8057 - dense_281_loss: 0.1679 - dense_283_loss: 0.2716 - dense_285_loss: 0.3764 - dense_287_loss: 0.4627 - dense_289_loss: 0.5173 - dense_281_accuracy: 0.9601 - dense_283_accuracy: 0.9356 - dense_285_accuracy: 0.8866 - dense_287_accuracy: 0.8686 - dense_289_accuracy: 0.8492 - val_loss: 10.9866 - val_dense_281_loss: 8.5298 - val_dense_283_loss: 0.4979 - val_dense_285_loss: 0.7222 - val_dense_287_loss: 0.6710 - val_dense_289_loss: 0.8396 - val_dense_281_accuracy: 0.0258 - val_dense_283_accuracy: 0.8763 - val_dense_285_accuracy: 0.7784 - val_dense_287_accuracy: 0.8041 - val_dense_289_accuracy: 0.7732\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.6110 - dense_281_loss: 0.1328 - dense_283_loss: 0.2253 - dense_285_loss: 0.3795 - dense_287_loss: 0.4156 - dense_289_loss: 0.4408 - dense_281_accuracy: 0.9613 - dense_283_accuracy: 0.9497 - dense_285_accuracy: 0.8905 - dense_287_accuracy: 0.8840 - dense_289_accuracy: 0.8660 - val_loss: 10.8041 - val_dense_281_loss: 8.3763 - val_dense_283_loss: 0.5129 - val_dense_285_loss: 0.7246 - val_dense_287_loss: 0.6289 - val_dense_289_loss: 0.7859 - val_dense_281_accuracy: 0.0722 - val_dense_283_accuracy: 0.8711 - val_dense_285_accuracy: 0.7784 - val_dense_287_accuracy: 0.8093 - val_dense_289_accuracy: 0.7835\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.5256 - dense_281_loss: 0.1261 - dense_283_loss: 0.2098 - dense_285_loss: 0.3549 - dense_287_loss: 0.4333 - dense_289_loss: 0.3928 - dense_281_accuracy: 0.9665 - dense_283_accuracy: 0.9485 - dense_285_accuracy: 0.9124 - dense_287_accuracy: 0.8660 - dense_289_accuracy: 0.8930 - val_loss: 11.0340 - val_dense_281_loss: 9.0658 - val_dense_283_loss: 0.4700 - val_dense_285_loss: 0.7197 - val_dense_287_loss: 0.6125 - val_dense_289_loss: 0.6431 - val_dense_281_accuracy: 0.1340 - val_dense_283_accuracy: 0.8814 - val_dense_285_accuracy: 0.7784 - val_dense_287_accuracy: 0.7990 - val_dense_289_accuracy: 0.8196\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.4322 - dense_281_loss: 0.1125 - dense_283_loss: 0.1868 - dense_285_loss: 0.3390 - dense_287_loss: 0.3934 - dense_289_loss: 0.3964 - dense_281_accuracy: 0.9768 - dense_283_accuracy: 0.9459 - dense_285_accuracy: 0.9111 - dense_287_accuracy: 0.8866 - dense_289_accuracy: 0.8866 - val_loss: 10.7939 - val_dense_281_loss: 8.3780 - val_dense_283_loss: 0.4912 - val_dense_285_loss: 0.7015 - val_dense_287_loss: 0.7171 - val_dense_289_loss: 0.6299 - val_dense_281_accuracy: 0.1134 - val_dense_283_accuracy: 0.8711 - val_dense_285_accuracy: 0.7887 - val_dense_287_accuracy: 0.7887 - val_dense_289_accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.3216 - dense_281_loss: 0.1461 - dense_283_loss: 0.1612 - dense_285_loss: 0.3121 - dense_287_loss: 0.3410 - dense_289_loss: 0.3439 - dense_281_accuracy: 0.9588 - dense_283_accuracy: 0.9549 - dense_285_accuracy: 0.9149 - dense_287_accuracy: 0.8866 - dense_289_accuracy: 0.8995 - val_loss: 11.6970 - val_dense_281_loss: 9.4567 - val_dense_283_loss: 0.5435 - val_dense_285_loss: 0.7572 - val_dense_287_loss: 0.6525 - val_dense_289_loss: 0.8076 - val_dense_281_accuracy: 0.1289 - val_dense_283_accuracy: 0.8557 - val_dense_285_accuracy: 0.7732 - val_dense_287_accuracy: 0.8041 - val_dense_289_accuracy: 0.8041\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 5s 6ms/sample - loss: 1.2713 - dense_281_loss: 0.1080 - dense_283_loss: 0.1607 - dense_285_loss: 0.3054 - dense_287_loss: 0.3129 - dense_289_loss: 0.3887 - dense_281_accuracy: 0.9729 - dense_283_accuracy: 0.9588 - dense_285_accuracy: 0.9201 - dense_287_accuracy: 0.9008 - dense_289_accuracy: 0.8982 - val_loss: 11.8215 - val_dense_281_loss: 9.7736 - val_dense_283_loss: 0.4878 - val_dense_285_loss: 0.7423 - val_dense_287_loss: 0.6224 - val_dense_289_loss: 0.5702 - val_dense_281_accuracy: 0.1340 - val_dense_283_accuracy: 0.8866 - val_dense_285_accuracy: 0.7887 - val_dense_287_accuracy: 0.7990 - val_dense_289_accuracy: 0.8041\n"
     ]
    }
   ],
   "source": [
    "# Adagrad optimizer\n",
    "gradient_est = keras.optimizers.Adagrad(learning_rate=0.01)\n",
    "model = grad_create_model(gradient_est)\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part F - Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def arc_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(conv3)  # 50x13\n",
    "    \n",
    "    conv4 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp3)\n",
    "    bn = layers.BatchNormalization()(conv4)\n",
    "    mp4 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 50, 200, 16)  160         input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling2D) (None, 25, 100, 16)  0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 25, 100, 32)  4640        max_pooling2d_93[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling2D) (None, 13, 50, 32)   0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 13, 50, 32)   9248        max_pooling2d_94[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 50, 32)   128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_96 (MaxPooling2D) (None, 7, 25, 32)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 5600)         0           max_pooling2d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_300 (Dense)               (None, 64)           358464      flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_302 (Dense)               (None, 64)           358464      flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_304 (Dense)               (None, 64)           358464      flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_306 (Dense)               (None, 64)           358464      flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_308 (Dense)               (None, 64)           358464      flatten_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 64)           0           dense_300[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 64)           0           dense_302[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 64)           0           dense_304[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 64)           0           dense_306[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 64)           0           dense_308[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_301 (Dense)               (None, 19)           1235        dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_303 (Dense)               (None, 19)           1235        dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_305 (Dense)               (None, 19)           1235        dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_307 (Dense)               (None, 19)           1235        dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_309 (Dense)               (None, 19)           1235        dropout_154[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,812,671\n",
      "Trainable params: 1,812,607\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 12s 16ms/sample - loss: 14.9473 - dense_301_loss: 2.8705 - dense_303_loss: 2.9960 - dense_305_loss: 3.0272 - dense_307_loss: 3.0333 - dense_309_loss: 3.0076 - dense_301_accuracy: 0.0889 - dense_303_accuracy: 0.0554 - dense_305_accuracy: 0.0438 - dense_307_accuracy: 0.0722 - dense_309_accuracy: 0.0528 - val_loss: 15.1473 - val_dense_301_loss: 3.3635 - val_dense_303_loss: 2.9411 - val_dense_305_loss: 2.9421 - val_dense_307_loss: 2.9429 - val_dense_309_loss: 2.9524 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.0567 - val_dense_305_accuracy: 0.0928 - val_dense_307_accuracy: 0.0979 - val_dense_309_accuracy: 0.0567\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 14.4530 - dense_301_loss: 2.7305 - dense_303_loss: 2.9063 - dense_305_loss: 2.9310 - dense_307_loss: 2.9304 - dense_309_loss: 2.9432 - dense_301_accuracy: 0.0812 - dense_303_accuracy: 0.0670 - dense_305_accuracy: 0.0773 - dense_307_accuracy: 0.1044 - dense_309_accuracy: 0.0799 - val_loss: 15.2481 - val_dense_301_loss: 3.5024 - val_dense_303_loss: 2.9367 - val_dense_305_loss: 2.9349 - val_dense_307_loss: 2.9411 - val_dense_309_loss: 2.9457 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.0979 - val_dense_305_accuracy: 0.1134 - val_dense_307_accuracy: 0.0979 - val_dense_309_accuracy: 0.0258\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 14.2549 - dense_301_loss: 2.6565 - dense_303_loss: 2.8606 - dense_305_loss: 2.9052 - dense_307_loss: 2.8939 - dense_309_loss: 2.9351 - dense_301_accuracy: 0.0954 - dense_303_accuracy: 0.0941 - dense_305_accuracy: 0.0773 - dense_307_accuracy: 0.0966 - dense_309_accuracy: 0.0979 - val_loss: 14.8868 - val_dense_301_loss: 3.1536 - val_dense_303_loss: 2.9304 - val_dense_305_loss: 2.9307 - val_dense_307_loss: 2.9393 - val_dense_309_loss: 2.9431 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.1237 - val_dense_305_accuracy: 0.0825 - val_dense_307_accuracy: 0.0979 - val_dense_309_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 13.9829 - dense_301_loss: 2.5360 - dense_303_loss: 2.7831 - dense_305_loss: 2.8708 - dense_307_loss: 2.8507 - dense_309_loss: 2.9258 - dense_301_accuracy: 0.1456 - dense_303_accuracy: 0.1289 - dense_305_accuracy: 0.0851 - dense_307_accuracy: 0.1005 - dense_309_accuracy: 0.0760 - val_loss: 14.7599 - val_dense_301_loss: 3.0641 - val_dense_303_loss: 2.9165 - val_dense_305_loss: 2.9288 - val_dense_307_loss: 2.9242 - val_dense_309_loss: 2.9424 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.1186 - val_dense_305_accuracy: 0.0979 - val_dense_307_accuracy: 0.1186 - val_dense_309_accuracy: 0.0876\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 6s 7ms/sample - loss: 13.6354 - dense_301_loss: 2.4234 - dense_303_loss: 2.6798 - dense_305_loss: 2.8181 - dense_307_loss: 2.8030 - dense_309_loss: 2.9077 - dense_301_accuracy: 0.1546 - dense_303_accuracy: 0.1559 - dense_305_accuracy: 0.1173 - dense_307_accuracy: 0.1224 - dense_309_accuracy: 0.0889 - val_loss: 14.7201 - val_dense_301_loss: 3.0721 - val_dense_303_loss: 2.8981 - val_dense_305_loss: 2.9219 - val_dense_307_loss: 2.9147 - val_dense_309_loss: 2.9334 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.1907 - val_dense_305_accuracy: 0.1443 - val_dense_307_accuracy: 0.1186 - val_dense_309_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 13.1937 - dense_301_loss: 2.2857 - dense_303_loss: 2.5980 - dense_305_loss: 2.7389 - dense_307_loss: 2.7192 - dense_309_loss: 2.8552 - dense_301_accuracy: 0.2075 - dense_303_accuracy: 0.1830 - dense_305_accuracy: 0.1495 - dense_307_accuracy: 0.1276 - dense_309_accuracy: 0.1095 - val_loss: 14.6362 - val_dense_301_loss: 3.1288 - val_dense_303_loss: 2.8518 - val_dense_305_loss: 2.8937 - val_dense_307_loss: 2.8732 - val_dense_309_loss: 2.9351 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.1443 - val_dense_305_accuracy: 0.2062 - val_dense_307_accuracy: 0.1649 - val_dense_309_accuracy: 0.1289\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 12.5777 - dense_301_loss: 2.0810 - dense_303_loss: 2.4238 - dense_305_loss: 2.6482 - dense_307_loss: 2.6085 - dense_309_loss: 2.8174 - dense_301_accuracy: 0.2693 - dense_303_accuracy: 0.2178 - dense_305_accuracy: 0.1778 - dense_307_accuracy: 0.1572 - dense_309_accuracy: 0.1018 - val_loss: 14.5821 - val_dense_301_loss: 3.2949 - val_dense_303_loss: 2.7319 - val_dense_305_loss: 2.8251 - val_dense_307_loss: 2.8424 - val_dense_309_loss: 2.9065 - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.2010 - val_dense_305_accuracy: 0.1495 - val_dense_307_accuracy: 0.1340 - val_dense_309_accuracy: 0.1392\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 11.8781 - dense_301_loss: 1.8567 - dense_303_loss: 2.2478 - dense_305_loss: 2.4813 - dense_307_loss: 2.5365 - dense_309_loss: 2.7375 - dense_301_accuracy: 0.3312 - dense_303_accuracy: 0.2384 - dense_305_accuracy: 0.1972 - dense_307_accuracy: 0.1727 - dense_309_accuracy: 0.1095 - val_loss: 14.2257 - val_dense_301_loss: 3.3315 - val_dense_303_loss: 2.6239 - val_dense_305_loss: 2.7463 - val_dense_307_loss: 2.7477 - val_dense_309_loss: 2.8893 - val_dense_301_accuracy: 0.0103 - val_dense_303_accuracy: 0.2216 - val_dense_305_accuracy: 0.2526 - val_dense_307_accuracy: 0.1495 - val_dense_309_accuracy: 0.1649\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 10.7876 - dense_301_loss: 1.5925 - dense_303_loss: 1.9946 - dense_305_loss: 2.2231 - dense_307_loss: 2.3695 - dense_309_loss: 2.5955 - dense_301_accuracy: 0.4059 - dense_303_accuracy: 0.2835 - dense_305_accuracy: 0.2719 - dense_307_accuracy: 0.2345 - dense_309_accuracy: 0.1701 - val_loss: 13.8613 - val_dense_301_loss: 3.3605 - val_dense_303_loss: 2.4931 - val_dense_305_loss: 2.5948 - val_dense_307_loss: 2.6818 - val_dense_309_loss: 2.7963 - val_dense_301_accuracy: 0.0103 - val_dense_303_accuracy: 0.3299 - val_dense_305_accuracy: 0.3144 - val_dense_307_accuracy: 0.2268 - val_dense_309_accuracy: 0.2216\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 9.8245 - dense_301_loss: 1.2575 - dense_303_loss: 1.7825 - dense_305_loss: 2.0859 - dense_307_loss: 2.2126 - dense_309_loss: 2.4667 - dense_301_accuracy: 0.5941 - dense_303_accuracy: 0.3866 - dense_305_accuracy: 0.2925 - dense_307_accuracy: 0.2268 - dense_309_accuracy: 0.2062 - val_loss: 13.4293 - val_dense_301_loss: 3.8171 - val_dense_303_loss: 2.1914 - val_dense_305_loss: 2.4226 - val_dense_307_loss: 2.5049 - val_dense_309_loss: 2.6344 - val_dense_301_accuracy: 0.0103 - val_dense_303_accuracy: 0.5464 - val_dense_305_accuracy: 0.3763 - val_dense_307_accuracy: 0.2990 - val_dense_309_accuracy: 0.2938\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 8.8822 - dense_301_loss: 1.0778 - dense_303_loss: 1.5915 - dense_305_loss: 1.8300 - dense_307_loss: 2.0128 - dense_309_loss: 2.3265 - dense_301_accuracy: 0.6688 - dense_303_accuracy: 0.4601 - dense_305_accuracy: 0.3802 - dense_307_accuracy: 0.3235 - dense_309_accuracy: 0.2410 - val_loss: 12.4923 - val_dense_301_loss: 3.4594 - val_dense_303_loss: 2.0636 - val_dense_305_loss: 2.1667 - val_dense_307_loss: 2.2944 - val_dense_309_loss: 2.5428 - val_dense_301_accuracy: 0.0567 - val_dense_303_accuracy: 0.3351 - val_dense_305_accuracy: 0.4227 - val_dense_307_accuracy: 0.3196 - val_dense_309_accuracy: 0.1701\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 7.7277 - dense_301_loss: 0.7910 - dense_303_loss: 1.3950 - dense_305_loss: 1.5012 - dense_307_loss: 1.8410 - dense_309_loss: 2.1893 - dense_301_accuracy: 0.7448 - dense_303_accuracy: 0.5052 - dense_305_accuracy: 0.4652 - dense_307_accuracy: 0.3789 - dense_309_accuracy: 0.2822 - val_loss: 12.3430 - val_dense_301_loss: 3.8222 - val_dense_303_loss: 1.8182 - val_dense_305_loss: 2.0588 - val_dense_307_loss: 2.2790 - val_dense_309_loss: 2.4648 - val_dense_301_accuracy: 0.0361 - val_dense_303_accuracy: 0.6340 - val_dense_305_accuracy: 0.4794 - val_dense_307_accuracy: 0.3660 - val_dense_309_accuracy: 0.3144\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 6.8973 - dense_301_loss: 0.6691 - dense_303_loss: 1.1724 - dense_305_loss: 1.4417 - dense_307_loss: 1.5861 - dense_309_loss: 2.0258 - dense_301_accuracy: 0.8041 - dense_303_accuracy: 0.6211 - dense_305_accuracy: 0.5193 - dense_307_accuracy: 0.4691 - dense_309_accuracy: 0.3235 - val_loss: 11.7320 - val_dense_301_loss: 3.8274 - val_dense_303_loss: 1.7804 - val_dense_305_loss: 1.8546 - val_dense_307_loss: 2.0599 - val_dense_309_loss: 2.2841 - val_dense_301_accuracy: 0.0052 - val_dense_303_accuracy: 0.6237 - val_dense_305_accuracy: 0.5412 - val_dense_307_accuracy: 0.3505 - val_dense_309_accuracy: 0.3351\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 5.8804 - dense_301_loss: 0.4935 - dense_303_loss: 1.0106 - dense_305_loss: 1.2279 - dense_307_loss: 1.4155 - dense_309_loss: 1.7275 - dense_301_accuracy: 0.8441 - dense_303_accuracy: 0.6688 - dense_305_accuracy: 0.5851 - dense_307_accuracy: 0.5129 - dense_309_accuracy: 0.3840 - val_loss: 11.3559 - val_dense_301_loss: 4.7144 - val_dense_303_loss: 1.2418 - val_dense_305_loss: 1.5387 - val_dense_307_loss: 1.8576 - val_dense_309_loss: 1.9981 - val_dense_301_accuracy: 0.0052 - val_dense_303_accuracy: 0.7165 - val_dense_305_accuracy: 0.6340 - val_dense_307_accuracy: 0.5258 - val_dense_309_accuracy: 0.4742\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 5.1248 - dense_301_loss: 0.4609 - dense_303_loss: 0.7322 - dense_305_loss: 1.0186 - dense_307_loss: 1.2644 - dense_309_loss: 1.6034 - dense_301_accuracy: 0.8363 - dense_303_accuracy: 0.7242 - dense_305_accuracy: 0.6662 - dense_307_accuracy: 0.5606 - dense_309_accuracy: 0.4678 - val_loss: 10.4271 - val_dense_301_loss: 4.8168 - val_dense_303_loss: 1.1312 - val_dense_305_loss: 1.2924 - val_dense_307_loss: 1.4909 - val_dense_309_loss: 1.7095 - val_dense_301_accuracy: 0.0052 - val_dense_303_accuracy: 0.7680 - val_dense_305_accuracy: 0.6649 - val_dense_307_accuracy: 0.6649 - val_dense_309_accuracy: 0.6031\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 5s 7ms/sample - loss: 4.6582 - dense_301_loss: 0.4118 - dense_303_loss: 0.7486 - dense_305_loss: 0.9649 - dense_307_loss: 1.1208 - dense_309_loss: 1.4245 - dense_301_accuracy: 0.8673 - dense_303_accuracy: 0.7616 - dense_305_accuracy: 0.6997 - dense_307_accuracy: 0.6456 - dense_309_accuracy: 0.5335 - val_loss: 10.3908 - val_dense_301_loss: 5.5449 - val_dense_303_loss: 0.9224 - val_dense_305_loss: 1.2472 - val_dense_307_loss: 1.1763 - val_dense_309_loss: 1.7123 - val_dense_301_accuracy: 0.0052 - val_dense_303_accuracy: 0.8093 - val_dense_305_accuracy: 0.6959 - val_dense_307_accuracy: 0.7680 - val_dense_309_accuracy: 0.6649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.9477 - dense_301_loss: 0.3248 - dense_303_loss: 0.5603 - dense_305_loss: 0.7924 - dense_307_loss: 0.9727 - dense_309_loss: 1.2879 - dense_301_accuracy: 0.8956 - dense_303_accuracy: 0.8119 - dense_305_accuracy: 0.7307 - dense_307_accuracy: 0.6508 - dense_309_accuracy: 0.5631 - val_loss: 9.9646 - val_dense_301_loss: 5.9941 - val_dense_303_loss: 0.7297 - val_dense_305_loss: 0.9198 - val_dense_307_loss: 1.1025 - val_dense_309_loss: 1.3457 - val_dense_301_accuracy: 0.0567 - val_dense_303_accuracy: 0.8196 - val_dense_305_accuracy: 0.7010 - val_dense_307_accuracy: 0.7371 - val_dense_309_accuracy: 0.7010\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.4957 - dense_301_loss: 0.2560 - dense_303_loss: 0.5520 - dense_305_loss: 0.7929 - dense_307_loss: 0.8731 - dense_309_loss: 1.0344 - dense_301_accuracy: 0.9227 - dense_303_accuracy: 0.8209 - dense_305_accuracy: 0.7371 - dense_307_accuracy: 0.6946 - dense_309_accuracy: 0.6405 - val_loss: 10.6756 - val_dense_301_loss: 7.1781 - val_dense_303_loss: 0.7650 - val_dense_305_loss: 0.8529 - val_dense_307_loss: 0.9324 - val_dense_309_loss: 1.1253 - val_dense_301_accuracy: 0.0155 - val_dense_303_accuracy: 0.8351 - val_dense_305_accuracy: 0.7423 - val_dense_307_accuracy: 0.7887 - val_dense_309_accuracy: 0.7526\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 3.1406 - dense_301_loss: 0.2657 - dense_303_loss: 0.4023 - dense_305_loss: 0.7292 - dense_307_loss: 0.7398 - dense_309_loss: 0.9833 - dense_301_accuracy: 0.9162 - dense_303_accuracy: 0.8853 - dense_305_accuracy: 0.7461 - dense_307_accuracy: 0.7526 - dense_309_accuracy: 0.6598 - val_loss: 10.1094 - val_dense_301_loss: 7.1338 - val_dense_303_loss: 0.6626 - val_dense_305_loss: 0.8048 - val_dense_307_loss: 0.7774 - val_dense_309_loss: 1.0875 - val_dense_301_accuracy: 0.0309 - val_dense_303_accuracy: 0.8196 - val_dense_305_accuracy: 0.7423 - val_dense_307_accuracy: 0.8144 - val_dense_309_accuracy: 0.7268\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 2.8286 - dense_301_loss: 0.2726 - dense_303_loss: 0.3626 - dense_305_loss: 0.5753 - dense_307_loss: 0.7285 - dense_309_loss: 0.8907 - dense_301_accuracy: 0.9021 - dense_303_accuracy: 0.8737 - dense_305_accuracy: 0.7887 - dense_307_accuracy: 0.7152 - dense_309_accuracy: 0.6946 - val_loss: 11.3652 - val_dense_301_loss: 8.5496 - val_dense_303_loss: 0.6158 - val_dense_305_loss: 0.8404 - val_dense_307_loss: 0.7371 - val_dense_309_loss: 1.0152 - val_dense_301_accuracy: 0.0412 - val_dense_303_accuracy: 0.8505 - val_dense_305_accuracy: 0.7216 - val_dense_307_accuracy: 0.7784 - val_dense_309_accuracy: 0.7732\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 2.5715 - dense_301_loss: 0.2300 - dense_303_loss: 0.3204 - dense_305_loss: 0.5840 - dense_307_loss: 0.6644 - dense_309_loss: 0.7608 - dense_301_accuracy: 0.9214 - dense_303_accuracy: 0.8892 - dense_305_accuracy: 0.7977 - dense_307_accuracy: 0.7539 - dense_309_accuracy: 0.7191 - val_loss: 11.5905 - val_dense_301_loss: 8.9269 - val_dense_303_loss: 0.5572 - val_dense_305_loss: 0.7570 - val_dense_307_loss: 0.6919 - val_dense_309_loss: 0.9272 - val_dense_301_accuracy: 0.0361 - val_dense_303_accuracy: 0.8763 - val_dense_305_accuracy: 0.7371 - val_dense_307_accuracy: 0.7629 - val_dense_309_accuracy: 0.7784\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 2.2497 - dense_301_loss: 0.1945 - dense_303_loss: 0.2925 - dense_305_loss: 0.4735 - dense_307_loss: 0.5900 - dense_309_loss: 0.6912 - dense_301_accuracy: 0.9394 - dense_303_accuracy: 0.9085 - dense_305_accuracy: 0.8144 - dense_307_accuracy: 0.7977 - dense_309_accuracy: 0.7616 - val_loss: 10.8083 - val_dense_301_loss: 8.2139 - val_dense_303_loss: 0.5641 - val_dense_305_loss: 0.7520 - val_dense_307_loss: 0.6026 - val_dense_309_loss: 0.9963 - val_dense_301_accuracy: 0.0412 - val_dense_303_accuracy: 0.8557 - val_dense_305_accuracy: 0.7371 - val_dense_307_accuracy: 0.8093 - val_dense_309_accuracy: 0.7732\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 2.1414 - dense_301_loss: 0.1780 - dense_303_loss: 0.2943 - dense_305_loss: 0.4692 - dense_307_loss: 0.5245 - dense_309_loss: 0.6538 - dense_301_accuracy: 0.9446 - dense_303_accuracy: 0.9034 - dense_305_accuracy: 0.8402 - dense_307_accuracy: 0.8067 - dense_309_accuracy: 0.7564 - val_loss: 12.2827 - val_dense_301_loss: 10.0282 - val_dense_303_loss: 0.6594 - val_dense_305_loss: 0.7113 - val_dense_307_loss: 0.6576 - val_dense_309_loss: 0.9728 - val_dense_301_accuracy: 0.0361 - val_dense_303_accuracy: 0.8402 - val_dense_305_accuracy: 0.7577 - val_dense_307_accuracy: 0.7577 - val_dense_309_accuracy: 0.7887\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.9899 - dense_301_loss: 0.1823 - dense_303_loss: 0.2641 - dense_305_loss: 0.4028 - dense_307_loss: 0.5032 - dense_309_loss: 0.6376 - dense_301_accuracy: 0.9381 - dense_303_accuracy: 0.9072 - dense_305_accuracy: 0.8582 - dense_307_accuracy: 0.8376 - dense_309_accuracy: 0.7590 - val_loss: 12.9641 - val_dense_301_loss: 10.8643 - val_dense_303_loss: 0.5271 - val_dense_305_loss: 0.7465 - val_dense_307_loss: 0.5777 - val_dense_309_loss: 0.9996 - val_dense_301_accuracy: 0.0412 - val_dense_303_accuracy: 0.8660 - val_dense_305_accuracy: 0.7990 - val_dense_307_accuracy: 0.8144 - val_dense_309_accuracy: 0.7938\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.9291 - dense_301_loss: 0.1594 - dense_303_loss: 0.2789 - dense_305_loss: 0.3837 - dense_307_loss: 0.5082 - dense_309_loss: 0.5964 - dense_301_accuracy: 0.9472 - dense_303_accuracy: 0.9008 - dense_305_accuracy: 0.8698 - dense_307_accuracy: 0.8106 - dense_309_accuracy: 0.7899 - val_loss: 13.6425 - val_dense_301_loss: 11.4226 - val_dense_303_loss: 0.7331 - val_dense_305_loss: 0.7902 - val_dense_307_loss: 0.6256 - val_dense_309_loss: 0.9637 - val_dense_301_accuracy: 0.0309 - val_dense_303_accuracy: 0.8711 - val_dense_305_accuracy: 0.7784 - val_dense_307_accuracy: 0.7938 - val_dense_309_accuracy: 0.8196\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.7845 - dense_301_loss: 0.1479 - dense_303_loss: 0.2369 - dense_305_loss: 0.3943 - dense_307_loss: 0.4536 - dense_309_loss: 0.5313 - dense_301_accuracy: 0.9497 - dense_303_accuracy: 0.9162 - dense_305_accuracy: 0.8428 - dense_307_accuracy: 0.8312 - dense_309_accuracy: 0.8209 - val_loss: 13.3870 - val_dense_301_loss: 11.3806 - val_dense_303_loss: 0.6242 - val_dense_305_loss: 0.7117 - val_dense_307_loss: 0.5483 - val_dense_309_loss: 0.9046 - val_dense_301_accuracy: 0.0206 - val_dense_303_accuracy: 0.8711 - val_dense_305_accuracy: 0.7732 - val_dense_307_accuracy: 0.8144 - val_dense_309_accuracy: 0.8144\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 6s 7ms/sample - loss: 1.6586 - dense_301_loss: 0.1285 - dense_303_loss: 0.2089 - dense_305_loss: 0.3542 - dense_307_loss: 0.4278 - dense_309_loss: 0.5405 - dense_301_accuracy: 0.9536 - dense_303_accuracy: 0.9330 - dense_305_accuracy: 0.8724 - dense_307_accuracy: 0.8428 - dense_309_accuracy: 0.8015 - val_loss: 13.5363 - val_dense_301_loss: 11.3785 - val_dense_303_loss: 0.6499 - val_dense_305_loss: 0.8016 - val_dense_307_loss: 0.6134 - val_dense_309_loss: 0.9552 - val_dense_301_accuracy: 0.0309 - val_dense_303_accuracy: 0.8660 - val_dense_305_accuracy: 0.7835 - val_dense_307_accuracy: 0.8093 - val_dense_309_accuracy: 0.8247\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: 1.6033 - dense_301_loss: 0.1703 - dense_303_loss: 0.1825 - dense_305_loss: 0.3314 - dense_307_loss: 0.4275 - dense_309_loss: 0.4741 - dense_301_accuracy: 0.9356 - dense_303_accuracy: 0.9356 - dense_305_accuracy: 0.8853 - dense_307_accuracy: 0.8479 - dense_309_accuracy: 0.8286 - val_loss: 14.4309 - val_dense_301_loss: 11.9733 - val_dense_303_loss: 0.6378 - val_dense_305_loss: 0.8845 - val_dense_307_loss: 0.6810 - val_dense_309_loss: 0.9786 - val_dense_301_accuracy: 0.0103 - val_dense_303_accuracy: 0.8711 - val_dense_305_accuracy: 0.7938 - val_dense_307_accuracy: 0.7835 - val_dense_309_accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: nan - dense_301_loss: nan - dense_303_loss: nan - dense_305_loss: nan - dense_307_loss: nan - dense_309_loss: nan - dense_301_accuracy: 0.8015 - dense_303_accuracy: 0.7706 - dense_305_accuracy: 0.7242 - dense_307_accuracy: 0.7204 - dense_309_accuracy: 0.6701 - val_loss: nan - val_dense_301_loss: nan - val_dense_303_loss: nan - val_dense_305_loss: nan - val_dense_307_loss: nan - val_dense_309_loss: nan - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.0515 - val_dense_305_accuracy: 0.0515 - val_dense_307_accuracy: 0.0773 - val_dense_309_accuracy: 0.0258\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 6s 8ms/sample - loss: nan - dense_301_loss: nan - dense_303_loss: nan - dense_305_loss: nan - dense_307_loss: nan - dense_309_loss: nan - dense_301_accuracy: 0.0619 - dense_303_accuracy: 0.0631 - dense_305_accuracy: 0.0541 - dense_307_accuracy: 0.0503 - dense_309_accuracy: 0.0477 - val_loss: nan - val_dense_301_loss: nan - val_dense_303_loss: nan - val_dense_305_loss: nan - val_dense_307_loss: nan - val_dense_309_loss: nan - val_dense_301_accuracy: 0.0000e+00 - val_dense_303_accuracy: 0.0515 - val_dense_305_accuracy: 0.0515 - val_dense_307_accuracy: 0.0773 - val_dense_309_accuracy: 0.0258\n"
     ]
    }
   ],
   "source": [
    "model = arc_create_model()\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the size of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def arc_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    \n",
    "    conv1 = layers.Conv2D(32, (5, 5), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    conv2 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, kernel_initializer = 'uniform',activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 50, 200, 32)  832         input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_104 (MaxPooling2D (None, 25, 100, 32)  0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 25, 100, 64)  51264       max_pooling2d_104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_105 (MaxPooling2D (None, 13, 50, 64)   0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 13, 50, 64)   102464      max_pooling2d_105[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 13, 50, 64)   256         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_106 (MaxPooling2D (None, 7, 25, 64)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 11200)        0           max_pooling2d_106[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_310 (Dense)               (None, 64)           716864      flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_312 (Dense)               (None, 64)           716864      flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_314 (Dense)               (None, 64)           716864      flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_316 (Dense)               (None, 64)           716864      flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_318 (Dense)               (None, 64)           716864      flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 64)           0           dense_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 64)           0           dense_312[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 64)           0           dense_314[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 64)           0           dense_316[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 64)           0           dense_318[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_311 (Dense)               (None, 19)           1235        dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_313 (Dense)               (None, 19)           1235        dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_315 (Dense)               (None, 19)           1235        dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_317 (Dense)               (None, 19)           1235        dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_319 (Dense)               (None, 19)           1235        dropout_159[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,745,311\n",
      "Trainable params: 3,745,183\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 26s 33ms/sample - loss: 15.3448 - dense_311_loss: 3.0479 - dense_313_loss: 3.0211 - dense_315_loss: 3.0451 - dense_317_loss: 3.0862 - dense_319_loss: 3.1191 - dense_311_accuracy: 0.0722 - dense_313_accuracy: 0.0683 - dense_315_accuracy: 0.0644 - dense_317_accuracy: 0.0670 - dense_319_accuracy: 0.0335 - val_loss: 14.8897 - val_dense_311_loss: 3.1035 - val_dense_313_loss: 2.9422 - val_dense_315_loss: 2.9440 - val_dense_317_loss: 2.9287 - val_dense_319_loss: 2.9491 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0309 - val_dense_315_accuracy: 0.0722 - val_dense_317_accuracy: 0.0567 - val_dense_319_accuracy: 0.0773\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 18s 23ms/sample - loss: 14.6744 - dense_311_loss: 2.8915 - dense_313_loss: 2.9436 - dense_315_loss: 2.9459 - dense_317_loss: 2.9464 - dense_319_loss: 2.9468 - dense_311_accuracy: 0.0760 - dense_313_accuracy: 0.1057 - dense_315_accuracy: 0.0851 - dense_317_accuracy: 0.0735 - dense_319_accuracy: 0.0773 - val_loss: 14.9269 - val_dense_311_loss: 3.1800 - val_dense_313_loss: 2.9382 - val_dense_315_loss: 2.9437 - val_dense_317_loss: 2.9339 - val_dense_319_loss: 2.9476 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0773 - val_dense_315_accuracy: 0.0979 - val_dense_317_accuracy: 0.0567 - val_dense_319_accuracy: 0.0722\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 19s 24ms/sample - loss: 14.6498 - dense_311_loss: 2.8773 - dense_313_loss: 2.9427 - dense_315_loss: 2.9427 - dense_317_loss: 2.9443 - dense_319_loss: 2.9422 - dense_311_accuracy: 0.0747 - dense_313_accuracy: 0.1057 - dense_315_accuracy: 0.0992 - dense_317_accuracy: 0.0979 - dense_319_accuracy: 0.1121 - val_loss: 15.0138 - val_dense_311_loss: 3.2901 - val_dense_313_loss: 2.9401 - val_dense_315_loss: 2.9431 - val_dense_317_loss: 2.9368 - val_dense_319_loss: 2.9442 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0825 - val_dense_315_accuracy: 0.0979 - val_dense_317_accuracy: 0.0567 - val_dense_319_accuracy: 0.0722\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 19s 24ms/sample - loss: 14.6147 - dense_311_loss: 2.8424 - dense_313_loss: 2.9418 - dense_315_loss: 2.9421 - dense_317_loss: 2.9433 - dense_319_loss: 2.9414 - dense_311_accuracy: 0.0812 - dense_313_accuracy: 0.1057 - dense_315_accuracy: 0.0992 - dense_317_accuracy: 0.1018 - dense_319_accuracy: 0.1121 - val_loss: 14.9683 - val_dense_311_loss: 3.2362 - val_dense_313_loss: 2.9417 - val_dense_315_loss: 2.9431 - val_dense_317_loss: 2.9425 - val_dense_319_loss: 2.9427 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0773 - val_dense_315_accuracy: 0.0979 - val_dense_317_accuracy: 0.0979 - val_dense_319_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 19s 24ms/sample - loss: 14.5781 - dense_311_loss: 2.8103 - dense_313_loss: 2.9408 - dense_315_loss: 2.9425 - dense_317_loss: 2.9428 - dense_319_loss: 2.9402 - dense_311_accuracy: 0.0915 - dense_313_accuracy: 0.1057 - dense_315_accuracy: 0.0966 - dense_317_accuracy: 0.1018 - dense_319_accuracy: 0.1121 - val_loss: 14.8512 - val_dense_311_loss: 3.1062 - val_dense_313_loss: 2.9404 - val_dense_315_loss: 2.9429 - val_dense_317_loss: 2.9448 - val_dense_319_loss: 2.9429 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0773 - val_dense_315_accuracy: 0.0979 - val_dense_317_accuracy: 0.0979 - val_dense_319_accuracy: 0.1392\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.5416 - dense_311_loss: 2.7816 - dense_313_loss: 2.9285 - dense_315_loss: 2.9419 - dense_317_loss: 2.9498 - dense_319_loss: 2.9396 - dense_311_accuracy: 0.0863 - dense_313_accuracy: 0.1005 - dense_315_accuracy: 0.0979 - dense_317_accuracy: 0.1018 - dense_319_accuracy: 0.1108 - val_loss: 14.7437 - val_dense_311_loss: 2.9539 - val_dense_313_loss: 2.9092 - val_dense_315_loss: 2.9326 - val_dense_317_loss: 2.9583 - val_dense_319_loss: 2.9505 - val_dense_311_accuracy: 0.1701 - val_dense_313_accuracy: 0.0928 - val_dense_315_accuracy: 0.1031 - val_dense_317_accuracy: 0.0412 - val_dense_319_accuracy: 0.0258\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 23s 30ms/sample - loss: 14.3240 - dense_311_loss: 2.6259 - dense_313_loss: 2.8634 - dense_315_loss: 2.9389 - dense_317_loss: 2.9419 - dense_319_loss: 2.9333 - dense_311_accuracy: 0.1095 - dense_313_accuracy: 0.1082 - dense_315_accuracy: 0.0966 - dense_317_accuracy: 0.0799 - dense_319_accuracy: 0.1031 - val_loss: 16.2788 - val_dense_311_loss: 2.8606 - val_dense_313_loss: 3.0408 - val_dense_315_loss: 3.3622 - val_dense_317_loss: 3.4553 - val_dense_319_loss: 3.5587 - val_dense_311_accuracy: 0.1856 - val_dense_313_accuracy: 0.0309 - val_dense_315_accuracy: 0.0412 - val_dense_317_accuracy: 0.0412 - val_dense_319_accuracy: 0.0567\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 21s 28ms/sample - loss: 14.0683 - dense_311_loss: 2.5048 - dense_313_loss: 2.8478 - dense_315_loss: 2.9133 - dense_317_loss: 2.8924 - dense_319_loss: 2.9089 - dense_311_accuracy: 0.1508 - dense_313_accuracy: 0.1070 - dense_315_accuracy: 0.0966 - dense_317_accuracy: 0.0670 - dense_319_accuracy: 0.0696 - val_loss: 15.8554 - val_dense_311_loss: 2.8698 - val_dense_313_loss: 2.9364 - val_dense_315_loss: 3.2462 - val_dense_317_loss: 3.4957 - val_dense_319_loss: 3.3663 - val_dense_311_accuracy: 0.0258 - val_dense_313_accuracy: 0.0515 - val_dense_315_accuracy: 0.0412 - val_dense_317_accuracy: 0.0412 - val_dense_319_accuracy: 0.0567\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 22s 28ms/sample - loss: 13.6720 - dense_311_loss: 2.3433 - dense_313_loss: 2.7841 - dense_315_loss: 2.8814 - dense_317_loss: 2.7986 - dense_319_loss: 2.8543 - dense_311_accuracy: 0.1804 - dense_313_accuracy: 0.1082 - dense_315_accuracy: 0.1082 - dense_317_accuracy: 0.1134 - dense_319_accuracy: 0.1211 - val_loss: 14.6032 - val_dense_311_loss: 3.0605 - val_dense_313_loss: 2.8356 - val_dense_315_loss: 2.8724 - val_dense_317_loss: 2.9106 - val_dense_319_loss: 2.9393 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.1082 - val_dense_315_accuracy: 0.1289 - val_dense_317_accuracy: 0.0979 - val_dense_319_accuracy: 0.0876\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 13.2412 - dense_311_loss: 2.1791 - dense_313_loss: 2.7740 - dense_315_loss: 2.7914 - dense_317_loss: 2.7039 - dense_319_loss: 2.7974 - dense_311_accuracy: 0.2036 - dense_313_accuracy: 0.1405 - dense_315_accuracy: 0.1186 - dense_317_accuracy: 0.1405 - dense_319_accuracy: 0.1134 - val_loss: 15.3339 - val_dense_311_loss: 2.9228 - val_dense_313_loss: 2.9105 - val_dense_315_loss: 3.0517 - val_dense_317_loss: 3.1693 - val_dense_319_loss: 3.2580 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.0979 - val_dense_315_accuracy: 0.0722 - val_dense_317_accuracy: 0.0464 - val_dense_319_accuracy: 0.0876\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 18s 24ms/sample - loss: 12.6885 - dense_311_loss: 2.0777 - dense_313_loss: 2.7026 - dense_315_loss: 2.6706 - dense_317_loss: 2.5602 - dense_319_loss: 2.6940 - dense_311_accuracy: 0.2822 - dense_313_accuracy: 0.1546 - dense_315_accuracy: 0.1585 - dense_317_accuracy: 0.1714 - dense_319_accuracy: 0.1173 - val_loss: 14.2142 - val_dense_311_loss: 3.0777 - val_dense_313_loss: 2.7459 - val_dense_315_loss: 2.7720 - val_dense_317_loss: 2.7645 - val_dense_319_loss: 2.8822 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.1392 - val_dense_315_accuracy: 0.1495 - val_dense_317_accuracy: 0.1392 - val_dense_319_accuracy: 0.1804\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 19s 24ms/sample - loss: 12.1323 - dense_311_loss: 1.8689 - dense_313_loss: 2.6027 - dense_315_loss: 2.5281 - dense_317_loss: 2.5040 - dense_319_loss: 2.6170 - dense_311_accuracy: 0.3260 - dense_313_accuracy: 0.1521 - dense_315_accuracy: 0.1817 - dense_317_accuracy: 0.1688 - dense_319_accuracy: 0.1276 - val_loss: 14.4157 - val_dense_311_loss: 3.3520 - val_dense_313_loss: 2.6630 - val_dense_315_loss: 2.7702 - val_dense_317_loss: 2.7694 - val_dense_319_loss: 2.8848 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.1237 - val_dense_315_accuracy: 0.1753 - val_dense_317_accuracy: 0.1753 - val_dense_319_accuracy: 0.2010\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 18s 24ms/sample - loss: 11.5014 - dense_311_loss: 1.6859 - dense_313_loss: 2.4790 - dense_315_loss: 2.4626 - dense_317_loss: 2.3454 - dense_319_loss: 2.5177 - dense_311_accuracy: 0.4034 - dense_313_accuracy: 0.1637 - dense_315_accuracy: 0.1959 - dense_317_accuracy: 0.2088 - dense_319_accuracy: 0.1611 - val_loss: 14.0297 - val_dense_311_loss: 3.8006 - val_dense_313_loss: 2.5261 - val_dense_315_loss: 2.6258 - val_dense_317_loss: 2.5653 - val_dense_319_loss: 2.6452 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.2062 - val_dense_315_accuracy: 0.1598 - val_dense_317_accuracy: 0.1804 - val_dense_319_accuracy: 0.1753\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 18s 23ms/sample - loss: 10.7118 - dense_311_loss: 1.4490 - dense_313_loss: 2.2818 - dense_315_loss: 2.2986 - dense_317_loss: 2.2664 - dense_319_loss: 2.4083 - dense_311_accuracy: 0.4369 - dense_313_accuracy: 0.2152 - dense_315_accuracy: 0.2101 - dense_317_accuracy: 0.2229 - dense_319_accuracy: 0.1869 - val_loss: 13.7631 - val_dense_311_loss: 3.0750 - val_dense_313_loss: 2.5931 - val_dense_315_loss: 2.6946 - val_dense_317_loss: 2.7617 - val_dense_319_loss: 2.8367 - val_dense_311_accuracy: 0.0052 - val_dense_313_accuracy: 0.1237 - val_dense_315_accuracy: 0.1701 - val_dense_317_accuracy: 0.2010 - val_dense_319_accuracy: 0.2474\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 18s 23ms/sample - loss: 9.8979 - dense_311_loss: 1.1658 - dense_313_loss: 2.1720 - dense_315_loss: 2.1226 - dense_317_loss: 2.1099 - dense_319_loss: 2.3053 - dense_311_accuracy: 0.5670 - dense_313_accuracy: 0.2268 - dense_315_accuracy: 0.2436 - dense_317_accuracy: 0.2784 - dense_319_accuracy: 0.2281 - val_loss: 13.2488 - val_dense_311_loss: 3.8831 - val_dense_313_loss: 2.2186 - val_dense_315_loss: 2.3497 - val_dense_317_loss: 2.3497 - val_dense_319_loss: 2.4506 - val_dense_311_accuracy: 0.0206 - val_dense_313_accuracy: 0.2887 - val_dense_315_accuracy: 0.2216 - val_dense_317_accuracy: 0.2577 - val_dense_319_accuracy: 0.2526\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 18s 24ms/sample - loss: 8.9758 - dense_311_loss: 0.9106 - dense_313_loss: 1.9512 - dense_315_loss: 1.9492 - dense_317_loss: 2.0035 - dense_319_loss: 2.1663 - dense_311_accuracy: 0.6624 - dense_313_accuracy: 0.2629 - dense_315_accuracy: 0.2925 - dense_317_accuracy: 0.2796 - dense_319_accuracy: 0.2345 - val_loss: 12.8694 - val_dense_311_loss: 4.2174 - val_dense_313_loss: 2.0323 - val_dense_315_loss: 2.0695 - val_dense_317_loss: 2.3282 - val_dense_319_loss: 2.2456 - val_dense_311_accuracy: 0.0206 - val_dense_313_accuracy: 0.2938 - val_dense_315_accuracy: 0.3505 - val_dense_317_accuracy: 0.2371 - val_dense_319_accuracy: 0.3041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 8.5649 - dense_311_loss: 0.8394 - dense_313_loss: 1.8733 - dense_315_loss: 1.9121 - dense_317_loss: 1.9332 - dense_319_loss: 2.0082 - dense_311_accuracy: 0.6856 - dense_313_accuracy: 0.3157 - dense_315_accuracy: 0.3621 - dense_317_accuracy: 0.3338 - dense_319_accuracy: 0.2693 - val_loss: 12.6660 - val_dense_311_loss: 5.0473 - val_dense_313_loss: 1.7558 - val_dense_315_loss: 1.9818 - val_dense_317_loss: 2.0478 - val_dense_319_loss: 2.0774 - val_dense_311_accuracy: 0.0309 - val_dense_313_accuracy: 0.4588 - val_dense_315_accuracy: 0.3866 - val_dense_317_accuracy: 0.4381 - val_dense_319_accuracy: 0.2732\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 7.8010 - dense_311_loss: 0.7110 - dense_313_loss: 1.6529 - dense_315_loss: 1.7075 - dense_317_loss: 1.8503 - dense_319_loss: 1.8590 - dense_311_accuracy: 0.7216 - dense_313_accuracy: 0.3776 - dense_315_accuracy: 0.3789 - dense_317_accuracy: 0.3724 - dense_319_accuracy: 0.2822 - val_loss: 11.6889 - val_dense_311_loss: 4.5874 - val_dense_313_loss: 1.5043 - val_dense_315_loss: 1.7638 - val_dense_317_loss: 2.1198 - val_dense_319_loss: 2.0086 - val_dense_311_accuracy: 0.0258 - val_dense_313_accuracy: 0.5103 - val_dense_315_accuracy: 0.5155 - val_dense_317_accuracy: 0.4845 - val_dense_319_accuracy: 0.2784\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 7.0466 - dense_311_loss: 0.5841 - dense_313_loss: 1.4510 - dense_315_loss: 1.4988 - dense_317_loss: 1.6980 - dense_319_loss: 1.7866 - dense_311_accuracy: 0.7912 - dense_313_accuracy: 0.4936 - dense_315_accuracy: 0.4588 - dense_317_accuracy: 0.3956 - dense_319_accuracy: 0.3080 - val_loss: 11.3647 - val_dense_311_loss: 5.4608 - val_dense_313_loss: 1.3718 - val_dense_315_loss: 1.4653 - val_dense_317_loss: 1.6785 - val_dense_319_loss: 1.7819 - val_dense_311_accuracy: 0.0825 - val_dense_313_accuracy: 0.6186 - val_dense_315_accuracy: 0.5515 - val_dense_317_accuracy: 0.5361 - val_dense_319_accuracy: 0.3351\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 6.0908 - dense_311_loss: 0.4206 - dense_313_loss: 1.2209 - dense_315_loss: 1.3104 - dense_317_loss: 1.4903 - dense_319_loss: 1.6391 - dense_311_accuracy: 0.8428 - dense_313_accuracy: 0.5193 - dense_315_accuracy: 0.5232 - dense_317_accuracy: 0.4626 - dense_319_accuracy: 0.3608 - val_loss: 11.4835 - val_dense_311_loss: 5.2955 - val_dense_313_loss: 1.3214 - val_dense_315_loss: 1.3731 - val_dense_317_loss: 1.7930 - val_dense_319_loss: 1.7970 - val_dense_311_accuracy: 0.0206 - val_dense_313_accuracy: 0.6134 - val_dense_315_accuracy: 0.5670 - val_dense_317_accuracy: 0.4536 - val_dense_319_accuracy: 0.4072\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 5.4659 - dense_311_loss: 0.4456 - dense_313_loss: 1.0813 - dense_315_loss: 1.1447 - dense_317_loss: 1.3229 - dense_319_loss: 1.5092 - dense_311_accuracy: 0.8454 - dense_313_accuracy: 0.5979 - dense_315_accuracy: 0.6005 - dense_317_accuracy: 0.5773 - dense_319_accuracy: 0.4201 - val_loss: 13.1044 - val_dense_311_loss: 7.2939 - val_dense_313_loss: 1.0423 - val_dense_315_loss: 1.2088 - val_dense_317_loss: 1.6973 - val_dense_319_loss: 1.6492 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.6546 - val_dense_315_accuracy: 0.6546 - val_dense_317_accuracy: 0.5103 - val_dense_319_accuracy: 0.4381\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 21s 27ms/sample - loss: 4.9093 - dense_311_loss: 0.3915 - dense_313_loss: 0.9159 - dense_315_loss: 1.0660 - dense_317_loss: 1.1699 - dense_319_loss: 1.3609 - dense_311_accuracy: 0.8505 - dense_313_accuracy: 0.6482 - dense_315_accuracy: 0.6469 - dense_317_accuracy: 0.5966 - dense_319_accuracy: 0.4974 - val_loss: 10.4214 - val_dense_311_loss: 6.8241 - val_dense_313_loss: 0.7278 - val_dense_315_loss: 0.9933 - val_dense_317_loss: 1.2533 - val_dense_319_loss: 1.2529 - val_dense_311_accuracy: 0.1237 - val_dense_313_accuracy: 0.7629 - val_dense_315_accuracy: 0.7113 - val_dense_317_accuracy: 0.6753 - val_dense_319_accuracy: 0.6134\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 4.5208 - dense_311_loss: 0.4024 - dense_313_loss: 0.8345 - dense_315_loss: 0.9482 - dense_317_loss: 1.0987 - dense_319_loss: 1.2123 - dense_311_accuracy: 0.8647 - dense_313_accuracy: 0.6649 - dense_315_accuracy: 0.6662 - dense_317_accuracy: 0.6082 - dense_319_accuracy: 0.5116 - val_loss: 11.5442 - val_dense_311_loss: 7.7355 - val_dense_313_loss: 0.7966 - val_dense_315_loss: 0.8870 - val_dense_317_loss: 1.3310 - val_dense_319_loss: 1.2906 - val_dense_311_accuracy: 0.0052 - val_dense_313_accuracy: 0.7474 - val_dense_315_accuracy: 0.7216 - val_dense_317_accuracy: 0.6649 - val_dense_319_accuracy: 0.6392\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 3.9511 - dense_311_loss: 0.2998 - dense_313_loss: 0.7641 - dense_315_loss: 0.8808 - dense_317_loss: 0.9178 - dense_319_loss: 1.1286 - dense_311_accuracy: 0.8982 - dense_313_accuracy: 0.7320 - dense_315_accuracy: 0.6997 - dense_317_accuracy: 0.6662 - dense_319_accuracy: 0.5683 - val_loss: 11.5768 - val_dense_311_loss: 9.2687 - val_dense_313_loss: 0.6216 - val_dense_315_loss: 0.7876 - val_dense_317_loss: 0.9581 - val_dense_319_loss: 0.8800 - val_dense_311_accuracy: 0.0155 - val_dense_313_accuracy: 0.7835 - val_dense_315_accuracy: 0.7629 - val_dense_317_accuracy: 0.7526 - val_dense_319_accuracy: 0.7268\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 3.6850 - dense_311_loss: 0.3177 - dense_313_loss: 0.7252 - dense_315_loss: 0.7308 - dense_317_loss: 0.9638 - dense_319_loss: 0.9606 - dense_311_accuracy: 0.8879 - dense_313_accuracy: 0.7436 - dense_315_accuracy: 0.7152 - dense_317_accuracy: 0.6495 - dense_319_accuracy: 0.6250 - val_loss: 15.1650 - val_dense_311_loss: 11.0542 - val_dense_313_loss: 0.9567 - val_dense_315_loss: 0.8878 - val_dense_317_loss: 1.0440 - val_dense_319_loss: 1.2091 - val_dense_311_accuracy: 0.0000e+00 - val_dense_313_accuracy: 0.7165 - val_dense_315_accuracy: 0.7010 - val_dense_317_accuracy: 0.7732 - val_dense_319_accuracy: 0.7165\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 3.2198 - dense_311_loss: 0.2709 - dense_313_loss: 0.6124 - dense_315_loss: 0.7129 - dense_317_loss: 0.7553 - dense_319_loss: 0.8954 - dense_311_accuracy: 0.9008 - dense_313_accuracy: 0.7474 - dense_315_accuracy: 0.7384 - dense_317_accuracy: 0.7229 - dense_319_accuracy: 0.6585 - val_loss: 13.8856 - val_dense_311_loss: 10.7422 - val_dense_313_loss: 0.6578 - val_dense_315_loss: 0.9680 - val_dense_317_loss: 1.0349 - val_dense_319_loss: 1.3998 - val_dense_311_accuracy: 0.0825 - val_dense_313_accuracy: 0.7938 - val_dense_315_accuracy: 0.7423 - val_dense_317_accuracy: 0.7526 - val_dense_319_accuracy: 0.6907\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 2.8605 - dense_311_loss: 0.2221 - dense_313_loss: 0.5243 - dense_315_loss: 0.5963 - dense_317_loss: 0.6589 - dense_319_loss: 0.8286 - dense_311_accuracy: 0.9188 - dense_313_accuracy: 0.7835 - dense_315_accuracy: 0.7745 - dense_317_accuracy: 0.7758 - dense_319_accuracy: 0.6946 - val_loss: 11.5521 - val_dense_311_loss: 9.7599 - val_dense_313_loss: 0.5124 - val_dense_315_loss: 0.6454 - val_dense_317_loss: 0.8245 - val_dense_319_loss: 0.6763 - val_dense_311_accuracy: 0.0876 - val_dense_313_accuracy: 0.8196 - val_dense_315_accuracy: 0.7990 - val_dense_317_accuracy: 0.7887 - val_dense_319_accuracy: 0.8093\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 2.6350 - dense_311_loss: 0.2286 - dense_313_loss: 0.4916 - dense_315_loss: 0.5353 - dense_317_loss: 0.6069 - dense_319_loss: 0.7521 - dense_311_accuracy: 0.9111 - dense_313_accuracy: 0.8170 - dense_315_accuracy: 0.7771 - dense_317_accuracy: 0.7590 - dense_319_accuracy: 0.7049 - val_loss: 10.5431 - val_dense_311_loss: 8.3933 - val_dense_313_loss: 0.5601 - val_dense_315_loss: 0.7399 - val_dense_317_loss: 0.9651 - val_dense_319_loss: 0.6486 - val_dense_311_accuracy: 0.1186 - val_dense_313_accuracy: 0.8402 - val_dense_315_accuracy: 0.8093 - val_dense_317_accuracy: 0.7732 - val_dense_319_accuracy: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 2.4453 - dense_311_loss: 0.2292 - dense_313_loss: 0.4987 - dense_315_loss: 0.4850 - dense_317_loss: 0.5712 - dense_319_loss: 0.6420 - dense_311_accuracy: 0.9124 - dense_313_accuracy: 0.8286 - dense_315_accuracy: 0.8144 - dense_317_accuracy: 0.7951 - dense_319_accuracy: 0.7526 - val_loss: 12.9581 - val_dense_311_loss: 10.7664 - val_dense_313_loss: 0.5483 - val_dense_315_loss: 0.7695 - val_dense_317_loss: 0.8182 - val_dense_319_loss: 0.8319 - val_dense_311_accuracy: 0.1134 - val_dense_313_accuracy: 0.8454 - val_dense_315_accuracy: 0.8144 - val_dense_317_accuracy: 0.8144 - val_dense_319_accuracy: 0.8454\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 2.2077 - dense_311_loss: 0.1808 - dense_313_loss: 0.4354 - dense_315_loss: 0.4403 - dense_317_loss: 0.5440 - dense_319_loss: 0.6092 - dense_311_accuracy: 0.9304 - dense_313_accuracy: 0.8389 - dense_315_accuracy: 0.8415 - dense_317_accuracy: 0.7964 - dense_319_accuracy: 0.7796 - val_loss: 11.6395 - val_dense_311_loss: 9.9186 - val_dense_313_loss: 0.5143 - val_dense_315_loss: 0.6895 - val_dense_317_loss: 0.7766 - val_dense_319_loss: 0.5487 - val_dense_311_accuracy: 0.1340 - val_dense_313_accuracy: 0.8505 - val_dense_315_accuracy: 0.8299 - val_dense_317_accuracy: 0.8093 - val_dense_319_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "model = arc_create_model()\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part G - Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using he_Uniform for intialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def int_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "       \n",
    "    conv1 = layers.Conv2D(32, (5, 5), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    \n",
    "    conv2 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, kernel_initializer = 'he_uniform',activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 50, 200, 32)  832         input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_107 (MaxPooling2D (None, 25, 100, 32)  0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 25, 100, 64)  51264       max_pooling2d_107[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_108 (MaxPooling2D (None, 13, 50, 64)   0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 13, 50, 64)   102464      max_pooling2d_108[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 13, 50, 64)   256         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_109 (MaxPooling2D (None, 7, 25, 64)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 11200)        0           max_pooling2d_109[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_320 (Dense)               (None, 64)           716864      flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_322 (Dense)               (None, 64)           716864      flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_324 (Dense)               (None, 64)           716864      flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_326 (Dense)               (None, 64)           716864      flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_328 (Dense)               (None, 64)           716864      flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 64)           0           dense_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 64)           0           dense_322[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 64)           0           dense_324[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 64)           0           dense_326[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 64)           0           dense_328[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_321 (Dense)               (None, 19)           1235        dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_323 (Dense)               (None, 19)           1235        dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_325 (Dense)               (None, 19)           1235        dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_327 (Dense)               (None, 19)           1235        dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_329 (Dense)               (None, 19)           1235        dropout_164[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,745,311\n",
      "Trainable params: 3,745,183\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 28s 36ms/sample - loss: 15.3420 - dense_321_loss: 2.9459 - dense_323_loss: 3.0605 - dense_325_loss: 3.0840 - dense_327_loss: 3.1349 - dense_329_loss: 3.1017 - dense_321_accuracy: 0.0619 - dense_323_accuracy: 0.0657 - dense_325_accuracy: 0.0580 - dense_327_accuracy: 0.0477 - dense_329_accuracy: 0.0606 - val_loss: 15.0317 - val_dense_321_loss: 3.3172 - val_dense_323_loss: 2.9376 - val_dense_325_loss: 2.9313 - val_dense_327_loss: 2.9360 - val_dense_329_loss: 2.9297 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0567 - val_dense_325_accuracy: 0.0464 - val_dense_327_accuracy: 0.0979 - val_dense_329_accuracy: 0.1082\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.5649 - dense_321_loss: 2.8001 - dense_323_loss: 2.9435 - dense_325_loss: 2.9360 - dense_327_loss: 2.9436 - dense_329_loss: 2.9424 - dense_321_accuracy: 0.0580 - dense_323_accuracy: 0.1031 - dense_325_accuracy: 0.0812 - dense_327_accuracy: 0.0863 - dense_329_accuracy: 0.1095 - val_loss: 15.6025 - val_dense_321_loss: 3.8392 - val_dense_323_loss: 2.9460 - val_dense_325_loss: 2.9456 - val_dense_327_loss: 2.9330 - val_dense_329_loss: 2.9432 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0722 - val_dense_325_accuracy: 0.0567 - val_dense_327_accuracy: 0.0979 - val_dense_329_accuracy: 0.1392\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.5357 - dense_321_loss: 2.7733 - dense_323_loss: 2.9429 - dense_325_loss: 2.9352 - dense_327_loss: 2.9435 - dense_329_loss: 2.9429 - dense_321_accuracy: 0.0657 - dense_323_accuracy: 0.1057 - dense_325_accuracy: 0.0928 - dense_327_accuracy: 0.1018 - dense_329_accuracy: 0.1121 - val_loss: 15.5246 - val_dense_321_loss: 3.7508 - val_dense_323_loss: 2.9445 - val_dense_325_loss: 2.9406 - val_dense_327_loss: 2.9438 - val_dense_329_loss: 2.9435 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0773 - val_dense_325_accuracy: 0.0567 - val_dense_327_accuracy: 0.0979 - val_dense_329_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.4888 - dense_321_loss: 2.7151 - dense_323_loss: 2.9420 - dense_325_loss: 2.9428 - dense_327_loss: 2.9429 - dense_329_loss: 2.9418 - dense_321_accuracy: 0.0799 - dense_323_accuracy: 0.1057 - dense_325_accuracy: 0.0992 - dense_327_accuracy: 0.1018 - dense_329_accuracy: 0.1121 - val_loss: 15.3522 - val_dense_321_loss: 3.5782 - val_dense_323_loss: 2.9433 - val_dense_325_loss: 2.9441 - val_dense_327_loss: 2.9443 - val_dense_329_loss: 2.9430 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0773 - val_dense_325_accuracy: 0.0979 - val_dense_327_accuracy: 0.0979 - val_dense_329_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 22s 28ms/sample - loss: 14.4595 - dense_321_loss: 2.6960 - dense_323_loss: 2.9411 - dense_325_loss: 2.9420 - dense_327_loss: 2.9426 - dense_329_loss: 2.9408 - dense_321_accuracy: 0.0644 - dense_323_accuracy: 0.1057 - dense_325_accuracy: 0.0992 - dense_327_accuracy: 0.1018 - dense_329_accuracy: 0.1121 - val_loss: 14.9692 - val_dense_321_loss: 3.2055 - val_dense_323_loss: 2.9432 - val_dense_325_loss: 2.9441 - val_dense_327_loss: 2.9446 - val_dense_329_loss: 2.9416 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0773 - val_dense_325_accuracy: 0.0979 - val_dense_327_accuracy: 0.0979 - val_dense_329_accuracy: 0.0258\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 14.3899 - dense_321_loss: 2.6180 - dense_323_loss: 2.9404 - dense_325_loss: 2.9463 - dense_327_loss: 2.9387 - dense_329_loss: 2.9398 - dense_321_accuracy: 0.0863 - dense_323_accuracy: 0.1057 - dense_325_accuracy: 0.1018 - dense_327_accuracy: 0.0992 - dense_329_accuracy: 0.1121 - val_loss: 15.0580 - val_dense_321_loss: 3.2455 - val_dense_323_loss: 2.9720 - val_dense_325_loss: 2.9358 - val_dense_327_loss: 2.9406 - val_dense_329_loss: 2.9595 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0258 - val_dense_325_accuracy: 0.0876 - val_dense_327_accuracy: 0.0515 - val_dense_329_accuracy: 0.0515\n",
      "Epoch 7/30\n",
      "776/776 [==============================] - 22s 28ms/sample - loss: 14.3031 - dense_321_loss: 2.5518 - dense_323_loss: 2.9416 - dense_325_loss: 2.9229 - dense_327_loss: 2.9425 - dense_329_loss: 2.9431 - dense_321_accuracy: 0.1160 - dense_323_accuracy: 0.1031 - dense_325_accuracy: 0.0928 - dense_327_accuracy: 0.0876 - dense_329_accuracy: 0.1095 - val_loss: 15.0764 - val_dense_321_loss: 3.3208 - val_dense_323_loss: 2.9469 - val_dense_325_loss: 2.9225 - val_dense_327_loss: 2.9415 - val_dense_329_loss: 2.9415 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0567 - val_dense_325_accuracy: 0.1082 - val_dense_327_accuracy: 0.0773 - val_dense_329_accuracy: 0.0567\n",
      "Epoch 8/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.2176 - dense_321_loss: 2.5080 - dense_323_loss: 2.9392 - dense_325_loss: 2.9174 - dense_327_loss: 2.9388 - dense_329_loss: 2.9188 - dense_321_accuracy: 0.1237 - dense_323_accuracy: 0.1070 - dense_325_accuracy: 0.1160 - dense_327_accuracy: 0.0954 - dense_329_accuracy: 0.1057 - val_loss: 15.1941 - val_dense_321_loss: 3.4080 - val_dense_323_loss: 2.9578 - val_dense_325_loss: 2.9187 - val_dense_327_loss: 2.9503 - val_dense_329_loss: 2.9448 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0412 - val_dense_325_accuracy: 0.0412 - val_dense_327_accuracy: 0.0722 - val_dense_329_accuracy: 0.0515\n",
      "Epoch 9/30\n",
      "776/776 [==============================] - 21s 28ms/sample - loss: 14.0104 - dense_321_loss: 2.3919 - dense_323_loss: 2.9394 - dense_325_loss: 2.8726 - dense_327_loss: 2.9173 - dense_329_loss: 2.9001 - dense_321_accuracy: 0.1469 - dense_323_accuracy: 0.1057 - dense_325_accuracy: 0.1082 - dense_327_accuracy: 0.0966 - dense_329_accuracy: 0.1108 - val_loss: 15.9118 - val_dense_321_loss: 3.8513 - val_dense_323_loss: 3.0519 - val_dense_325_loss: 2.9514 - val_dense_327_loss: 2.9453 - val_dense_329_loss: 2.9456 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0619 - val_dense_325_accuracy: 0.0309 - val_dense_327_accuracy: 0.0567 - val_dense_329_accuracy: 0.0619\n",
      "Epoch 10/30\n",
      "776/776 [==============================] - 22s 29ms/sample - loss: 13.8667 - dense_321_loss: 2.3308 - dense_323_loss: 2.9406 - dense_325_loss: 2.8364 - dense_327_loss: 2.8842 - dense_329_loss: 2.8741 - dense_321_accuracy: 0.1662 - dense_323_accuracy: 0.0954 - dense_325_accuracy: 0.1263 - dense_327_accuracy: 0.0941 - dense_329_accuracy: 0.1082 - val_loss: 15.7872 - val_dense_321_loss: 4.0641 - val_dense_323_loss: 2.9548 - val_dense_325_loss: 2.8903 - val_dense_327_loss: 2.9064 - val_dense_329_loss: 2.9071 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.0567 - val_dense_325_accuracy: 0.0464 - val_dense_327_accuracy: 0.0928 - val_dense_329_accuracy: 0.1443\n",
      "Epoch 11/30\n",
      "776/776 [==============================] - 23s 30ms/sample - loss: 13.5778 - dense_321_loss: 2.1947 - dense_323_loss: 2.8979 - dense_325_loss: 2.7938 - dense_327_loss: 2.8438 - dense_329_loss: 2.8441 - dense_321_accuracy: 0.2036 - dense_323_accuracy: 0.0863 - dense_325_accuracy: 0.1456 - dense_327_accuracy: 0.1082 - dense_329_accuracy: 0.1134 - val_loss: 15.2610 - val_dense_321_loss: 3.6725 - val_dense_323_loss: 2.9110 - val_dense_325_loss: 2.8451 - val_dense_327_loss: 2.9052 - val_dense_329_loss: 2.8981 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.1289 - val_dense_325_accuracy: 0.1289 - val_dense_327_accuracy: 0.1443 - val_dense_329_accuracy: 0.1237\n",
      "Epoch 12/30\n",
      "776/776 [==============================] - 22s 29ms/sample - loss: 13.2355 - dense_321_loss: 2.0426 - dense_323_loss: 2.8453 - dense_325_loss: 2.7114 - dense_327_loss: 2.8255 - dense_329_loss: 2.8092 - dense_321_accuracy: 0.2410 - dense_323_accuracy: 0.1031 - dense_325_accuracy: 0.1559 - dense_327_accuracy: 0.1366 - dense_329_accuracy: 0.1250 - val_loss: 15.7158 - val_dense_321_loss: 4.1533 - val_dense_323_loss: 2.7968 - val_dense_325_loss: 2.8189 - val_dense_327_loss: 2.8547 - val_dense_329_loss: 2.8673 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.1031 - val_dense_325_accuracy: 0.0412 - val_dense_327_accuracy: 0.1237 - val_dense_329_accuracy: 0.0670\n",
      "Epoch 13/30\n",
      "776/776 [==============================] - 24s 31ms/sample - loss: 12.6679 - dense_321_loss: 1.8544 - dense_323_loss: 2.7089 - dense_325_loss: 2.6232 - dense_327_loss: 2.7264 - dense_329_loss: 2.7244 - dense_321_accuracy: 0.3028 - dense_323_accuracy: 0.1418 - dense_325_accuracy: 0.1469 - dense_327_accuracy: 0.1598 - dense_329_accuracy: 0.1353 - val_loss: 15.4763 - val_dense_321_loss: 4.1600 - val_dense_323_loss: 2.7276 - val_dense_325_loss: 2.8068 - val_dense_327_loss: 2.7675 - val_dense_329_loss: 2.8396 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.1598 - val_dense_325_accuracy: 0.0309 - val_dense_327_accuracy: 0.1289 - val_dense_329_accuracy: 0.1082\n",
      "Epoch 14/30\n",
      "776/776 [==============================] - 22s 28ms/sample - loss: 11.8411 - dense_321_loss: 1.5510 - dense_323_loss: 2.4522 - dense_325_loss: 2.5434 - dense_327_loss: 2.6246 - dense_329_loss: 2.6473 - dense_321_accuracy: 0.4188 - dense_323_accuracy: 0.2049 - dense_325_accuracy: 0.1869 - dense_327_accuracy: 0.1662 - dense_329_accuracy: 0.1482 - val_loss: 15.4928 - val_dense_321_loss: 4.9158 - val_dense_323_loss: 2.4355 - val_dense_325_loss: 2.6983 - val_dense_327_loss: 2.6224 - val_dense_329_loss: 2.7300 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.3247 - val_dense_325_accuracy: 0.0979 - val_dense_327_accuracy: 0.2887 - val_dense_329_accuracy: 0.1804\n",
      "Epoch 15/30\n",
      "776/776 [==============================] - 21s 27ms/sample - loss: 10.9318 - dense_321_loss: 1.3069 - dense_323_loss: 2.2247 - dense_325_loss: 2.4211 - dense_327_loss: 2.4828 - dense_329_loss: 2.4871 - dense_321_accuracy: 0.5142 - dense_323_accuracy: 0.2693 - dense_325_accuracy: 0.1997 - dense_327_accuracy: 0.2010 - dense_329_accuracy: 0.1637 - val_loss: 15.2118 - val_dense_321_loss: 4.4868 - val_dense_323_loss: 2.3445 - val_dense_325_loss: 2.7915 - val_dense_327_loss: 2.7109 - val_dense_329_loss: 2.7101 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.2268 - val_dense_325_accuracy: 0.0567 - val_dense_327_accuracy: 0.2371 - val_dense_329_accuracy: 0.1495\n",
      "Epoch 16/30\n",
      "776/776 [==============================] - 19s 25ms/sample - loss: 10.0870 - dense_321_loss: 1.0141 - dense_323_loss: 2.0085 - dense_325_loss: 2.3488 - dense_327_loss: 2.3588 - dense_329_loss: 2.3798 - dense_321_accuracy: 0.6469 - dense_323_accuracy: 0.3466 - dense_325_accuracy: 0.2062 - dense_327_accuracy: 0.2564 - dense_329_accuracy: 0.2126 - val_loss: 14.8079 - val_dense_321_loss: 5.3876 - val_dense_323_loss: 1.9784 - val_dense_325_loss: 2.4841 - val_dense_327_loss: 2.4177 - val_dense_329_loss: 2.5670 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.5979 - val_dense_325_accuracy: 0.2216 - val_dense_327_accuracy: 0.2835 - val_dense_329_accuracy: 0.2732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 9.1362 - dense_321_loss: 0.8969 - dense_323_loss: 1.6756 - dense_325_loss: 2.1549 - dense_327_loss: 2.1746 - dense_329_loss: 2.2272 - dense_321_accuracy: 0.6740 - dense_323_accuracy: 0.4601 - dense_325_accuracy: 0.2887 - dense_327_accuracy: 0.2899 - dense_329_accuracy: 0.2539 - val_loss: 15.0472 - val_dense_321_loss: 7.0515 - val_dense_323_loss: 1.4601 - val_dense_325_loss: 2.2287 - val_dense_327_loss: 2.1271 - val_dense_329_loss: 2.2625 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.6546 - val_dense_325_accuracy: 0.2216 - val_dense_327_accuracy: 0.5052 - val_dense_329_accuracy: 0.3041\n",
      "Epoch 18/30\n",
      "776/776 [==============================] - 19s 24ms/sample - loss: 8.0577 - dense_321_loss: 0.6808 - dense_323_loss: 1.3900 - dense_325_loss: 1.9501 - dense_327_loss: 1.9089 - dense_329_loss: 2.1243 - dense_321_accuracy: 0.7345 - dense_323_accuracy: 0.5090 - dense_325_accuracy: 0.3338 - dense_327_accuracy: 0.3660 - dense_329_accuracy: 0.2564 - val_loss: 14.1144 - val_dense_321_loss: 7.5650 - val_dense_323_loss: 1.1929 - val_dense_325_loss: 1.9705 - val_dense_327_loss: 1.7223 - val_dense_329_loss: 2.0281 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.6701 - val_dense_325_accuracy: 0.4021 - val_dense_327_accuracy: 0.5000 - val_dense_329_accuracy: 0.3711\n",
      "Epoch 19/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 7.1950 - dense_321_loss: 0.6223 - dense_323_loss: 1.0849 - dense_325_loss: 1.7514 - dense_327_loss: 1.7581 - dense_329_loss: 1.9649 - dense_321_accuracy: 0.7680 - dense_323_accuracy: 0.6121 - dense_325_accuracy: 0.4111 - dense_327_accuracy: 0.4356 - dense_329_accuracy: 0.3235 - val_loss: 12.2669 - val_dense_321_loss: 5.7741 - val_dense_323_loss: 1.0952 - val_dense_325_loss: 1.8710 - val_dense_327_loss: 1.8541 - val_dense_329_loss: 1.9620 - val_dense_321_accuracy: 0.0155 - val_dense_323_accuracy: 0.7216 - val_dense_325_accuracy: 0.4124 - val_dense_327_accuracy: 0.5464 - val_dense_329_accuracy: 0.4175\n",
      "Epoch 20/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 6.2968 - dense_321_loss: 0.5186 - dense_323_loss: 0.9516 - dense_325_loss: 1.5225 - dense_327_loss: 1.5401 - dense_329_loss: 1.7554 - dense_321_accuracy: 0.8209 - dense_323_accuracy: 0.6688 - dense_325_accuracy: 0.4884 - dense_327_accuracy: 0.5129 - dense_329_accuracy: 0.3724 - val_loss: 13.4177 - val_dense_321_loss: 8.2905 - val_dense_323_loss: 0.9164 - val_dense_325_loss: 1.3894 - val_dense_327_loss: 1.4911 - val_dense_329_loss: 1.7018 - val_dense_321_accuracy: 0.0052 - val_dense_323_accuracy: 0.7423 - val_dense_325_accuracy: 0.5722 - val_dense_327_accuracy: 0.5979 - val_dense_329_accuracy: 0.5155\n",
      "Epoch 21/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 5.4447 - dense_321_loss: 0.4346 - dense_323_loss: 0.8156 - dense_325_loss: 1.2570 - dense_327_loss: 1.3211 - dense_329_loss: 1.5799 - dense_321_accuracy: 0.8389 - dense_323_accuracy: 0.7088 - dense_325_accuracy: 0.5399 - dense_327_accuracy: 0.5644 - dense_329_accuracy: 0.4536 - val_loss: 13.6123 - val_dense_321_loss: 9.6543 - val_dense_323_loss: 0.7046 - val_dense_325_loss: 1.0922 - val_dense_327_loss: 1.1524 - val_dense_329_loss: 1.3514 - val_dense_321_accuracy: 0.0103 - val_dense_323_accuracy: 0.8196 - val_dense_325_accuracy: 0.6907 - val_dense_327_accuracy: 0.7165 - val_dense_329_accuracy: 0.6598\n",
      "Epoch 22/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 4.7143 - dense_321_loss: 0.3417 - dense_323_loss: 0.7124 - dense_325_loss: 1.1422 - dense_327_loss: 1.1409 - dense_329_loss: 1.3649 - dense_321_accuracy: 0.8634 - dense_323_accuracy: 0.7423 - dense_325_accuracy: 0.6198 - dense_327_accuracy: 0.5838 - dense_329_accuracy: 0.5103 - val_loss: 11.9953 - val_dense_321_loss: 8.6364 - val_dense_323_loss: 0.6330 - val_dense_325_loss: 0.9181 - val_dense_327_loss: 1.1297 - val_dense_329_loss: 1.0645 - val_dense_321_accuracy: 0.0670 - val_dense_323_accuracy: 0.8299 - val_dense_325_accuracy: 0.7062 - val_dense_327_accuracy: 0.6804 - val_dense_329_accuracy: 0.7216\n",
      "Epoch 23/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 4.0555 - dense_321_loss: 0.3302 - dense_323_loss: 0.5650 - dense_325_loss: 0.9420 - dense_327_loss: 1.0551 - dense_329_loss: 1.1233 - dense_321_accuracy: 0.8905 - dense_323_accuracy: 0.8144 - dense_325_accuracy: 0.6675 - dense_327_accuracy: 0.6198 - dense_329_accuracy: 0.6044 - val_loss: 11.6173 - val_dense_321_loss: 8.4013 - val_dense_323_loss: 0.6521 - val_dense_325_loss: 0.8390 - val_dense_327_loss: 1.0922 - val_dense_329_loss: 1.0921 - val_dense_321_accuracy: 0.0670 - val_dense_323_accuracy: 0.7990 - val_dense_325_accuracy: 0.7371 - val_dense_327_accuracy: 0.7010 - val_dense_329_accuracy: 0.7113\n",
      "Epoch 24/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 3.5120 - dense_321_loss: 0.2912 - dense_323_loss: 0.5154 - dense_325_loss: 0.8374 - dense_327_loss: 0.9353 - dense_329_loss: 0.9570 - dense_321_accuracy: 0.9008 - dense_323_accuracy: 0.8196 - dense_325_accuracy: 0.7126 - dense_327_accuracy: 0.6701 - dense_329_accuracy: 0.6765 - val_loss: 13.6757 - val_dense_321_loss: 10.5792 - val_dense_323_loss: 0.6007 - val_dense_325_loss: 0.7981 - val_dense_327_loss: 0.9454 - val_dense_329_loss: 1.0632 - val_dense_321_accuracy: 0.0000e+00 - val_dense_323_accuracy: 0.8299 - val_dense_325_accuracy: 0.7732 - val_dense_327_accuracy: 0.6804 - val_dense_329_accuracy: 0.7732\n",
      "Epoch 25/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 3.0569 - dense_321_loss: 0.2692 - dense_323_loss: 0.4282 - dense_325_loss: 0.6927 - dense_327_loss: 0.8045 - dense_329_loss: 0.8172 - dense_321_accuracy: 0.9137 - dense_323_accuracy: 0.8570 - dense_325_accuracy: 0.7526 - dense_327_accuracy: 0.7204 - dense_329_accuracy: 0.7165 - val_loss: 13.8669 - val_dense_321_loss: 11.5642 - val_dense_323_loss: 0.6111 - val_dense_325_loss: 0.7278 - val_dense_327_loss: 1.0577 - val_dense_329_loss: 0.7268 - val_dense_321_accuracy: 0.0052 - val_dense_323_accuracy: 0.8454 - val_dense_325_accuracy: 0.7577 - val_dense_327_accuracy: 0.7784 - val_dense_329_accuracy: 0.7835\n",
      "Epoch 26/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 2.7282 - dense_321_loss: 0.2285 - dense_323_loss: 0.3933 - dense_325_loss: 0.6309 - dense_327_loss: 0.7941 - dense_329_loss: 0.7129 - dense_321_accuracy: 0.9253 - dense_323_accuracy: 0.8595 - dense_325_accuracy: 0.7848 - dense_327_accuracy: 0.7294 - dense_329_accuracy: 0.7410 - val_loss: 11.9036 - val_dense_321_loss: 10.0726 - val_dense_323_loss: 0.6415 - val_dense_325_loss: 0.7457 - val_dense_327_loss: 0.8025 - val_dense_329_loss: 0.6680 - val_dense_321_accuracy: 0.0464 - val_dense_323_accuracy: 0.8557 - val_dense_325_accuracy: 0.7371 - val_dense_327_accuracy: 0.7680 - val_dense_329_accuracy: 0.8299\n",
      "Epoch 27/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 2.3934 - dense_321_loss: 0.2631 - dense_323_loss: 0.3374 - dense_325_loss: 0.5128 - dense_327_loss: 0.6592 - dense_329_loss: 0.6135 - dense_321_accuracy: 0.9085 - dense_323_accuracy: 0.8827 - dense_325_accuracy: 0.8131 - dense_327_accuracy: 0.7706 - dense_329_accuracy: 0.7809 - val_loss: 13.1850 - val_dense_321_loss: 11.2829 - val_dense_323_loss: 0.5279 - val_dense_325_loss: 0.7118 - val_dense_327_loss: 0.8169 - val_dense_329_loss: 0.6774 - val_dense_321_accuracy: 0.0103 - val_dense_323_accuracy: 0.8763 - val_dense_325_accuracy: 0.7784 - val_dense_327_accuracy: 0.7784 - val_dense_329_accuracy: 0.8144\n",
      "Epoch 28/30\n",
      "776/776 [==============================] - 20s 25ms/sample - loss: 2.1223 - dense_321_loss: 0.2064 - dense_323_loss: 0.3251 - dense_325_loss: 0.4640 - dense_327_loss: 0.6002 - dense_329_loss: 0.5103 - dense_321_accuracy: 0.9291 - dense_323_accuracy: 0.8892 - dense_325_accuracy: 0.8454 - dense_327_accuracy: 0.7887 - dense_329_accuracy: 0.8131 - val_loss: 13.2385 - val_dense_321_loss: 11.4830 - val_dense_323_loss: 0.6690 - val_dense_325_loss: 0.6906 - val_dense_327_loss: 0.6586 - val_dense_329_loss: 0.4438 - val_dense_321_accuracy: 0.0309 - val_dense_323_accuracy: 0.8608 - val_dense_325_accuracy: 0.7938 - val_dense_327_accuracy: 0.8093 - val_dense_329_accuracy: 0.8454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 1.9520 - dense_321_loss: 0.1976 - dense_323_loss: 0.2691 - dense_325_loss: 0.4288 - dense_327_loss: 0.5290 - dense_329_loss: 0.5167 - dense_321_accuracy: 0.9227 - dense_323_accuracy: 0.9111 - dense_325_accuracy: 0.8454 - dense_327_accuracy: 0.8196 - dense_329_accuracy: 0.7990 - val_loss: 13.6860 - val_dense_321_loss: 11.6996 - val_dense_323_loss: 0.5479 - val_dense_325_loss: 0.7211 - val_dense_327_loss: 0.8393 - val_dense_329_loss: 0.5866 - val_dense_321_accuracy: 0.0309 - val_dense_323_accuracy: 0.8711 - val_dense_325_accuracy: 0.8041 - val_dense_327_accuracy: 0.7732 - val_dense_329_accuracy: 0.8866\n",
      "Epoch 30/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 1.7601 - dense_321_loss: 0.1521 - dense_323_loss: 0.2593 - dense_325_loss: 0.3857 - dense_327_loss: 0.4978 - dense_329_loss: 0.4445 - dense_321_accuracy: 0.9562 - dense_323_accuracy: 0.9085 - dense_325_accuracy: 0.8660 - dense_327_accuracy: 0.8209 - dense_329_accuracy: 0.8286 - val_loss: 12.3090 - val_dense_321_loss: 10.9453 - val_dense_323_loss: 0.5325 - val_dense_325_loss: 0.5667 - val_dense_327_loss: 0.6280 - val_dense_329_loss: 0.3559 - val_dense_321_accuracy: 0.0412 - val_dense_323_accuracy: 0.8763 - val_dense_325_accuracy: 0.8247 - val_dense_327_accuracy: 0.8144 - val_dense_329_accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "model = int_create_model()\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using glorot_uniform intializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_shape = (50, 200, 1)\n",
    "num_symbols = len(tryset)\n",
    "def int_create_model():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "       \n",
    "    conv1 = layers.Conv2D(32, (5, 5), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    \n",
    "    \n",
    "    conv2 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    \n",
    "    conv3 = layers.Conv2D(64, (5, 5), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 5 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(5):\n",
    "        dens1 = layers.Dense(64, kernel_initializer = 'glorot_uniform',activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    #model = Model(img, outs) replace this with below code as it will give error of TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key\n",
    "    model = tf.compat.v1.keras.Model(img, outs) \n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           [(None, 50, 200, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 50, 200, 32)  832         input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_113 (MaxPooling2D (None, 25, 100, 32)  0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 25, 100, 64)  51264       max_pooling2d_113[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_114 (MaxPooling2D (None, 13, 50, 64)   0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 13, 50, 64)   102464      max_pooling2d_114[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 13, 50, 64)   256         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_115 (MaxPooling2D (None, 7, 25, 64)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 11200)        0           max_pooling2d_115[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_331 (Dense)               (None, 64)           716864      flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_333 (Dense)               (None, 64)           716864      flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_335 (Dense)               (None, 64)           716864      flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_337 (Dense)               (None, 64)           716864      flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_339 (Dense)               (None, 64)           716864      flatten_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 64)           0           dense_331[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 64)           0           dense_333[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 64)           0           dense_335[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 64)           0           dense_337[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 64)           0           dense_339[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_332 (Dense)               (None, 19)           1235        dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_334 (Dense)               (None, 19)           1235        dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_336 (Dense)               (None, 19)           1235        dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_338 (Dense)               (None, 19)           1235        dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_340 (Dense)               (None, 19)           1235        dropout_169[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,745,311\n",
      "Trainable params: 3,745,183\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n",
      "Train on 776 samples, validate on 194 samples\n",
      "Epoch 1/30\n",
      "776/776 [==============================] - 26s 34ms/sample - loss: 15.0936 - dense_332_loss: 2.9262 - dense_334_loss: 3.1025 - dense_336_loss: 3.0212 - dense_338_loss: 3.0254 - dense_340_loss: 3.0096 - dense_332_accuracy: 0.0773 - dense_334_accuracy: 0.0477 - dense_336_accuracy: 0.0631 - dense_338_accuracy: 0.0735 - dense_340_accuracy: 0.0670 - val_loss: 15.6040 - val_dense_332_loss: 3.6800 - val_dense_334_loss: 2.9615 - val_dense_336_loss: 2.9428 - val_dense_338_loss: 2.9430 - val_dense_340_loss: 2.9467 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0567 - val_dense_336_accuracy: 0.0361 - val_dense_338_accuracy: 0.0979 - val_dense_340_accuracy: 0.1186\n",
      "Epoch 2/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 14.6145 - dense_332_loss: 2.7990 - dense_334_loss: 2.9707 - dense_336_loss: 2.9472 - dense_338_loss: 2.9407 - dense_340_loss: 2.9496 - dense_332_accuracy: 0.0928 - dense_334_accuracy: 0.0619 - dense_336_accuracy: 0.0799 - dense_338_accuracy: 0.0889 - dense_340_accuracy: 0.0941 - val_loss: 15.6706 - val_dense_332_loss: 3.9159 - val_dense_334_loss: 2.9276 - val_dense_336_loss: 2.9406 - val_dense_338_loss: 2.9377 - val_dense_340_loss: 2.9436 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0515 - val_dense_336_accuracy: 0.0464 - val_dense_338_accuracy: 0.0979 - val_dense_340_accuracy: 0.1392\n",
      "Epoch 3/30\n",
      "776/776 [==============================] - 22s 28ms/sample - loss: 14.5061 - dense_332_loss: 2.7611 - dense_334_loss: 2.9232 - dense_336_loss: 2.9429 - dense_338_loss: 2.9381 - dense_340_loss: 2.9378 - dense_332_accuracy: 0.0838 - dense_334_accuracy: 0.0876 - dense_336_accuracy: 0.0992 - dense_338_accuracy: 0.0928 - dense_340_accuracy: 0.0876 - val_loss: 15.6690 - val_dense_332_loss: 4.0174 - val_dense_334_loss: 2.9240 - val_dense_336_loss: 2.9355 - val_dense_338_loss: 2.9464 - val_dense_340_loss: 2.9423 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0619 - val_dense_336_accuracy: 0.0773 - val_dense_338_accuracy: 0.0979 - val_dense_340_accuracy: 0.1392\n",
      "Epoch 4/30\n",
      "776/776 [==============================] - 21s 27ms/sample - loss: 14.3721 - dense_332_loss: 2.6810 - dense_334_loss: 2.8911 - dense_336_loss: 2.9430 - dense_338_loss: 2.9336 - dense_340_loss: 2.9200 - dense_332_accuracy: 0.1224 - dense_334_accuracy: 0.0851 - dense_336_accuracy: 0.0915 - dense_338_accuracy: 0.1018 - dense_340_accuracy: 0.0992 - val_loss: 15.0280 - val_dense_332_loss: 3.2469 - val_dense_334_loss: 3.0394 - val_dense_336_loss: 2.9538 - val_dense_338_loss: 2.9651 - val_dense_340_loss: 2.9548 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0464 - val_dense_336_accuracy: 0.0361 - val_dense_338_accuracy: 0.0670 - val_dense_340_accuracy: 0.1392\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 20s 25ms/sample - loss: 14.0787 - dense_332_loss: 2.5469 - dense_334_loss: 2.8467 - dense_336_loss: 2.9271 - dense_338_loss: 2.8933 - dense_340_loss: 2.8647 - dense_332_accuracy: 0.1327 - dense_334_accuracy: 0.0799 - dense_336_accuracy: 0.1044 - dense_338_accuracy: 0.1082 - dense_340_accuracy: 0.1095 - val_loss: 14.8667 - val_dense_332_loss: 3.0086 - val_dense_334_loss: 3.0664 - val_dense_336_loss: 2.9895 - val_dense_338_loss: 2.9724 - val_dense_340_loss: 2.9083 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0670 - val_dense_336_accuracy: 0.0361 - val_dense_338_accuracy: 0.0412 - val_dense_340_accuracy: 0.0722\n",
      "Epoch 6/30\n",
      "776/776 [==============================] - 20s 26ms/sample - loss: 13.6145 - dense_332_loss: 2.4482 - dense_334_loss: 2.7365 - dense_336_loss: 2.8418 - dense_338_loss: 2.8444 - dense_340_loss: 2.7492 - dense_332_accuracy: 0.2332 - dense_334_accuracy: 0.1044 - dense_336_accuracy: 0.1314 - dense_338_accuracy: 0.1276 - dense_340_accuracy: 0.1392 - val_loss: 15.8605 - val_dense_332_loss: 3.2989 - val_dense_334_loss: 3.3251 - val_dense_336_loss: 3.0755 - val_dense_338_loss: 3.1305 - val_dense_340_loss: 3.0593 - val_dense_332_accuracy: 0.0000e+00 - val_dense_334_accuracy: 0.0670 - val_dense_336_accuracy: 0.0361 - val_dense_338_accuracy: 0.0670 - val_dense_340_accuracy: 0.0619\n",
      "Epoch 7/30\n",
      "736/776 [===========================>..] - ETA: 1s - loss: 13.1400 - dense_332_loss: 2.3109 - dense_334_loss: 2.6392 - dense_336_loss: 2.7336 - dense_338_loss: 2.7965 - dense_340_loss: 2.6598 - dense_332_accuracy: 0.2147 - dense_334_accuracy: 0.1345 - dense_336_accuracy: 0.1359 - dense_338_accuracy: 0.1236 - dense_340_accuracy: 0.1522"
     ]
    }
   ],
   "source": [
    "model = int_create_model()\n",
    "model.summary();\n",
    "#model = create_model()\n",
    "hist = model.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3], y_train[4]], batch_size=32, epochs=30,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
